[{"content":"来了来了，晚到了几天的年度总结，但是总算是没有鸽掉 ~\n2022年，疫情第三年，在这一年里面对于我来说关键词就是 “变化”，一切都在变化，我从大学本科毕业，第二次裸辞，再到中国疫情管控政策突然的完全放开，这一年的生活充满了不确定性。\n说实话，我也不知道为什么当初为啥我会这么的莽，居然在刚刚毕业的时候就因为没有争取到心中合适的薪资而不在原来实习的公司转正，现在想想还是感觉当时的决定是如此的冲动，在7月这个对于学生来说的招聘高峰期以及对于企业来说的招聘真空期，在今年疫情对经济的冲击下就业市场真的比往年更加的难找工作，好在在不长时间的摆烂+面试后还是顺利的找到了我现在呆的这家公司，虽然工资没有高很多，我当时是真的怕了，因为招聘网站上面虽然很多HR挂着招聘，但是真的没有人回复。\n生活方面也迎来了比较大的变化，从之前一个人住在城中村的一房一厅，到9月跟朋友一起搬到了一个小区里面的三房一厅，虽然房租什么的分摊下来并不比之前要低，但是生活质量也大大的提高了，同时也可以说是躲过了11月在城中村爆发的一波疫情。这个搬家其实我已经想了很久的了，一方面是到了这个时间我转正了，工资相应的会提高一点，另一方面，城中村的生活环境真的不算太好，即使你租的房子带阳台、有阳光直射，你在回房子的路上总会要经过城中村的小巷，小巷真的一年四季无论什么天气，你的头顶都有可能会滴下来一些不明液体，更不用说一些路会坑坑洼洼，就真的会比较搞心态。安全也是在城中村里面我觉得最需要担心的一个地方，倒也不是说担心被人抢东西偷东西啥的，我是经常看到路上会有电动车停着，我就常常在害怕，万一突发火灾，还真不太好跑得出去。所以基于种种原因，就跟几个朋友一起合租搬出去啦！\n好，大概今年工作、生活的变化就唠到这里吧。\n博客写了啥  博客迁移到cloudflare踩坑 年初将博客从自建的服务器迁移到了 cloudflare worker 上了 博客及相关服务部署更新 然后我又更新了下博客的部署流程，将博客主域名部署到了 vercel 上面，因为他的 cdn 貌似更大陆友好一些 Oneplus 8T 刷入 LineageOS 折腾了下我的手机，主要是 大氢亡了 然后 OOS 我也不是很喜欢，干脆刷成了 LineageOS，另外，这部 Oneplus 8T 也在今年的 12月14日 突然结束了自己的一生，它主板坏了。可恶，刚好在小米13发布后第二天，我只好忍痛买了新手机 Go 实现瑞士轮排列算法 这篇文章是我在新公司改进原有瑞士论算法的时候顺便记录下来的，比原来用的算法不仅结构清晰了，执行效率也更高了 使用 docker-compose 搭建 clickhouse 集群 这篇博客，其实是我在上家公司搭建 ck 集群的记录，当时顺手也水了一篇博客 使用 ssh 密钥签名 git commit 这篇没有啥可说的，记录一下 使用 headscale 异地组网 这个主要是当时想要连上内网设备折腾了一下，然后家里的网络配好了ipv6就没有啥大作用了  博客今年怎么样  今年更新了 8 篇文章(包括本文) 友链增加了 0 个大佬 评论 0 条(无人在意.jpg)  其实在我的 todo 里面还有很多博客还没写，就摁鸽，看看明年有没有空补一下了\n去年说好绝对不咕的雄狮少年的观后感看起来还是鸽了，笑死\n代码写了啥 貌似没有新写啥，都是旧项目在更新依赖啥的修修补补\n johnpoint/mc-mod-sync 一个同步 mc mod 的命令行程序  今年玩了啥新东西 今年倒是折腾了不少好玩的东西\n cloudflare zero trust 零信任 saas 平台 ZeroTier Tailscale Headscale  参与了啥活动  GDG devfest GuangZhou (他真的又延期了！延到了明年的2月，真可怕) ","permalink":"https://blog.lvcshu.com/2022/12/29/2022-year-summary/","summary":"\u003cp\u003e来了来了，晚到了几天的年度总结，但是总算是没有鸽掉 ~\u003c/p\u003e","title":"2022 年度总结"},{"content":"很久之前看过柠檬大佬的使用 N2N 进行异地组网的文章，大受震撼，但是 N2N 的部署体验很难说得上令人愉悦。\n然后就听说了 wireguard 被加入 linux 内核，以下是 wireguard 的介绍：\n WireGuard是由Jason A. Donenfeld开发的开放源代码VPN程序及协议[1]，基于Linux内核实现，利用Curve25519进行密钥交换，ChaCha20用于加密，Poly1305用于数据认证，BLAKE2用于散列函数运算[1]，支持IPv4和IPv6的第3层。[2]WireGuard旨在获得比IPsec和OpenVPN更好的性能[3]。\n 确实，wireguard 性能十分不错，但是配置实在是过于繁琐了，如果要往 wireguard 网络中加入一台设备，则需要修改几乎所有连入网络设备的配置文件，实在是太麻烦了，好在现在已经有了 tailscale 这个服务提供商提供了基于 wireguard 的 0 配置的 VPN 组网方案。\n而 headscale 就是 tailscale 中控服务端的开源版本，开源版本支持自己部署，同时没有连入设备的数量限制，于是我花了一点时间将 headscale 部署了一下。\n使用到的项目 Github:juanfont/headscale Github:gurucomputing/headscale-ui\n部署 headscale 这里我使用 docker-componse 进行部署\nversion:\u0026#39;3.5\u0026#39;services:headscale:image:headscale/headscale:latest-alpinecontainer_name:headscalevolumes:- ./container-config:/etc/headscale- ./container-data/data:/var/lib/headscaleports:- 27896:8080command:headscale serverestart:unless-stoppedheadscale-ui:image:ghcr.io/gurucomputing/headscale-ui:latestrestart:unless-stoppedcontainer_name:headscale-uiports:- 9443:443同时我还使用了nginx来进行反向代理，将 headscale-ui 和 headscale 分别部署在了不同的域名下面，因此要做一些 CORS 的处理，Nginx 配置文件参考如下\nlocation / { add_header \u0026#39;Access-Control-Allow-Origin\u0026#39; \u0026#39;{{UI的域名}}\u0026#39; always; add_header \u0026#39;Access-Control-Allow-Methods\u0026#39; \u0026#39;GET, POST, OPTIONS,DELETE ,PUT\u0026#39; always; add_header \u0026#39;Access-Control-Allow-Headers\u0026#39; \u0026#39;authorization ,DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range\u0026#39; always; add_header \u0026#39;Access-Control-Expose-Headers\u0026#39; \u0026#39;Content-Length,Content-Range\u0026#39; always; if ($request_method = \u0026#39;OPTIONS\u0026#39;) { add_header \u0026#39;Access-Control-Allow-Origin\u0026#39; \u0026#39;{{UI的域名}}\u0026#39; always; add_header \u0026#39;Access-Control-Allow-Methods\u0026#39; \u0026#39;GET, POST, OPTIONS,DELETE ,PUT \u0026#39; always; add_header \u0026#39;Access-Control-Allow-Headers\u0026#39; \u0026#39;authorization ,DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range\u0026#39; always; add_header \u0026#39;Access-Control-Expose-Headers\u0026#39; \u0026#39;Content-Length,Content-Range\u0026#39; always; add_header \u0026#39;Access-Control-Max-Age\u0026#39; 1728000; add_header \u0026#39;Content-Type\u0026#39; \u0026#39;text/plain; charset=utf-8\u0026#39;; add_header \u0026#39;Content-Length\u0026#39; 0; return 204; } proxy_pass {{headscale的地址}}; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;Upgrade\u0026#34;; proxy_redirect default; } 配置 headscale-ui headscale-ui 这个项目是一个纯前端的项目，是通过用户的浏览器直接调用 headscale 的 API 接口，所以需要自己去 headscale container 内部创建 apikey 来通过鉴权\ndocker exec -it headscale headscale apikey create 这个指令会创建一个 apikey，将他填入 headscale-ui 的配置里面即可，这里的配置仅保留在本地，不会上传到任何地方，所以如果更换了设备或者浏览器想要进行 headscale 的配置的话，要将这一步重复一遍。\n配置 ACL headscale 同时还支持 ACL 功能，从而控制在这个大内网之中设备能访问的设备，这边我写了个比较简单的 ACL 配置文件\n// ./container-config/acl.json { \u0026#34;groups\u0026#34;: { \u0026#34;group:admin\u0026#34;: [\u0026#34;admin\u0026#34;], // 管理员用户  \u0026#34;group:user\u0026#34;: [\u0026#34;user\u0026#34;], // 普通用户  }, \u0026#34;acls\u0026#34;: [ // { \u0026#34;action\u0026#34;: \u0026#34;accept\u0026#34;, \u0026#34;src\u0026#34;: [\u0026#34;*\u0026#34;], \u0026#34;dst\u0026#34;: [\u0026#34;*:*\u0026#34;] },  { \u0026#34;action\u0026#34;: \u0026#34;accept\u0026#34;, \u0026#34;src\u0026#34;: [\u0026#34;group:admin\u0026#34;], \u0026#34;dst\u0026#34;: [\u0026#34;*:*\u0026#34;] }, // 管理员用户的设备能访问所有设备  { \u0026#34;action\u0026#34;: \u0026#34;accept\u0026#34;, \u0026#34;src\u0026#34;: [\u0026#34;group:user\u0026#34;], \u0026#34;dst\u0026#34;: [\u0026#34;tag:share:*\u0026#34;,\u0026#34;autogroup:self:*\u0026#34;] }, // 普通用户仅能访问带 share 标签以及自己的设备  ], \u0026#34;ssh\u0026#34;: [ { \u0026#34;action\u0026#34;: \u0026#34;check\u0026#34;, \u0026#34;src\u0026#34;: [ \u0026#34;autogroup:members\u0026#34; ], \u0026#34;dst\u0026#34;: [ \u0026#34;autogroup:self\u0026#34; ], \u0026#34;users\u0026#34;: [ \u0026#34;autogroup:nonroot\u0026#34;, \u0026#34;root\u0026#34; ] }, ], \u0026#34;tagOwners\u0026#34;: { \u0026#34;tag:share\u0026#34;: [\u0026#34;group:admin\u0026#34;], }, } 同时，要修改配置文件里面的 acl_policy_path\nacl_policy_path: \u0026#34;/etc/headscale/acl.json\u0026#34; 这样基本上就大功告成了，客户端的配置网上基本上都有，就不多写了。\n","permalink":"https://blog.lvcshu.com/2022/11/04/deploy-headscale/","summary":"很久之前看过柠檬大佬的使用 N2N 进行异地组网的文章，大受震撼，但是 N2N 的部署体验很难说得上令人愉悦。\n然后就听说了 wireguard 被加入 linux 内核，以下是 wireguard 的介绍：\n WireGuard是由Jason A. Donenfeld开发的开放源代码VPN程序及协议[1]，基于Linux内核实现，利用Curve25519进行密钥交换，ChaCha20用于加密，Poly1305用于数据认证，BLAKE2用于散列函数运算[1]，支持IPv4和IPv6的第3层。[2]WireGuard旨在获得比IPsec和OpenVPN更好的性能[3]。\n 确实，wireguard 性能十分不错，但是配置实在是过于繁琐了，如果要往 wireguard 网络中加入一台设备，则需要修改几乎所有连入网络设备的配置文件，实在是太麻烦了，好在现在已经有了 tailscale 这个服务提供商提供了基于 wireguard 的 0 配置的 VPN 组网方案。\n而 headscale 就是 tailscale 中控服务端的开源版本，开源版本支持自己部署，同时没有连入设备的数量限制，于是我花了一点时间将 headscale 部署了一下。\n使用到的项目 Github:juanfont/headscale Github:gurucomputing/headscale-ui\n部署 headscale 这里我使用 docker-componse 进行部署\nversion:\u0026#39;3.5\u0026#39;services:headscale:image:headscale/headscale:latest-alpinecontainer_name:headscalevolumes:- ./container-config:/etc/headscale- ./container-data/data:/var/lib/headscaleports:- 27896:8080command:headscale serverestart:unless-stoppedheadscale-ui:image:ghcr.io/gurucomputing/headscale-ui:latestrestart:unless-stoppedcontainer_name:headscale-uiports:- 9443:443同时我还使用了nginx来进行反向代理，将 headscale-ui 和 headscale 分别部署在了不同的域名下面，因此要做一些 CORS 的处理，Nginx 配置文件参考如下\nlocation / { add_header \u0026#39;Access-Control-Allow-Origin\u0026#39; \u0026#39;{{UI的域名}}\u0026#39; always; add_header \u0026#39;Access-Control-Allow-Methods\u0026#39; \u0026#39;GET, POST, OPTIONS,DELETE ,PUT\u0026#39; always; add_header \u0026#39;Access-Control-Allow-Headers\u0026#39; \u0026#39;authorization ,DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range\u0026#39; always; add_header \u0026#39;Access-Control-Expose-Headers\u0026#39; \u0026#39;Content-Length,Content-Range\u0026#39; always; if ($request_method = \u0026#39;OPTIONS\u0026#39;) { add_header \u0026#39;Access-Control-Allow-Origin\u0026#39; \u0026#39;{{UI的域名}}\u0026#39; always; add_header \u0026#39;Access-Control-Allow-Methods\u0026#39; \u0026#39;GET, POST, OPTIONS,DELETE ,PUT \u0026#39; always; add_header \u0026#39;Access-Control-Allow-Headers\u0026#39; \u0026#39;authorization ,DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range\u0026#39; always; add_header \u0026#39;Access-Control-Expose-Headers\u0026#39; \u0026#39;Content-Length,Content-Range\u0026#39; always; add_header \u0026#39;Access-Control-Max-Age\u0026#39; 1728000; add_header \u0026#39;Content-Type\u0026#39; \u0026#39;text/plain; charset=utf-8\u0026#39;; add_header \u0026#39;Content-Length\u0026#39; 0; return 204; } proxy_pass {{headscale的地址}}; proxy_http_version 1.","title":"使用 headscale 异地组网"},{"content":"在 Github commit添加verified标识 这篇文章中，配置好了 gpg 密钥签名作为标识 git commit 是否值得信任带凭证，但是载后面使用签名的过程中渐渐感到了一丝丝的麻烦，因为 gpg 密钥在我日常的生活中并没有很多其他的用处。最近 github 支持了显示通过 ssh 密钥签名的 commit 的功能。ssh 密钥在日常用起来要比 gpg 密钥要多得多，所以配置了一下，顺便写个文章记录操作流程。\ngit config --global gpg.format ssh git config --global user.signingKey ~/.ssh/id_ed25519.pub git config --global commit.gpgsign true git config --global tag.gpgsign true 一般来说，配置好了这几个选项，就可以顺利的把签名加上了，要是 git commit 的时候提示你 ssh是不支持的格式 那么就意味着当前版本的 git 并不支持通过 ssh 密钥签名 commit，这时候就要自己更新下系统上面的 git 了。\n","permalink":"https://blog.lvcshu.com/2022/10/05/git-commit-sign-by-ssh-key/","summary":"在 Github commit添加verified标识 这篇文章中，配置好了 gpg 密钥签名作为标识 git commit 是否值得信任带凭证，但是载后面使用签名的过程中渐渐感到了一丝丝的麻烦，因为 gpg 密钥在我日常的生活中并没有很多其他的用处。最近 github 支持了显示通过 ssh 密钥签名的 commit 的功能。ssh 密钥在日常用起来要比 gpg 密钥要多得多，所以配置了一下，顺便写个文章记录操作流程。\ngit config --global gpg.format ssh git config --global user.signingKey ~/.ssh/id_ed25519.pub git config --global commit.gpgsign true git config --global tag.gpgsign true 一般来说，配置好了这几个选项，就可以顺利的把签名加上了，要是 git commit 的时候提示你 ssh是不支持的格式 那么就意味着当前版本的 git 并不支持通过 ssh 密钥签名 commit，这时候就要自己更新下系统上面的 git 了。","title":"使用 ssh 密钥签名 git commit"},{"content":"Docker Compose 配置 version:\u0026#39;3\u0026#39;services:clickhouse-server-ck1:restart:on-failure:10# 退出非0重启，尝试10次image:yandex/clickhouse-servercontainer_name:ck1networks:- ck-networkports:- \u0026#34;8124:8123\u0026#34;- \u0026#34;9001:9000\u0026#34;- \u0026#34;9010:9004\u0026#34;volumes:- `pwd`/clickhouse/:/var/lib/clickhouse/- `pwd`/clickhouse-server/:/etc/clickhouse-server/- `pwd`/log/clickhouse-server/:/var/log/clickhouse-server/ulimits:nofile:soft:\u0026#34;262144\u0026#34;hard:\u0026#34;262144\u0026#34;depends_on:- zookeeper-1clickhouse-server-ck2:restart:on-failure:10# 退出非0重启，尝试10次image:yandex/clickhouse-servercontainer_name:ck2networks:- ck-networkports:- \u0026#34;8125:8123\u0026#34;- \u0026#34;9002:9000\u0026#34;- \u0026#34;9011:9004\u0026#34;volumes:- `pwd`/clickhouse2/:/var/lib/clickhouse/- `pwd`/clickhouse-server2/:/etc/clickhouse-server/- `pwd`/log/clickhouse-server2/:/var/log/clickhouse-server/ulimits:nofile:soft:\u0026#34;262144\u0026#34;hard:\u0026#34;262144\u0026#34;depends_on:- zookeeper-1clickhouse-server-ck3:restart:on-failure:10# 退出非0重启，尝试10次image:yandex/clickhouse-servercontainer_name:ck3networks:- ck-networkports:- \u0026#34;8126:8123\u0026#34;- \u0026#34;9003:9000\u0026#34;- \u0026#34;9012:9004\u0026#34;volumes:- `pwd`/clickhouse3/:/var/lib/clickhouse/- `pwd`/clickhouse-server3/:/etc/clickhouse-server/- `pwd`/log/clickhouse-server3/:/var/log/clickhouse-server/ulimits:nofile:soft:\u0026#34;262144\u0026#34;hard:\u0026#34;262144\u0026#34;depends_on:- zookeeper-1zookeeper-1:restart:on-failure:10# 退出非0重启，尝试10次image:zookeeper:3.8.0container_name:zookeeper1networks:- ck-networkports:- \u0026#34;2181:2181\u0026#34;volumes:- `pwd`/zookeeper/conf/:/apache-zookeeper-3.8.0-bin/conf/- `pwd`/zookeeper/data/:/data- `pwd`/zookeeper/datalog/:/datalog- `pwd`/zookeeper/logs/:/logsulimits:nofile:soft:\u0026#34;262144\u0026#34;hard:\u0026#34;262144\u0026#34;networks:ck-network:Clickhouse 配置文件 \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!-- NOTE: User and query level settings are set up in \u0026#34;users.xml\u0026#34; file. If you have accidentally specified user-level settings here, server won\u0026#39;t start. You can either move the settings to the right place inside \u0026#34;users.xml\u0026#34; file or add \u0026lt;skip_check_for_incorrect_settings\u0026gt;1\u0026lt;/skip_check_for_incorrect_settings\u0026gt; here. --\u0026gt; \u0026lt;clickhouse\u0026gt; \u0026lt;logger\u0026gt; \u0026lt;!-- Possible levels [1]: - none (turns off logging) - fatal - critical - error - warning - notice - information - debug - trace - test (not for production usage) [1]: https://github.com/pocoproject/poco/blob/poco-1.9.4-release/Foundation/include/Poco/Logger.h#L105-L114 --\u0026gt; \u0026lt;level\u0026gt;trace\u0026lt;/level\u0026gt; \u0026lt;log\u0026gt;/var/log/clickhouse-server/clickhouse-server.log\u0026lt;/log\u0026gt; \u0026lt;errorlog\u0026gt;/var/log/clickhouse-server/clickhouse-server.err.log\u0026lt;/errorlog\u0026gt; \u0026lt;!-- Rotation policy See https://github.com/pocoproject/poco/blob/poco-1.9.4-release/Foundation/include/Poco/FileChannel.h#L54-L85 --\u0026gt; \u0026lt;size\u0026gt;1000M\u0026lt;/size\u0026gt; \u0026lt;count\u0026gt;10\u0026lt;/count\u0026gt; \u0026lt;!-- \u0026lt;console\u0026gt;1\u0026lt;/console\u0026gt; --\u0026gt; \u0026lt;!-- Default behavior is autodetection (log to console if not daemon mode and is tty) --\u0026gt; \u0026lt;!-- Per level overrides (legacy): For example to suppress logging of the ConfigReloader you can use: NOTE: levels.logger is reserved, see below. --\u0026gt; \u0026lt;!-- \u0026lt;levels\u0026gt; \u0026lt;ConfigReloader\u0026gt;none\u0026lt;/ConfigReloader\u0026gt; \u0026lt;/levels\u0026gt; --\u0026gt; \u0026lt;!-- Per level overrides: For example to suppress logging of the RBAC for default user you can use: (But please note that the logger name maybe changed from version to version, even after minor upgrade) --\u0026gt; \u0026lt;!-- \u0026lt;levels\u0026gt; \u0026lt;logger\u0026gt; \u0026lt;name\u0026gt;ContextAccess (default)\u0026lt;/name\u0026gt; \u0026lt;level\u0026gt;none\u0026lt;/level\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;logger\u0026gt; \u0026lt;name\u0026gt;DatabaseOrdinary (test)\u0026lt;/name\u0026gt; \u0026lt;level\u0026gt;none\u0026lt;/level\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;/levels\u0026gt; --\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;!-- Add headers to response in options request. OPTIONS method is used in CORS preflight requests. --\u0026gt; \u0026lt;!-- It is off by default. Next headers are obligate for CORS.--\u0026gt; \u0026lt;!-- http_options_response\u0026gt; \u0026lt;header\u0026gt; \u0026lt;name\u0026gt;Access-Control-Allow-Origin\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;*\u0026lt;/value\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;header\u0026gt; \u0026lt;name\u0026gt;Access-Control-Allow-Headers\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;origin, x-requested-with\u0026lt;/value\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;header\u0026gt; \u0026lt;name\u0026gt;Access-Control-Allow-Methods\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;POST, GET, OPTIONS\u0026lt;/value\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;header\u0026gt; \u0026lt;name\u0026gt;Access-Control-Max-Age\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;86400\u0026lt;/value\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;/http_options_response --\u0026gt; \u0026lt;!-- It is the name that will be shown in the clickhouse-client. By default, anything with \u0026#34;production\u0026#34; will be highlighted in red in query prompt. --\u0026gt; \u0026lt;!--display_name\u0026gt;production\u0026lt;/display_name--\u0026gt; \u0026lt;!-- Port for HTTP API. See also \u0026#39;https_port\u0026#39; for secure connections. This interface is also used by ODBC and JDBC drivers (DataGrip, Dbeaver, ...) and by most of web interfaces (embedded UI, Grafana, Redash, ...). --\u0026gt; \u0026lt;http_port\u0026gt;8123\u0026lt;/http_port\u0026gt; \u0026lt;!-- Port for interaction by native protocol with: - clickhouse-client and other native ClickHouse tools (clickhouse-benchmark, clickhouse-copier); - clickhouse-server with other clickhouse-servers for distributed query processing; - ClickHouse drivers and applications supporting native protocol (this protocol is also informally called as \u0026#34;the TCP protocol\u0026#34;); See also \u0026#39;tcp_port_secure\u0026#39; for secure connections. --\u0026gt; \u0026lt;tcp_port\u0026gt;9000\u0026lt;/tcp_port\u0026gt; \u0026lt;!-- Compatibility with MySQL protocol. ClickHouse will pretend to be MySQL for applications connecting to this port. --\u0026gt; \u0026lt;mysql_port\u0026gt;9004\u0026lt;/mysql_port\u0026gt; \u0026lt;!-- Compatibility with PostgreSQL protocol. ClickHouse will pretend to be PostgreSQL for applications connecting to this port. --\u0026gt; \u0026lt;postgresql_port\u0026gt;9005\u0026lt;/postgresql_port\u0026gt; \u0026lt;!-- HTTP API with TLS (HTTPS). You have to configure certificate to enable this interface. See the openSSL section below. --\u0026gt; \u0026lt;!-- \u0026lt;https_port\u0026gt;8443\u0026lt;/https_port\u0026gt; --\u0026gt; \u0026lt;!-- Native interface with TLS. You have to configure certificate to enable this interface. See the openSSL section below. --\u0026gt; \u0026lt;!-- \u0026lt;tcp_port_secure\u0026gt;9440\u0026lt;/tcp_port_secure\u0026gt; --\u0026gt; \u0026lt;!-- Native interface wrapped with PROXYv1 protocol PROXYv1 header sent for every connection. ClickHouse will extract information about proxy-forwarded client address from the header. --\u0026gt; \u0026lt;!-- \u0026lt;tcp_with_proxy_port\u0026gt;9011\u0026lt;/tcp_with_proxy_port\u0026gt; --\u0026gt; \u0026lt;!-- Port for communication between replicas. Used for data exchange. It provides low-level data access between servers. This port should not be accessible from untrusted networks. See also \u0026#39;interserver_http_credentials\u0026#39;. Data transferred over connections to this port should not go through untrusted networks. See also \u0026#39;interserver_https_port\u0026#39;. --\u0026gt; \u0026lt;interserver_http_port\u0026gt;9009\u0026lt;/interserver_http_port\u0026gt; \u0026lt;!-- Port for communication between replicas with TLS. You have to configure certificate to enable this interface. See the openSSL section below. See also \u0026#39;interserver_http_credentials\u0026#39;. --\u0026gt; \u0026lt;!-- \u0026lt;interserver_https_port\u0026gt;9010\u0026lt;/interserver_https_port\u0026gt; --\u0026gt; \u0026lt;!-- Hostname that is used by other replicas to request this server. If not specified, than it is determined analogous to \u0026#39;hostname -f\u0026#39; command. This setting could be used to switch replication to another network interface (the server may be connected to multiple networks via multiple addresses) --\u0026gt; \u0026lt;interserver_http_host\u0026gt;0.0.0.0\u0026lt;/interserver_http_host\u0026gt; \u0026lt;!-- You can specify credentials for authenthication between replicas. This is required when interserver_https_port is accessible from untrusted networks, and also recommended to avoid SSRF attacks from possibly compromised services in your network. --\u0026gt; \u0026lt;!--\u0026lt;interserver_http_credentials\u0026gt; \u0026lt;user\u0026gt;interserver\u0026lt;/user\u0026gt; \u0026lt;password\u0026gt;\u0026lt;/password\u0026gt; \u0026lt;/interserver_http_credentials\u0026gt;--\u0026gt; \u0026lt;!-- Listen specified address. Use :: (wildcard IPv6 address), if you want to accept connections both with IPv4 and IPv6 from everywhere. Notes: If you open connections from wildcard address, make sure that at least one of the following measures applied: - server is protected by firewall and not accessible from untrusted networks; - all users are restricted to subset of network addresses (see users.xml); - all users have strong passwords, only secure (TLS) interfaces are accessible, or connections are only made via TLS interfaces. - users without password have readonly access. See also: https://www.shodan.io/search?query=clickhouse --\u0026gt; \u0026lt;!-- \u0026lt;listen_host\u0026gt;::\u0026lt;/listen_host\u0026gt; --\u0026gt; \u0026lt;!-- Same for hosts without support for IPv6: --\u0026gt; \u0026lt;listen_host\u0026gt;0.0.0.0\u0026lt;/listen_host\u0026gt; \u0026lt;!-- Default values - try listen localhost on IPv4 and IPv6. --\u0026gt; \u0026lt;!-- \u0026lt;listen_host\u0026gt;::1\u0026lt;/listen_host\u0026gt; \u0026lt;listen_host\u0026gt;127.0.0.1\u0026lt;/listen_host\u0026gt; --\u0026gt; \u0026lt;!-- Don\u0026#39;t exit if IPv6 or IPv4 networks are unavailable while trying to listen. --\u0026gt; \u0026lt;!-- \u0026lt;listen_try\u0026gt;0\u0026lt;/listen_try\u0026gt; --\u0026gt; \u0026lt;!-- Allow multiple servers to listen on the same address:port. This is not recommended. --\u0026gt; \u0026lt;!-- \u0026lt;listen_reuse_port\u0026gt;0\u0026lt;/listen_reuse_port\u0026gt; --\u0026gt; \u0026lt;!-- \u0026lt;listen_backlog\u0026gt;4096\u0026lt;/listen_backlog\u0026gt; --\u0026gt; \u0026lt;max_connections\u0026gt;4096\u0026lt;/max_connections\u0026gt; \u0026lt;!-- For \u0026#39;Connection: keep-alive\u0026#39; in HTTP 1.1 --\u0026gt; \u0026lt;keep_alive_timeout\u0026gt;3\u0026lt;/keep_alive_timeout\u0026gt; \u0026lt;!-- gRPC protocol (see src/Server/grpc_protos/clickhouse_grpc.proto for the API) --\u0026gt; \u0026lt;!-- \u0026lt;grpc_port\u0026gt;9100\u0026lt;/grpc_port\u0026gt; --\u0026gt; \u0026lt;grpc\u0026gt; \u0026lt;enable_ssl\u0026gt;false\u0026lt;/enable_ssl\u0026gt; \u0026lt;!-- The following two files are used only if enable_ssl=1 --\u0026gt; \u0026lt;ssl_cert_file\u0026gt;/path/to/ssl_cert_file\u0026lt;/ssl_cert_file\u0026gt; \u0026lt;ssl_key_file\u0026gt;/path/to/ssl_key_file\u0026lt;/ssl_key_file\u0026gt; \u0026lt;!-- Whether server will request client for a certificate --\u0026gt; \u0026lt;ssl_require_client_auth\u0026gt;false\u0026lt;/ssl_require_client_auth\u0026gt; \u0026lt;!-- The following file is used only if ssl_require_client_auth=1 --\u0026gt; \u0026lt;ssl_ca_cert_file\u0026gt;/path/to/ssl_ca_cert_file\u0026lt;/ssl_ca_cert_file\u0026gt; \u0026lt;!-- Default compression algorithm (applied if client doesn\u0026#39;t specify another algorithm, see result_compression in QueryInfo). Supported algorithms: none, deflate, gzip, stream_gzip --\u0026gt; \u0026lt;compression\u0026gt;deflate\u0026lt;/compression\u0026gt; \u0026lt;!-- Default compression level (applied if client doesn\u0026#39;t specify another level, see result_compression in QueryInfo). Supported levels: none, low, medium, high --\u0026gt; \u0026lt;compression_level\u0026gt;medium\u0026lt;/compression_level\u0026gt; \u0026lt;!-- Send/receive message size limits in bytes. -1 means unlimited --\u0026gt; \u0026lt;max_send_message_size\u0026gt;-1\u0026lt;/max_send_message_size\u0026gt; \u0026lt;max_receive_message_size\u0026gt;-1\u0026lt;/max_receive_message_size\u0026gt; \u0026lt;!-- Enable if you want very detailed logs --\u0026gt; \u0026lt;verbose_logs\u0026gt;false\u0026lt;/verbose_logs\u0026gt; \u0026lt;/grpc\u0026gt; \u0026lt;!-- Used with https_port and tcp_port_secure. Full ssl options list: https://github.com/ClickHouse-Extras/poco/blob/master/NetSSL_OpenSSL/include/Poco/Net/SSLManager.h#L71 --\u0026gt; \u0026lt;openSSL\u0026gt; \u0026lt;server\u0026gt; \u0026lt;!-- Used for https server AND secure tcp port --\u0026gt; \u0026lt;!-- openssl req -subj \u0026#34;/CN=localhost\u0026#34; -new -newkey rsa:2048 -days 365 -nodes -x509 -keyout /etc/clickhouse-server/server.key -out /etc/clickhouse-server/server.crt --\u0026gt; \u0026lt;certificateFile\u0026gt;/etc/clickhouse-server/server.crt\u0026lt;/certificateFile\u0026gt; \u0026lt;privateKeyFile\u0026gt;/etc/clickhouse-server/server.key\u0026lt;/privateKeyFile\u0026gt; \u0026lt;!-- dhparams are optional. You can delete the \u0026lt;dhParamsFile\u0026gt; element. To generate dhparams, use the following command: openssl dhparam -out /etc/clickhouse-server/dhparam.pem 4096 Only file format with BEGIN DH PARAMETERS is supported. --\u0026gt; \u0026lt;dhParamsFile\u0026gt;/etc/clickhouse-server/dhparam.pem\u0026lt;/dhParamsFile\u0026gt; \u0026lt;verificationMode\u0026gt;none\u0026lt;/verificationMode\u0026gt; \u0026lt;loadDefaultCAFile\u0026gt;true\u0026lt;/loadDefaultCAFile\u0026gt; \u0026lt;cacheSessions\u0026gt;true\u0026lt;/cacheSessions\u0026gt; \u0026lt;disableProtocols\u0026gt;sslv2,sslv3\u0026lt;/disableProtocols\u0026gt; \u0026lt;preferServerCiphers\u0026gt;true\u0026lt;/preferServerCiphers\u0026gt; \u0026lt;/server\u0026gt; \u0026lt;client\u0026gt; \u0026lt;!-- Used for connecting to https dictionary source and secured Zookeeper communication --\u0026gt; \u0026lt;loadDefaultCAFile\u0026gt;true\u0026lt;/loadDefaultCAFile\u0026gt; \u0026lt;cacheSessions\u0026gt;true\u0026lt;/cacheSessions\u0026gt; \u0026lt;disableProtocols\u0026gt;sslv2,sslv3\u0026lt;/disableProtocols\u0026gt; \u0026lt;preferServerCiphers\u0026gt;true\u0026lt;/preferServerCiphers\u0026gt; \u0026lt;!-- Use for self-signed: \u0026lt;verificationMode\u0026gt;none\u0026lt;/verificationMode\u0026gt; --\u0026gt; \u0026lt;invalidCertificateHandler\u0026gt; \u0026lt;!-- Use for self-signed: \u0026lt;name\u0026gt;AcceptCertificateHandler\u0026lt;/name\u0026gt; --\u0026gt; \u0026lt;name\u0026gt;RejectCertificateHandler\u0026lt;/name\u0026gt; \u0026lt;/invalidCertificateHandler\u0026gt; \u0026lt;/client\u0026gt; \u0026lt;/openSSL\u0026gt; \u0026lt;!-- Default root page on http[s] server. For example load UI from https://tabix.io/ when opening http://localhost:8123 --\u0026gt; \u0026lt;!-- \u0026lt;http_server_default_response\u0026gt;\u0026lt;![CDATA[\u0026lt;html ng-app=\u0026#34;SMI2\u0026#34;\u0026gt;\u0026lt;head\u0026gt;\u0026lt;base href=\u0026#34;http://ui.tabix.io/\u0026#34;\u0026gt;\u0026lt;/head\u0026gt;\u0026lt;body\u0026gt;\u0026lt;div ui-view=\u0026#34;\u0026#34; class=\u0026#34;content-ui\u0026#34;\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;script src=\u0026#34;http://loader.tabix.io/master.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;]]\u0026gt;\u0026lt;/http_server_default_response\u0026gt; --\u0026gt; \u0026lt;!-- Maximum number of concurrent queries. --\u0026gt; \u0026lt;max_concurrent_queries\u0026gt;100\u0026lt;/max_concurrent_queries\u0026gt; \u0026lt;!-- Maximum memory usage (resident set size) for server process. Zero value or unset means default. Default is \u0026#34;max_server_memory_usage_to_ram_ratio\u0026#34; of available physical RAM. If the value is larger than \u0026#34;max_server_memory_usage_to_ram_ratio\u0026#34; of available physical RAM, it will be cut down. The constraint is checked on query execution time. If a query tries to allocate memory and the current memory usage plus allocation is greater than specified threshold, exception will be thrown. It is not practical to set this constraint to small values like just a few gigabytes, because memory allocator will keep this amount of memory in caches and the server will deny service of queries. --\u0026gt; \u0026lt;max_server_memory_usage\u0026gt;0\u0026lt;/max_server_memory_usage\u0026gt; \u0026lt;!-- Maximum number of threads in the Global thread pool. This will default to a maximum of 10000 threads if not specified. This setting will be useful in scenarios where there are a large number of distributed queries that are running concurrently but are idling most of the time, in which case a higher number of threads might be required. --\u0026gt; \u0026lt;max_thread_pool_size\u0026gt;10000\u0026lt;/max_thread_pool_size\u0026gt; \u0026lt;!-- Number of workers to recycle connections in background (see also drain_timeout). If the pool is full, connection will be drained synchronously. --\u0026gt; \u0026lt;!-- \u0026lt;max_threads_for_connection_collector\u0026gt;10\u0026lt;/max_threads_for_connection_collector\u0026gt; --\u0026gt; \u0026lt;!-- On memory constrained environments you may have to set this to value larger than 1. --\u0026gt; \u0026lt;max_server_memory_usage_to_ram_ratio\u0026gt;0.9\u0026lt;/max_server_memory_usage_to_ram_ratio\u0026gt; \u0026lt;!-- Simple server-wide memory profiler. Collect a stack trace at every peak allocation step (in bytes). Data will be stored in system.trace_log table with query_id = empty string. Zero means disabled. --\u0026gt; \u0026lt;total_memory_profiler_step\u0026gt;4194304\u0026lt;/total_memory_profiler_step\u0026gt; \u0026lt;!-- Collect random allocations and deallocations and write them into system.trace_log with \u0026#39;MemorySample\u0026#39; trace_type. The probability is for every alloc/free regardless to the size of the allocation. Note that sampling happens only when the amount of untracked memory exceeds the untracked memory limit, which is 4 MiB by default but can be lowered if \u0026#39;total_memory_profiler_step\u0026#39; is lowered. You may want to set \u0026#39;total_memory_profiler_step\u0026#39; to 1 for extra fine grained sampling. --\u0026gt; \u0026lt;total_memory_tracker_sample_probability\u0026gt;0\u0026lt;/total_memory_tracker_sample_probability\u0026gt; \u0026lt;!-- Set limit on number of open files (default: maximum). This setting makes sense on Mac OS X because getrlimit() fails to retrieve correct maximum value. --\u0026gt; \u0026lt;!-- \u0026lt;max_open_files\u0026gt;262144\u0026lt;/max_open_files\u0026gt; --\u0026gt; \u0026lt;!-- Size of cache of uncompressed blocks of data, used in tables of MergeTree family. In bytes. Cache is single for server. Memory is allocated only on demand. Cache is used when \u0026#39;use_uncompressed_cache\u0026#39; user setting turned on (off by default). Uncompressed cache is advantageous only for very short queries and in rare cases. Note: uncompressed cache can be pointless for lz4, because memory bandwidth is slower than multi-core decompression on some server configurations. Enabling it can sometimes paradoxically make queries slower. --\u0026gt; \u0026lt;uncompressed_cache_size\u0026gt;8589934592\u0026lt;/uncompressed_cache_size\u0026gt; \u0026lt;!-- Approximate size of mark cache, used in tables of MergeTree family. In bytes. Cache is single for server. Memory is allocated only on demand. You should not lower this value. --\u0026gt; \u0026lt;mark_cache_size\u0026gt;5368709120\u0026lt;/mark_cache_size\u0026gt; \u0026lt;!-- If you enable the `min_bytes_to_use_mmap_io` setting, the data in MergeTree tables can be read with mmap to avoid copying from kernel to userspace. It makes sense only for large files and helps only if data reside in page cache. To avoid frequent open/mmap/munmap/close calls (which are very expensive due to consequent page faults) and to reuse mappings from several threads and queries, the cache of mapped files is maintained. Its size is the number of mapped regions (usually equal to the number of mapped files). The amount of data in mapped files can be monitored in system.metrics, system.metric_log by the MMappedFiles, MMappedFileBytes metrics and in system.asynchronous_metrics, system.asynchronous_metrics_log by the MMapCacheCells metric, and also in system.events, system.processes, system.query_log, system.query_thread_log, system.query_views_log by the CreatedReadBufferMMap, CreatedReadBufferMMapFailed, MMappedFileCacheHits, MMappedFileCacheMisses events. Note that the amount of data in mapped files does not consume memory directly and is not accounted in query or server memory usage - because this memory can be discarded similar to OS page cache. The cache is dropped (the files are closed) automatically on removal of old parts in MergeTree, also it can be dropped manually by the SYSTEM DROP MMAP CACHE query. --\u0026gt; \u0026lt;mmap_cache_size\u0026gt;1000\u0026lt;/mmap_cache_size\u0026gt; \u0026lt;!-- Cache size in bytes for compiled expressions.--\u0026gt; \u0026lt;compiled_expression_cache_size\u0026gt;134217728\u0026lt;/compiled_expression_cache_size\u0026gt; \u0026lt;!-- Cache size in elements for compiled expressions.--\u0026gt; \u0026lt;compiled_expression_cache_elements_size\u0026gt;10000\u0026lt;/compiled_expression_cache_elements_size\u0026gt; \u0026lt;!-- Path to data directory, with trailing slash. --\u0026gt; \u0026lt;path\u0026gt;/var/lib/clickhouse/\u0026lt;/path\u0026gt; \u0026lt;!-- Path to temporary data for processing hard queries. --\u0026gt; \u0026lt;tmp_path\u0026gt;/var/lib/clickhouse/tmp/\u0026lt;/tmp_path\u0026gt; \u0026lt;!-- Policy from the \u0026lt;storage_configuration\u0026gt; for the temporary files. If not set \u0026lt;tmp_path\u0026gt; is used, otherwise \u0026lt;tmp_path\u0026gt; is ignored. Notes: - move_factor is ignored - keep_free_space_bytes is ignored - max_data_part_size_bytes is ignored - you must have exactly one volume in that policy --\u0026gt; \u0026lt;!-- \u0026lt;tmp_policy\u0026gt;tmp\u0026lt;/tmp_policy\u0026gt; --\u0026gt; \u0026lt;!-- Directory with user provided files that are accessible by \u0026#39;file\u0026#39; table function. --\u0026gt; \u0026lt;user_files_path\u0026gt;/var/lib/clickhouse/user_files/\u0026lt;/user_files_path\u0026gt; \u0026lt;!-- LDAP server definitions. --\u0026gt; \u0026lt;ldap_servers\u0026gt; \u0026lt;!-- List LDAP servers with their connection parameters here to later 1) use them as authenticators for dedicated local users, who have \u0026#39;ldap\u0026#39; authentication mechanism specified instead of \u0026#39;password\u0026#39;, or to 2) use them as remote user directories. Parameters: host - LDAP server hostname or IP, this parameter is mandatory and cannot be empty. port - LDAP server port, default is 636 if enable_tls is set to true, 389 otherwise. bind_dn - template used to construct the DN to bind to. The resulting DN will be constructed by replacing all \u0026#39;{user_name}\u0026#39; substrings of the template with the actual user name during each authentication attempt. user_dn_detection - section with LDAP search parameters for detecting the actual user DN of the bound user. This is mainly used in search filters for further role mapping when the server is Active Directory. The resulting user DN will be used when replacing \u0026#39;{user_dn}\u0026#39; substrings wherever they are allowed. By default, user DN is set equal to bind DN, but once search is performed, it will be updated with to the actual detected user DN value. base_dn - template used to construct the base DN for the LDAP search. The resulting DN will be constructed by replacing all \u0026#39;{user_name}\u0026#39; and \u0026#39;{bind_dn}\u0026#39; substrings of the template with the actual user name and bind DN during the LDAP search. scope - scope of the LDAP search. Accepted values are: \u0026#39;base\u0026#39;, \u0026#39;one_level\u0026#39;, \u0026#39;children\u0026#39;, \u0026#39;subtree\u0026#39; (the default). search_filter - template used to construct the search filter for the LDAP search. The resulting filter will be constructed by replacing all \u0026#39;{user_name}\u0026#39;, \u0026#39;{bind_dn}\u0026#39;, and \u0026#39;{base_dn}\u0026#39; substrings of the template with the actual user name, bind DN, and base DN during the LDAP search. Note, that the special characters must be escaped properly in XML. verification_cooldown - a period of time, in seconds, after a successful bind attempt, during which a user will be assumed to be successfully authenticated for all consecutive requests without contacting the LDAP server. Specify 0 (the default) to disable caching and force contacting the LDAP server for each authentication request. enable_tls - flag to trigger use of secure connection to the LDAP server. Specify \u0026#39;no\u0026#39; for plain text (ldap://) protocol (not recommended). Specify \u0026#39;yes\u0026#39; for LDAP over SSL/TLS (ldaps://) protocol (recommended, the default). Specify \u0026#39;starttls\u0026#39; for legacy StartTLS protocol (plain text (ldap://) protocol, upgraded to TLS). tls_minimum_protocol_version - the minimum protocol version of SSL/TLS. Accepted values are: \u0026#39;ssl2\u0026#39;, \u0026#39;ssl3\u0026#39;, \u0026#39;tls1.0\u0026#39;, \u0026#39;tls1.1\u0026#39;, \u0026#39;tls1.2\u0026#39; (the default). tls_require_cert - SSL/TLS peer certificate verification behavior. Accepted values are: \u0026#39;never\u0026#39;, \u0026#39;allow\u0026#39;, \u0026#39;try\u0026#39;, \u0026#39;demand\u0026#39; (the default). tls_cert_file - path to certificate file. tls_key_file - path to certificate key file. tls_ca_cert_file - path to CA certificate file. tls_ca_cert_dir - path to the directory containing CA certificates. tls_cipher_suite - allowed cipher suite (in OpenSSL notation). Example: \u0026lt;my_ldap_server\u0026gt; \u0026lt;host\u0026gt;localhost\u0026lt;/host\u0026gt; \u0026lt;port\u0026gt;636\u0026lt;/port\u0026gt; \u0026lt;bind_dn\u0026gt;uid={user_name},ou=users,dc=example,dc=com\u0026lt;/bind_dn\u0026gt; \u0026lt;verification_cooldown\u0026gt;300\u0026lt;/verification_cooldown\u0026gt; \u0026lt;enable_tls\u0026gt;yes\u0026lt;/enable_tls\u0026gt; \u0026lt;tls_minimum_protocol_version\u0026gt;tls1.2\u0026lt;/tls_minimum_protocol_version\u0026gt; \u0026lt;tls_require_cert\u0026gt;demand\u0026lt;/tls_require_cert\u0026gt; \u0026lt;tls_cert_file\u0026gt;/path/to/tls_cert_file\u0026lt;/tls_cert_file\u0026gt; \u0026lt;tls_key_file\u0026gt;/path/to/tls_key_file\u0026lt;/tls_key_file\u0026gt; \u0026lt;tls_ca_cert_file\u0026gt;/path/to/tls_ca_cert_file\u0026lt;/tls_ca_cert_file\u0026gt; \u0026lt;tls_ca_cert_dir\u0026gt;/path/to/tls_ca_cert_dir\u0026lt;/tls_ca_cert_dir\u0026gt; \u0026lt;tls_cipher_suite\u0026gt;ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:AES256-GCM-SHA384\u0026lt;/tls_cipher_suite\u0026gt; \u0026lt;/my_ldap_server\u0026gt; Example (typical Active Directory with configured user DN detection for further role mapping): \u0026lt;my_ad_server\u0026gt; \u0026lt;host\u0026gt;localhost\u0026lt;/host\u0026gt; \u0026lt;port\u0026gt;389\u0026lt;/port\u0026gt; \u0026lt;bind_dn\u0026gt;EXAMPLE\\{user_name}\u0026lt;/bind_dn\u0026gt; \u0026lt;user_dn_detection\u0026gt; \u0026lt;base_dn\u0026gt;CN=Users,DC=example,DC=com\u0026lt;/base_dn\u0026gt; \u0026lt;search_filter\u0026gt;(\u0026amp;amp;(objectClass=user)(sAMAccountName={user_name}))\u0026lt;/search_filter\u0026gt; \u0026lt;/user_dn_detection\u0026gt; \u0026lt;enable_tls\u0026gt;no\u0026lt;/enable_tls\u0026gt; \u0026lt;/my_ad_server\u0026gt; --\u0026gt; \u0026lt;/ldap_servers\u0026gt; \u0026lt;!-- To enable Kerberos authentication support for HTTP requests (GSS-SPNEGO), for those users who are explicitly configured to authenticate via Kerberos, define a single \u0026#39;kerberos\u0026#39; section here. Parameters: principal - canonical service principal name, that will be acquired and used when accepting security contexts. This parameter is optional, if omitted, the default principal will be used. This parameter cannot be specified together with \u0026#39;realm\u0026#39; parameter. realm - a realm, that will be used to restrict authentication to only those requests whose initiator\u0026#39;s realm matches it. This parameter is optional, if omitted, no additional filtering by realm will be applied. This parameter cannot be specified together with \u0026#39;principal\u0026#39; parameter. Example: \u0026lt;kerberos /\u0026gt; Example: \u0026lt;kerberos\u0026gt; \u0026lt;principal\u0026gt;HTTP/clickhouse.example.com@EXAMPLE.COM\u0026lt;/principal\u0026gt; \u0026lt;/kerberos\u0026gt; Example: \u0026lt;kerberos\u0026gt; \u0026lt;realm\u0026gt;EXAMPLE.COM\u0026lt;/realm\u0026gt; \u0026lt;/kerberos\u0026gt; --\u0026gt; \u0026lt;!-- Sources to read users, roles, access rights, profiles of settings, quotas. --\u0026gt; \u0026lt;user_directories\u0026gt; \u0026lt;users_xml\u0026gt; \u0026lt;!-- Path to configuration file with predefined users. --\u0026gt; \u0026lt;path\u0026gt;users.xml\u0026lt;/path\u0026gt; \u0026lt;/users_xml\u0026gt; \u0026lt;local_directory\u0026gt; \u0026lt;!-- Path to folder where users created by SQL commands are stored. --\u0026gt; \u0026lt;path\u0026gt;/var/lib/clickhouse/access/\u0026lt;/path\u0026gt; \u0026lt;/local_directory\u0026gt; \u0026lt;!-- To add an LDAP server as a remote user directory of users that are not defined locally, define a single \u0026#39;ldap\u0026#39; section with the following parameters: server - one of LDAP server names defined in \u0026#39;ldap_servers\u0026#39; config section above. This parameter is mandatory and cannot be empty. roles - section with a list of locally defined roles that will be assigned to each user retrieved from the LDAP server. If no roles are specified here or assigned during role mapping (below), user will not be able to perform any actions after authentication. role_mapping - section with LDAP search parameters and mapping rules. When a user authenticates, while still bound to LDAP, an LDAP search is performed using search_filter and the name of the logged in user. For each entry found during that search, the value of the specified attribute is extracted. For each attribute value that has the specified prefix, the prefix is removed, and the rest of the value becomes the name of a local role defined in ClickHouse, which is expected to be created beforehand by CREATE ROLE command. There can be multiple \u0026#39;role_mapping\u0026#39; sections defined inside the same \u0026#39;ldap\u0026#39; section. All of them will be applied. base_dn - template used to construct the base DN for the LDAP search. The resulting DN will be constructed by replacing all \u0026#39;{user_name}\u0026#39;, \u0026#39;{bind_dn}\u0026#39;, and \u0026#39;{user_dn}\u0026#39; substrings of the template with the actual user name, bind DN, and user DN during each LDAP search. scope - scope of the LDAP search. Accepted values are: \u0026#39;base\u0026#39;, \u0026#39;one_level\u0026#39;, \u0026#39;children\u0026#39;, \u0026#39;subtree\u0026#39; (the default). search_filter - template used to construct the search filter for the LDAP search. The resulting filter will be constructed by replacing all \u0026#39;{user_name}\u0026#39;, \u0026#39;{bind_dn}\u0026#39;, \u0026#39;{user_dn}\u0026#39;, and \u0026#39;{base_dn}\u0026#39; substrings of the template with the actual user name, bind DN, user DN, and base DN during each LDAP search. Note, that the special characters must be escaped properly in XML. attribute - attribute name whose values will be returned by the LDAP search. \u0026#39;cn\u0026#39;, by default. prefix - prefix, that will be expected to be in front of each string in the original list of strings returned by the LDAP search. Prefix will be removed from the original strings and resulting strings will be treated as local role names. Empty, by default. Example: \u0026lt;ldap\u0026gt; \u0026lt;server\u0026gt;my_ldap_server\u0026lt;/server\u0026gt; \u0026lt;roles\u0026gt; \u0026lt;my_local_role1 /\u0026gt; \u0026lt;my_local_role2 /\u0026gt; \u0026lt;/roles\u0026gt; \u0026lt;role_mapping\u0026gt; \u0026lt;base_dn\u0026gt;ou=groups,dc=example,dc=com\u0026lt;/base_dn\u0026gt; \u0026lt;scope\u0026gt;subtree\u0026lt;/scope\u0026gt; \u0026lt;search_filter\u0026gt;(\u0026amp;amp;(objectClass=groupOfNames)(member={bind_dn}))\u0026lt;/search_filter\u0026gt; \u0026lt;attribute\u0026gt;cn\u0026lt;/attribute\u0026gt; \u0026lt;prefix\u0026gt;clickhouse_\u0026lt;/prefix\u0026gt; \u0026lt;/role_mapping\u0026gt; \u0026lt;/ldap\u0026gt; Example (typical Active Directory with role mapping that relies on the detected user DN): \u0026lt;ldap\u0026gt; \u0026lt;server\u0026gt;my_ad_server\u0026lt;/server\u0026gt; \u0026lt;role_mapping\u0026gt; \u0026lt;base_dn\u0026gt;CN=Users,DC=example,DC=com\u0026lt;/base_dn\u0026gt; \u0026lt;attribute\u0026gt;CN\u0026lt;/attribute\u0026gt; \u0026lt;scope\u0026gt;subtree\u0026lt;/scope\u0026gt; \u0026lt;search_filter\u0026gt;(\u0026amp;amp;(objectClass=group)(member={user_dn}))\u0026lt;/search_filter\u0026gt; \u0026lt;prefix\u0026gt;clickhouse_\u0026lt;/prefix\u0026gt; \u0026lt;/role_mapping\u0026gt; \u0026lt;/ldap\u0026gt; --\u0026gt; \u0026lt;/user_directories\u0026gt; \u0026lt;!-- Default profile of settings. --\u0026gt; \u0026lt;default_profile\u0026gt;default\u0026lt;/default_profile\u0026gt; \u0026lt;!-- Comma-separated list of prefixes for user-defined settings. --\u0026gt; \u0026lt;custom_settings_prefixes\u0026gt;\u0026lt;/custom_settings_prefixes\u0026gt; \u0026lt;!-- System profile of settings. This settings are used by internal processes (Distributed DDL worker and so on). --\u0026gt; \u0026lt;!-- \u0026lt;system_profile\u0026gt;default\u0026lt;/system_profile\u0026gt; --\u0026gt; \u0026lt;!-- Buffer profile of settings. This settings are used by Buffer storage to flush data to the underlying table. Default: used from system_profile directive. --\u0026gt; \u0026lt;!-- \u0026lt;buffer_profile\u0026gt;default\u0026lt;/buffer_profile\u0026gt; --\u0026gt; \u0026lt;!-- Default database. --\u0026gt; \u0026lt;default_database\u0026gt;default\u0026lt;/default_database\u0026gt; \u0026lt;!-- Server time zone could be set here. Time zone is used when converting between String and DateTime types, when printing DateTime in text formats and parsing DateTime from text, it is used in date and time related functions, if specific time zone was not passed as an argument. Time zone is specified as identifier from IANA time zone database, like UTC or Africa/Abidjan. If not specified, system time zone at server startup is used. Please note, that server could display time zone alias instead of specified name. Example: W-SU is an alias for Europe/Moscow and Zulu is an alias for UTC. --\u0026gt; \u0026lt;!-- \u0026lt;timezone\u0026gt;Europe/Moscow\u0026lt;/timezone\u0026gt; --\u0026gt; \u0026lt;!-- You can specify umask here (see \u0026#34;man umask\u0026#34;). Server will apply it on startup. Number is always parsed as octal. Default umask is 027 (other users cannot read logs, data files, etc; group can only read). --\u0026gt; \u0026lt;!-- \u0026lt;umask\u0026gt;022\u0026lt;/umask\u0026gt; --\u0026gt; \u0026lt;!-- Perform mlockall after startup to lower first queries latency and to prevent clickhouse executable from being paged out under high IO load. Enabling this option is recommended but will lead to increased startup time for up to a few seconds. --\u0026gt; \u0026lt;mlock_executable\u0026gt;true\u0026lt;/mlock_executable\u0026gt; \u0026lt;!-- Reallocate memory for machine code (\u0026#34;text\u0026#34;) using huge pages. Highly experimental. --\u0026gt; \u0026lt;remap_executable\u0026gt;false\u0026lt;/remap_executable\u0026gt; \u0026lt;![CDATA[ Uncomment below in order to use JDBC table engine and function. To install and run JDBC bridge in background: * [Debian/Ubuntu] export MVN_URL=https://repo1.maven.org/maven2/ru/yandex/clickhouse/clickhouse-jdbc-bridge export PKG_VER=$(curl -sL $MVN_URL/maven-metadata.xml | grep \u0026#39;\u0026lt;release\u0026gt;\u0026#39; | sed -e \u0026#39;s|.*\u0026gt;\\(.*\\)\u0026lt;.*|\\1|\u0026#39;) wget https://github.com/ClickHouse/clickhouse-jdbc-bridge/releases/download/v$PKG_VER/clickhouse-jdbc-bridge_$PKG_VER-1_all.deb apt install --no-install-recommends -f ./clickhouse-jdbc-bridge_$PKG_VER-1_all.deb clickhouse-jdbc-bridge \u0026amp; * [CentOS/RHEL] export MVN_URL=https://repo1.maven.org/maven2/ru/yandex/clickhouse/clickhouse-jdbc-bridge export PKG_VER=$(curl -sL $MVN_URL/maven-metadata.xml | grep \u0026#39;\u0026lt;release\u0026gt;\u0026#39; | sed -e \u0026#39;s|.*\u0026gt;\\(.*\\)\u0026lt;.*|\\1|\u0026#39;) wget https://github.com/ClickHouse/clickhouse-jdbc-bridge/releases/download/v$PKG_VER/clickhouse-jdbc-bridge-$PKG_VER-1.noarch.rpm yum localinstall -y clickhouse-jdbc-bridge-$PKG_VER-1.noarch.rpm clickhouse-jdbc-bridge \u0026amp; Please refer to https://github.com/ClickHouse/clickhouse-jdbc-bridge#usage for more information. ]]\u0026gt; \u0026lt;!-- \u0026lt;jdbc_bridge\u0026gt; \u0026lt;host\u0026gt;127.0.0.1\u0026lt;/host\u0026gt; \u0026lt;port\u0026gt;9019\u0026lt;/port\u0026gt; \u0026lt;/jdbc_bridge\u0026gt; --\u0026gt; \u0026lt;!-- Configuration of clusters that could be used in Distributed tables. https://clickhouse.com/docs/en/operations/table_engines/distributed/ --\u0026gt; \u0026lt;remote_servers\u0026gt; \u0026lt;default_cluster\u0026gt; \u0026lt;shard\u0026gt; \u0026lt;weight\u0026gt;1\u0026lt;/weight\u0026gt; \u0026lt;internal_replication\u0026gt;false\u0026lt;/internal_replication\u0026gt; \u0026lt;replica\u0026gt; \u0026lt;host\u0026gt;ck1\u0026lt;/host\u0026gt; \u0026lt;port\u0026gt;9000\u0026lt;/port\u0026gt; \u0026lt;/replica\u0026gt; \u0026lt;/shard\u0026gt; \u0026lt;shard\u0026gt; \u0026lt;weight\u0026gt;1\u0026lt;/weight\u0026gt; \u0026lt;internal_replication\u0026gt;false\u0026lt;/internal_replication\u0026gt; \u0026lt;replica\u0026gt; \u0026lt;host\u0026gt;ck2\u0026lt;/host\u0026gt; \u0026lt;port\u0026gt;9000\u0026lt;/port\u0026gt; \u0026lt;/replica\u0026gt; \u0026lt;/shard\u0026gt; \u0026lt;shard\u0026gt; \u0026lt;weight\u0026gt;1\u0026lt;/weight\u0026gt; \u0026lt;internal_replication\u0026gt;false\u0026lt;/internal_replication\u0026gt; \u0026lt;replica\u0026gt; \u0026lt;host\u0026gt;ck3\u0026lt;/host\u0026gt; \u0026lt;port\u0026gt;9000\u0026lt;/port\u0026gt; \u0026lt;/replica\u0026gt; \u0026lt;/shard\u0026gt; \u0026lt;/default_cluster\u0026gt; \u0026lt;/remote_servers\u0026gt; \u0026lt;macros\u0026gt; \u0026lt;replica\u0026gt;ck1\u0026lt;/replica\u0026gt; \u0026lt;shard\u0026gt;01\u0026lt;/shard\u0026gt; \u0026lt;layer\u0026gt;01\u0026lt;/layer\u0026gt; \u0026lt;/macros\u0026gt; \u0026lt;!-- The list of hosts allowed to use in URL-related storage engines and table functions. If this section is not present in configuration, all hosts are allowed. --\u0026gt; \u0026lt;!--\u0026lt;remote_url_allow_hosts\u0026gt;--\u0026gt; \u0026lt;!-- Host should be specified exactly as in URL. The name is checked before DNS resolution. Example: \u0026#34;yandex.ru\u0026#34;, \u0026#34;yandex.ru.\u0026#34; and \u0026#34;www.yandex.ru\u0026#34; are different hosts. If port is explicitly specified in URL, the host:port is checked as a whole. If host specified here without port, any port with this host allowed. \u0026#34;yandex.ru\u0026#34; -\u0026gt; \u0026#34;yandex.ru:443\u0026#34;, \u0026#34;yandex.ru:80\u0026#34; etc. is allowed, but \u0026#34;yandex.ru:80\u0026#34; -\u0026gt; only \u0026#34;yandex.ru:80\u0026#34; is allowed. If the host is specified as IP address, it is checked as specified in URL. Example: \u0026#34;[2a02:6b8:a::a]\u0026#34;. If there are redirects and support for redirects is enabled, every redirect (the Location field) is checked. Host should be specified using the host xml tag: \u0026lt;host\u0026gt;yandex.ru\u0026lt;/host\u0026gt; --\u0026gt; \u0026lt;!-- Regular expression can be specified. RE2 engine is used for regexps. Regexps are not aligned: don\u0026#39;t forget to add ^ and $. Also don\u0026#39;t forget to escape dot (.) metacharacter (forgetting to do so is a common source of error). --\u0026gt; \u0026lt;!--\u0026lt;/remote_url_allow_hosts\u0026gt;--\u0026gt; \u0026lt;!-- If element has \u0026#39;incl\u0026#39; attribute, then for it\u0026#39;s value will be used corresponding substitution from another file. By default, path to file with substitutions is /etc/metrika.xml. It could be changed in config in \u0026#39;include_from\u0026#39; element. Values for substitutions are specified in /clickhouse/name_of_substitution elements in that file. --\u0026gt; \u0026lt;!-- ZooKeeper is used to store metadata about replicas, when using Replicated tables. Optional. If you don\u0026#39;t use replicated tables, you could omit that. See https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/replication/ --\u0026gt; \u0026lt;zookeeper\u0026gt; \u0026lt;node\u0026gt; \u0026lt;host\u0026gt;zookeeper1\u0026lt;/host\u0026gt; \u0026lt;port\u0026gt;2181\u0026lt;/port\u0026gt; \u0026lt;/node\u0026gt; \u0026lt;/zookeeper\u0026gt; \u0026lt;!-- Substitutions for parameters of replicated tables. Optional. If you don\u0026#39;t use replicated tables, you could omit that. See https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/replication/#creating-replicated-tables --\u0026gt; \u0026lt;!-- \u0026lt;macros\u0026gt; \u0026lt;shard\u0026gt;01\u0026lt;/shard\u0026gt; \u0026lt;replica\u0026gt;example01-01-1\u0026lt;/replica\u0026gt; \u0026lt;/macros\u0026gt; --\u0026gt; \u0026lt;!-- Reloading interval for embedded dictionaries, in seconds. Default: 3600. --\u0026gt; \u0026lt;builtin_dictionaries_reload_interval\u0026gt;3600\u0026lt;/builtin_dictionaries_reload_interval\u0026gt; \u0026lt;!-- Maximum session timeout, in seconds. Default: 3600. --\u0026gt; \u0026lt;max_session_timeout\u0026gt;3600\u0026lt;/max_session_timeout\u0026gt; \u0026lt;!-- Default session timeout, in seconds. Default: 60. --\u0026gt; \u0026lt;default_session_timeout\u0026gt;60\u0026lt;/default_session_timeout\u0026gt; \u0026lt;!-- Sending data to Graphite for monitoring. Several sections can be defined. --\u0026gt; \u0026lt;!-- interval - send every X second root_path - prefix for keys hostname_in_path - append hostname to root_path (default = true) metrics - send data from table system.metrics events - send data from table system.events asynchronous_metrics - send data from table system.asynchronous_metrics --\u0026gt; \u0026lt;!-- \u0026lt;graphite\u0026gt; \u0026lt;host\u0026gt;localhost\u0026lt;/host\u0026gt; \u0026lt;port\u0026gt;42000\u0026lt;/port\u0026gt; \u0026lt;timeout\u0026gt;0.1\u0026lt;/timeout\u0026gt; \u0026lt;interval\u0026gt;60\u0026lt;/interval\u0026gt; \u0026lt;root_path\u0026gt;one_min\u0026lt;/root_path\u0026gt; \u0026lt;hostname_in_path\u0026gt;true\u0026lt;/hostname_in_path\u0026gt; \u0026lt;metrics\u0026gt;true\u0026lt;/metrics\u0026gt; \u0026lt;events\u0026gt;true\u0026lt;/events\u0026gt; \u0026lt;events_cumulative\u0026gt;false\u0026lt;/events_cumulative\u0026gt; \u0026lt;asynchronous_metrics\u0026gt;true\u0026lt;/asynchronous_metrics\u0026gt; \u0026lt;/graphite\u0026gt; \u0026lt;graphite\u0026gt; \u0026lt;host\u0026gt;localhost\u0026lt;/host\u0026gt; \u0026lt;port\u0026gt;42000\u0026lt;/port\u0026gt; \u0026lt;timeout\u0026gt;0.1\u0026lt;/timeout\u0026gt; \u0026lt;interval\u0026gt;1\u0026lt;/interval\u0026gt; \u0026lt;root_path\u0026gt;one_sec\u0026lt;/root_path\u0026gt; \u0026lt;metrics\u0026gt;true\u0026lt;/metrics\u0026gt; \u0026lt;events\u0026gt;true\u0026lt;/events\u0026gt; \u0026lt;events_cumulative\u0026gt;false\u0026lt;/events_cumulative\u0026gt; \u0026lt;asynchronous_metrics\u0026gt;false\u0026lt;/asynchronous_metrics\u0026gt; \u0026lt;/graphite\u0026gt; --\u0026gt; \u0026lt;!-- Serve endpoint for Prometheus monitoring. --\u0026gt; \u0026lt;!-- endpoint - mertics path (relative to root, statring with \u0026#34;/\u0026#34;) port - port to setup server. If not defined or 0 than http_port used metrics - send data from table system.metrics events - send data from table system.events asynchronous_metrics - send data from table system.asynchronous_metrics status_info - send data from different component from CH, ex: Dictionaries status --\u0026gt; \u0026lt;!-- \u0026lt;prometheus\u0026gt; \u0026lt;endpoint\u0026gt;/metrics\u0026lt;/endpoint\u0026gt; \u0026lt;port\u0026gt;9363\u0026lt;/port\u0026gt; \u0026lt;metrics\u0026gt;true\u0026lt;/metrics\u0026gt; \u0026lt;events\u0026gt;true\u0026lt;/events\u0026gt; \u0026lt;asynchronous_metrics\u0026gt;true\u0026lt;/asynchronous_metrics\u0026gt; \u0026lt;status_info\u0026gt;true\u0026lt;/status_info\u0026gt; \u0026lt;/prometheus\u0026gt; --\u0026gt; \u0026lt;!-- Query log. Used only for queries with setting log_queries = 1. --\u0026gt; \u0026lt;query_log\u0026gt; \u0026lt;!-- What table to insert data. If table is not exist, it will be created. When query log structure is changed after system update, then old table will be renamed and new table will be created automatically. --\u0026gt; \u0026lt;database\u0026gt;system\u0026lt;/database\u0026gt; \u0026lt;table\u0026gt;query_log\u0026lt;/table\u0026gt; \u0026lt;!-- PARTITION BY expr: https://clickhouse.com/docs/en/table_engines/mergetree-family/custom_partitioning_key/ Example: event_date toMonday(event_date) toYYYYMM(event_date) toStartOfHour(event_time) --\u0026gt; \u0026lt;partition_by\u0026gt;toYYYYMM(event_date)\u0026lt;/partition_by\u0026gt; \u0026lt;!-- Table TTL specification: https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/mergetree/#mergetree-table-ttl Example: event_date + INTERVAL 1 WEEK event_date + INTERVAL 7 DAY DELETE event_date + INTERVAL 2 WEEK TO DISK \u0026#39;bbb\u0026#39; \u0026lt;ttl\u0026gt;event_date + INTERVAL 30 DAY DELETE\u0026lt;/ttl\u0026gt; --\u0026gt; \u0026lt;!-- Instead of partition_by, you can provide full engine expression (starting with ENGINE = ) with parameters, Example: \u0026lt;engine\u0026gt;ENGINE = MergeTree PARTITION BY toYYYYMM(event_date) ORDER BY (event_date, event_time) SETTINGS index_granularity = 1024\u0026lt;/engine\u0026gt; --\u0026gt; \u0026lt;!-- Interval of flushing data. --\u0026gt; \u0026lt;flush_interval_milliseconds\u0026gt;7500\u0026lt;/flush_interval_milliseconds\u0026gt; \u0026lt;/query_log\u0026gt; \u0026lt;!-- Trace log. Stores stack traces collected by query profilers. See query_profiler_real_time_period_ns and query_profiler_cpu_time_period_ns settings. --\u0026gt; \u0026lt;trace_log\u0026gt; \u0026lt;database\u0026gt;system\u0026lt;/database\u0026gt; \u0026lt;table\u0026gt;trace_log\u0026lt;/table\u0026gt; \u0026lt;partition_by\u0026gt;toYYYYMM(event_date)\u0026lt;/partition_by\u0026gt; \u0026lt;flush_interval_milliseconds\u0026gt;7500\u0026lt;/flush_interval_milliseconds\u0026gt; \u0026lt;/trace_log\u0026gt; \u0026lt;!-- Query thread log. Has information about all threads participated in query execution. Used only for queries with setting log_query_threads = 1. --\u0026gt; \u0026lt;query_thread_log\u0026gt; \u0026lt;database\u0026gt;system\u0026lt;/database\u0026gt; \u0026lt;table\u0026gt;query_thread_log\u0026lt;/table\u0026gt; \u0026lt;partition_by\u0026gt;toYYYYMM(event_date)\u0026lt;/partition_by\u0026gt; \u0026lt;flush_interval_milliseconds\u0026gt;7500\u0026lt;/flush_interval_milliseconds\u0026gt; \u0026lt;/query_thread_log\u0026gt; \u0026lt;!-- Query views log. Has information about all dependent views associated with a query. Used only for queries with setting log_query_views = 1. --\u0026gt; \u0026lt;query_views_log\u0026gt; \u0026lt;database\u0026gt;system\u0026lt;/database\u0026gt; \u0026lt;table\u0026gt;query_views_log\u0026lt;/table\u0026gt; \u0026lt;partition_by\u0026gt;toYYYYMM(event_date)\u0026lt;/partition_by\u0026gt; \u0026lt;flush_interval_milliseconds\u0026gt;7500\u0026lt;/flush_interval_milliseconds\u0026gt; \u0026lt;/query_views_log\u0026gt; \u0026lt;!-- Uncomment if use part log. Part log contains information about all actions with parts in MergeTree tables (creation, deletion, merges, downloads).--\u0026gt; \u0026lt;part_log\u0026gt; \u0026lt;database\u0026gt;system\u0026lt;/database\u0026gt; \u0026lt;table\u0026gt;part_log\u0026lt;/table\u0026gt; \u0026lt;partition_by\u0026gt;toYYYYMM(event_date)\u0026lt;/partition_by\u0026gt; \u0026lt;flush_interval_milliseconds\u0026gt;7500\u0026lt;/flush_interval_milliseconds\u0026gt; \u0026lt;/part_log\u0026gt; \u0026lt;!-- Uncomment to write text log into table. Text log contains all information from usual server log but stores it in structured and efficient way. The level of the messages that goes to the table can be limited (\u0026lt;level\u0026gt;), if not specified all messages will go to the table. \u0026lt;text_log\u0026gt; \u0026lt;database\u0026gt;system\u0026lt;/database\u0026gt; \u0026lt;table\u0026gt;text_log\u0026lt;/table\u0026gt; \u0026lt;flush_interval_milliseconds\u0026gt;7500\u0026lt;/flush_interval_milliseconds\u0026gt; \u0026lt;level\u0026gt;\u0026lt;/level\u0026gt; \u0026lt;/text_log\u0026gt; --\u0026gt; \u0026lt;!-- Metric log contains rows with current values of ProfileEvents, CurrentMetrics collected with \u0026#34;collect_interval_milliseconds\u0026#34; interval. --\u0026gt; \u0026lt;metric_log\u0026gt; \u0026lt;database\u0026gt;system\u0026lt;/database\u0026gt; \u0026lt;table\u0026gt;metric_log\u0026lt;/table\u0026gt; \u0026lt;flush_interval_milliseconds\u0026gt;7500\u0026lt;/flush_interval_milliseconds\u0026gt; \u0026lt;collect_interval_milliseconds\u0026gt;1000\u0026lt;/collect_interval_milliseconds\u0026gt; \u0026lt;/metric_log\u0026gt; \u0026lt;!-- Asynchronous metric log contains values of metrics from system.asynchronous_metrics. --\u0026gt; \u0026lt;asynchronous_metric_log\u0026gt; \u0026lt;database\u0026gt;system\u0026lt;/database\u0026gt; \u0026lt;table\u0026gt;asynchronous_metric_log\u0026lt;/table\u0026gt; \u0026lt;!-- Asynchronous metrics are updated once a minute, so there is no need to flush more often. --\u0026gt; \u0026lt;flush_interval_milliseconds\u0026gt;7000\u0026lt;/flush_interval_milliseconds\u0026gt; \u0026lt;/asynchronous_metric_log\u0026gt; \u0026lt;!-- OpenTelemetry log contains OpenTelemetry trace spans. --\u0026gt; \u0026lt;opentelemetry_span_log\u0026gt; \u0026lt;!-- The default table creation code is insufficient, this \u0026lt;engine\u0026gt; spec is a workaround. There is no \u0026#39;event_time\u0026#39; for this log, but two times, start and finish. It is sorted by finish time, to avoid inserting data too far away in the past (probably we can sometimes insert a span that is seconds earlier than the last span in the table, due to a race between several spans inserted in parallel). This gives the spans a global order that we can use to e.g. retry insertion into some external system. --\u0026gt; \u0026lt;engine\u0026gt; engine MergeTree partition by toYYYYMM(finish_date) order by (finish_date, finish_time_us, trace_id) \u0026lt;/engine\u0026gt; \u0026lt;database\u0026gt;system\u0026lt;/database\u0026gt; \u0026lt;table\u0026gt;opentelemetry_span_log\u0026lt;/table\u0026gt; \u0026lt;flush_interval_milliseconds\u0026gt;7500\u0026lt;/flush_interval_milliseconds\u0026gt; \u0026lt;/opentelemetry_span_log\u0026gt; \u0026lt;!-- Crash log. Stores stack traces for fatal errors. This table is normally empty. --\u0026gt; \u0026lt;crash_log\u0026gt; \u0026lt;database\u0026gt;system\u0026lt;/database\u0026gt; \u0026lt;table\u0026gt;crash_log\u0026lt;/table\u0026gt; \u0026lt;partition_by/\u0026gt; \u0026lt;flush_interval_milliseconds\u0026gt;1000\u0026lt;/flush_interval_milliseconds\u0026gt; \u0026lt;/crash_log\u0026gt; \u0026lt;!-- Session log. Stores user log in (successful or not) and log out events. --\u0026gt; \u0026lt;session_log\u0026gt; \u0026lt;database\u0026gt;system\u0026lt;/database\u0026gt; \u0026lt;table\u0026gt;session_log\u0026lt;/table\u0026gt; \u0026lt;partition_by\u0026gt;toYYYYMM(event_date)\u0026lt;/partition_by\u0026gt; \u0026lt;flush_interval_milliseconds\u0026gt;7500\u0026lt;/flush_interval_milliseconds\u0026gt; \u0026lt;/session_log\u0026gt; \u0026lt;!-- Parameters for embedded dictionaries, used in Yandex.Metrica. See https://clickhouse.com/docs/en/dicts/internal_dicts/ --\u0026gt; \u0026lt;!-- Path to file with region hierarchy. --\u0026gt; \u0026lt;!-- \u0026lt;path_to_regions_hierarchy_file\u0026gt;/opt/geo/regions_hierarchy.txt\u0026lt;/path_to_regions_hierarchy_file\u0026gt; --\u0026gt; \u0026lt;!-- Path to directory with files containing names of regions --\u0026gt; \u0026lt;!-- \u0026lt;path_to_regions_names_files\u0026gt;/opt/geo/\u0026lt;/path_to_regions_names_files\u0026gt; --\u0026gt; \u0026lt;!-- \u0026lt;top_level_domains_path\u0026gt;/var/lib/clickhouse/top_level_domains/\u0026lt;/top_level_domains_path\u0026gt; --\u0026gt; \u0026lt;!-- Custom TLD lists. Format: \u0026lt;name\u0026gt;/path/to/file\u0026lt;/name\u0026gt; Changes will not be applied w/o server restart. Path to the list is under top_level_domains_path (see above). --\u0026gt; \u0026lt;top_level_domains_lists\u0026gt; \u0026lt;!-- \u0026lt;public_suffix_list\u0026gt;/path/to/public_suffix_list.dat\u0026lt;/public_suffix_list\u0026gt; --\u0026gt; \u0026lt;/top_level_domains_lists\u0026gt; \u0026lt;!-- Configuration of external dictionaries. See: https://clickhouse.com/docs/en/sql-reference/dictionaries/external-dictionaries/external-dicts --\u0026gt; \u0026lt;dictionaries_config\u0026gt;*_dictionary.xml\u0026lt;/dictionaries_config\u0026gt; \u0026lt;!-- Configuration of user defined executable functions --\u0026gt; \u0026lt;user_defined_executable_functions_config\u0026gt;*_function.xml\u0026lt;/user_defined_executable_functions_config\u0026gt; \u0026lt;!-- Uncomment if you want data to be compressed 30-100% better. Don\u0026#39;t do that if you just started using ClickHouse. --\u0026gt; \u0026lt;!-- \u0026lt;compression\u0026gt; \u0026lt;!- - Set of variants. Checked in order. Last matching case wins. If nothing matches, lz4 will be used. - -\u0026gt; \u0026lt;case\u0026gt; \u0026lt;!- - Conditions. All must be satisfied. Some conditions may be omitted. - -\u0026gt; \u0026lt;min_part_size\u0026gt;10000000000\u0026lt;/min_part_size\u0026gt; \u0026lt;!- - Min part size in bytes. - -\u0026gt; \u0026lt;min_part_size_ratio\u0026gt;0.01\u0026lt;/min_part_size_ratio\u0026gt; \u0026lt;!- - Min size of part relative to whole table size. - -\u0026gt; \u0026lt;!- - What compression method to use. - -\u0026gt; \u0026lt;method\u0026gt;zstd\u0026lt;/method\u0026gt; \u0026lt;/case\u0026gt; \u0026lt;/compression\u0026gt; --\u0026gt; \u0026lt;!-- Configuration of encryption. The server executes a command to obtain an encryption key at startup if such a command is defined, or encryption codecs will be disabled otherwise. The command is executed through /bin/sh and is expected to write a Base64-encoded key to the stdout. --\u0026gt; \u0026lt;encryption_codecs\u0026gt; \u0026lt;!-- aes_128_gcm_siv --\u0026gt; \u0026lt;!-- Example of getting hex key from env --\u0026gt; \u0026lt;!-- the code should use this key and throw an exception if its length is not 16 bytes --\u0026gt; \u0026lt;!--key_hex from_env=\u0026#34;...\u0026#34;\u0026gt;\u0026lt;/key_hex --\u0026gt; \u0026lt;!-- Example of multiple hex keys. They can be imported from env or be written down in config--\u0026gt; \u0026lt;!-- the code should use these keys and throw an exception if their length is not 16 bytes --\u0026gt; \u0026lt;!-- key_hex id=\u0026#34;0\u0026#34;\u0026gt;...\u0026lt;/key_hex --\u0026gt; \u0026lt;!-- key_hex id=\u0026#34;1\u0026#34; from_env=\u0026#34;..\u0026#34;\u0026gt;\u0026lt;/key_hex --\u0026gt; \u0026lt;!-- key_hex id=\u0026#34;2\u0026#34;\u0026gt;...\u0026lt;/key_hex --\u0026gt; \u0026lt;!-- current_key_id\u0026gt;2\u0026lt;/current_key_id --\u0026gt; \u0026lt;!-- Example of getting hex key from config --\u0026gt; \u0026lt;!-- the code should use this key and throw an exception if its length is not 16 bytes --\u0026gt; \u0026lt;!-- key\u0026gt;...\u0026lt;/key --\u0026gt; \u0026lt;!-- example of adding nonce --\u0026gt; \u0026lt;!-- nonce\u0026gt;...\u0026lt;/nonce --\u0026gt; \u0026lt;!-- /aes_128_gcm_siv --\u0026gt; \u0026lt;/encryption_codecs\u0026gt; \u0026lt;!-- Allow to execute distributed DDL queries (CREATE, DROP, ALTER, RENAME) on cluster. Works only if ZooKeeper is enabled. Comment it if such functionality isn\u0026#39;t required. --\u0026gt; \u0026lt;distributed_ddl\u0026gt; \u0026lt;!-- Path in ZooKeeper to queue with DDL queries --\u0026gt; \u0026lt;path\u0026gt;/clickhouse/task_queue/ddl\u0026lt;/path\u0026gt; \u0026lt;!-- Settings from this profile will be used to execute DDL queries --\u0026gt; \u0026lt;!-- \u0026lt;profile\u0026gt;default\u0026lt;/profile\u0026gt; --\u0026gt; \u0026lt;!-- Controls how much ON CLUSTER queries can be run simultaneously. --\u0026gt; \u0026lt;!-- \u0026lt;pool_size\u0026gt;1\u0026lt;/pool_size\u0026gt; --\u0026gt; \u0026lt;!-- Cleanup settings (active tasks will not be removed) --\u0026gt; \u0026lt;!-- Controls task TTL (default 1 week) --\u0026gt; \u0026lt;!-- \u0026lt;task_max_lifetime\u0026gt;604800\u0026lt;/task_max_lifetime\u0026gt; --\u0026gt; \u0026lt;!-- Controls how often cleanup should be performed (in seconds) --\u0026gt; \u0026lt;!-- \u0026lt;cleanup_delay_period\u0026gt;60\u0026lt;/cleanup_delay_period\u0026gt; --\u0026gt; \u0026lt;!-- Controls how many tasks could be in the queue --\u0026gt; \u0026lt;!-- \u0026lt;max_tasks_in_queue\u0026gt;1000\u0026lt;/max_tasks_in_queue\u0026gt; --\u0026gt; \u0026lt;/distributed_ddl\u0026gt; \u0026lt;!-- Settings to fine tune MergeTree tables. See documentation in source code, in MergeTreeSettings.h --\u0026gt; \u0026lt;!-- \u0026lt;merge_tree\u0026gt; \u0026lt;max_suspicious_broken_parts\u0026gt;5\u0026lt;/max_suspicious_broken_parts\u0026gt; \u0026lt;/merge_tree\u0026gt; --\u0026gt; \u0026lt;!-- Protection from accidental DROP. If size of a MergeTree table is greater than max_table_size_to_drop (in bytes) than table could not be dropped with any DROP query. If you want do delete one table and don\u0026#39;t want to change clickhouse-server config, you could create special file \u0026lt;clickhouse-path\u0026gt;/flags/force_drop_table and make DROP once. By default max_table_size_to_drop is 50GB; max_table_size_to_drop=0 allows to DROP any tables. The same for max_partition_size_to_drop. Uncomment to disable protection. --\u0026gt; \u0026lt;!-- \u0026lt;max_table_size_to_drop\u0026gt;0\u0026lt;/max_table_size_to_drop\u0026gt; --\u0026gt; \u0026lt;!-- \u0026lt;max_partition_size_to_drop\u0026gt;0\u0026lt;/max_partition_size_to_drop\u0026gt; --\u0026gt; \u0026lt;!-- Example of parameters for GraphiteMergeTree table engine --\u0026gt; \u0026lt;graphite_rollup_example\u0026gt; \u0026lt;pattern\u0026gt; \u0026lt;regexp\u0026gt;click_cost\u0026lt;/regexp\u0026gt; \u0026lt;function\u0026gt;any\u0026lt;/function\u0026gt; \u0026lt;retention\u0026gt; \u0026lt;age\u0026gt;0\u0026lt;/age\u0026gt; \u0026lt;precision\u0026gt;3600\u0026lt;/precision\u0026gt; \u0026lt;/retention\u0026gt; \u0026lt;retention\u0026gt; \u0026lt;age\u0026gt;86400\u0026lt;/age\u0026gt; \u0026lt;precision\u0026gt;60\u0026lt;/precision\u0026gt; \u0026lt;/retention\u0026gt; \u0026lt;/pattern\u0026gt; \u0026lt;default\u0026gt; \u0026lt;function\u0026gt;max\u0026lt;/function\u0026gt; \u0026lt;retention\u0026gt; \u0026lt;age\u0026gt;0\u0026lt;/age\u0026gt; \u0026lt;precision\u0026gt;60\u0026lt;/precision\u0026gt; \u0026lt;/retention\u0026gt; \u0026lt;retention\u0026gt; \u0026lt;age\u0026gt;3600\u0026lt;/age\u0026gt; \u0026lt;precision\u0026gt;300\u0026lt;/precision\u0026gt; \u0026lt;/retention\u0026gt; \u0026lt;retention\u0026gt; \u0026lt;age\u0026gt;86400\u0026lt;/age\u0026gt; \u0026lt;precision\u0026gt;3600\u0026lt;/precision\u0026gt; \u0026lt;/retention\u0026gt; \u0026lt;/default\u0026gt; \u0026lt;/graphite_rollup_example\u0026gt; \u0026lt;!-- Directory in \u0026lt;clickhouse-path\u0026gt; containing schema files for various input formats. The directory will be created if it doesn\u0026#39;t exist. --\u0026gt; \u0026lt;format_schema_path\u0026gt;/var/lib/clickhouse/format_schemas/\u0026lt;/format_schema_path\u0026gt; \u0026lt;!-- Default query masking rules, matching lines would be replaced with something else in the logs (both text logs and system.query_log). name - name for the rule (optional) regexp - RE2 compatible regular expression (mandatory) replace - substitution string for sensitive data (optional, by default - six asterisks) --\u0026gt; \u0026lt;query_masking_rules\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;name\u0026gt;hide encrypt/decrypt arguments\u0026lt;/name\u0026gt; \u0026lt;regexp\u0026gt;((?:aes_)?(?:encrypt|decrypt)(?:_mysql)?)\\s*\\(\\s*(?:\u0026#39;(?:\\\\\u0026#39;|.)+\u0026#39;|.*?)\\s*\\)\u0026lt;/regexp\u0026gt; \u0026lt;!-- or more secure, but also more invasive: (aes_\\w+)\\s*\\(.*\\) --\u0026gt; \u0026lt;replace\u0026gt;\\1(???)\u0026lt;/replace\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/query_masking_rules\u0026gt; \u0026lt;!-- Uncomment to use custom http handlers. rules are checked from top to bottom, first match runs the handler url - to match request URL, you can use \u0026#39;regex:\u0026#39; prefix to use regex match(optional) methods - to match request method, you can use commas to separate multiple method matches(optional) headers - to match request headers, match each child element(child element name is header name), you can use \u0026#39;regex:\u0026#39; prefix to use regex match(optional) handler is request handler type - supported types: static, dynamic_query_handler, predefined_query_handler query - use with predefined_query_handler type, executes query when the handler is called query_param_name - use with dynamic_query_handler type, extracts and executes the value corresponding to the \u0026lt;query_param_name\u0026gt; value in HTTP request params status - use with static type, response status code content_type - use with static type, response content-type response_content - use with static type, Response content sent to client, when using the prefix \u0026#39;file://\u0026#39; or \u0026#39;config://\u0026#39;, find the content from the file or configuration send to client. \u0026lt;http_handlers\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;url\u0026gt;/\u0026lt;/url\u0026gt; \u0026lt;methods\u0026gt;POST,GET\u0026lt;/methods\u0026gt; \u0026lt;headers\u0026gt;\u0026lt;pragma\u0026gt;no-cache\u0026lt;/pragma\u0026gt;\u0026lt;/headers\u0026gt; \u0026lt;handler\u0026gt; \u0026lt;type\u0026gt;dynamic_query_handler\u0026lt;/type\u0026gt; \u0026lt;query_param_name\u0026gt;query\u0026lt;/query_param_name\u0026gt; \u0026lt;/handler\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;url\u0026gt;/predefined_query\u0026lt;/url\u0026gt; \u0026lt;methods\u0026gt;POST,GET\u0026lt;/methods\u0026gt; \u0026lt;handler\u0026gt; \u0026lt;type\u0026gt;predefined_query_handler\u0026lt;/type\u0026gt; \u0026lt;query\u0026gt;SELECT * FROM system.settings\u0026lt;/query\u0026gt; \u0026lt;/handler\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;handler\u0026gt; \u0026lt;type\u0026gt;static\u0026lt;/type\u0026gt; \u0026lt;status\u0026gt;200\u0026lt;/status\u0026gt; \u0026lt;content_type\u0026gt;text/plain; charset=UTF-8\u0026lt;/content_type\u0026gt; \u0026lt;response_content\u0026gt;config://http_server_default_response\u0026lt;/response_content\u0026gt; \u0026lt;/handler\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/http_handlers\u0026gt; --\u0026gt; \u0026lt;send_crash_reports\u0026gt; \u0026lt;!-- Changing \u0026lt;enabled\u0026gt; to true allows sending crash reports to --\u0026gt; \u0026lt;!-- the ClickHouse core developers team via Sentry https://sentry.io --\u0026gt; \u0026lt;!-- Doing so at least in pre-production environments is highly appreciated --\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;!-- Change \u0026lt;anonymize\u0026gt; to true if you don\u0026#39;t feel comfortable attaching the server hostname to the crash report --\u0026gt; \u0026lt;anonymize\u0026gt;false\u0026lt;/anonymize\u0026gt; \u0026lt;!-- Default endpoint s hould be changed to different Sentry DSN only if you have --\u0026gt; \u0026lt;!-- some in-house engineers or hired consultants who\u0026#39;re going to debug ClickHouse issues for you --\u0026gt; \u0026lt;endpoint\u0026gt;\u0026lt;/endpoint\u0026gt; \u0026lt;/send_crash_reports\u0026gt; \u0026lt;!-- Uncomment to disable ClickHouse internal DNS caching. --\u0026gt; \u0026lt;!-- \u0026lt;disable_internal_dns_cache\u0026gt;1\u0026lt;/disable_internal_dns_cache\u0026gt; --\u0026gt; \u0026lt;!-- You can also configure rocksdb like this: --\u0026gt; \u0026lt;!-- \u0026lt;rocksdb\u0026gt; \u0026lt;options\u0026gt; \u0026lt;max_background_jobs\u0026gt;8\u0026lt;/max_background_jobs\u0026gt; \u0026lt;/options\u0026gt; \u0026lt;column_family_options\u0026gt; \u0026lt;num_levels\u0026gt;2\u0026lt;/num_levels\u0026gt; \u0026lt;/column_family_options\u0026gt; \u0026lt;tables\u0026gt; \u0026lt;table\u0026gt; \u0026lt;name\u0026gt;TABLE\u0026lt;/name\u0026gt; \u0026lt;options\u0026gt; \u0026lt;max_background_jobs\u0026gt;8\u0026lt;/max_background_jobs\u0026gt; \u0026lt;/options\u0026gt; \u0026lt;column_family_options\u0026gt; \u0026lt;num_levels\u0026gt;2\u0026lt;/num_levels\u0026gt; \u0026lt;/column_family_options\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/tables\u0026gt; \u0026lt;/rocksdb\u0026gt; --\u0026gt; \u0026lt;timezone\u0026gt;Asia/Shanghai\u0026lt;/timezone\u0026gt; \u0026lt;/clickhouse\u0026gt; 启动命令 docker-compose up -d TODO 现在配置的 zookeeper 还是单机部署的，有空看看部署个zookeeper集群怎么配置\n","permalink":"https://blog.lvcshu.com/2022/08/12/deploy-clickhouse-by-docker-compose/","summary":"Docker Compose 配置 version:\u0026#39;3\u0026#39;services:clickhouse-server-ck1:restart:on-failure:10# 退出非0重启，尝试10次image:yandex/clickhouse-servercontainer_name:ck1networks:- ck-networkports:- \u0026#34;8124:8123\u0026#34;- \u0026#34;9001:9000\u0026#34;- \u0026#34;9010:9004\u0026#34;volumes:- `pwd`/clickhouse/:/var/lib/clickhouse/- `pwd`/clickhouse-server/:/etc/clickhouse-server/- `pwd`/log/clickhouse-server/:/var/log/clickhouse-server/ulimits:nofile:soft:\u0026#34;262144\u0026#34;hard:\u0026#34;262144\u0026#34;depends_on:- zookeeper-1clickhouse-server-ck2:restart:on-failure:10# 退出非0重启，尝试10次image:yandex/clickhouse-servercontainer_name:ck2networks:- ck-networkports:- \u0026#34;8125:8123\u0026#34;- \u0026#34;9002:9000\u0026#34;- \u0026#34;9011:9004\u0026#34;volumes:- `pwd`/clickhouse2/:/var/lib/clickhouse/- `pwd`/clickhouse-server2/:/etc/clickhouse-server/- `pwd`/log/clickhouse-server2/:/var/log/clickhouse-server/ulimits:nofile:soft:\u0026#34;262144\u0026#34;hard:\u0026#34;262144\u0026#34;depends_on:- zookeeper-1clickhouse-server-ck3:restart:on-failure:10# 退出非0重启，尝试10次image:yandex/clickhouse-servercontainer_name:ck3networks:- ck-networkports:- \u0026#34;8126:8123\u0026#34;- \u0026#34;9003:9000\u0026#34;- \u0026#34;9012:9004\u0026#34;volumes:- `pwd`/clickhouse3/:/var/lib/clickhouse/- `pwd`/clickhouse-server3/:/etc/clickhouse-server/- `pwd`/log/clickhouse-server3/:/var/log/clickhouse-server/ulimits:nofile:soft:\u0026#34;262144\u0026#34;hard:\u0026#34;262144\u0026#34;depends_on:- zookeeper-1zookeeper-1:restart:on-failure:10# 退出非0重启，尝试10次image:zookeeper:3.8.0container_name:zookeeper1networks:- ck-networkports:- \u0026#34;2181:2181\u0026#34;volumes:- `pwd`/zookeeper/conf/:/apache-zookeeper-3.8.0-bin/conf/- `pwd`/zookeeper/data/:/data- `pwd`/zookeeper/datalog/:/datalog- `pwd`/zookeeper/logs/:/logsulimits:nofile:soft:\u0026#34;262144\u0026#34;hard:\u0026#34;262144\u0026#34;networks:ck-network:Clickhouse 配置文件 \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!-- NOTE: User and query level settings are set up in \u0026#34;users.xml\u0026#34; file. If you have accidentally specified user-level settings here, server won\u0026#39;t start. You can either move the settings to the right place inside \u0026#34;users.","title":"使用 docker-compose 搭建 clickhouse 集群"},{"content":"工作原因接触到了瑞士轮这种赛制，记录一下瑞士轮比赛对手编排的算法\n瑞士轮有两个规则\n 选择积分相近的对手进行比赛 不会重复比赛  写出来的算法如下:\ntype player struct { Id int64 Score int64 Opponent map[int64]struct{} // 曾经遇到过的对手 } // pickTablePlayer 计算瑞士轮比赛排列 func pickTablePlayer(players []int64, playerOpponentMap map[int64]map[int64]struct{}) ([]int64, bool) { if len(players) \u0026lt; 2 { return players, true } whitePlayer := players[0] opponentMap, _ := playerOpponentMap[whitePlayer] for i := range players { if i != 0 { // 判断是否已经比过 \tif _, has := opponentMap[players[i]]; !has { // 选中 \tres := make([]int64, 2) res[0] = whitePlayer res[1] = players[i] // 组装剩下排序的数据 \tvar nextRound []int64 nextRound = append(nextRound, players[1:i]...) nextRound = append(nextRound, players[i+1:]...) pick, ok := pickTablePlayer(nextRound, playerOpponentMap) // 进行下一轮排序 \tif ok { return append(res, pick...), true // 成功，结果上浮 \t} } } } return nil, false // 失败，上层重算 } func CreateSwissRound(players []player) (playerBattleList [][]int64, emptyPlayer int64, ok bool) { ok = true // 判断轮空选手 \ttotal := len(players) if total%2 != 0 { emptyPlayer = players[total-1].Id players = players[:total] } // 转换数据结构 \tvar playerIds []int64 var playerOpponentMap = make(map[int64]map[int64]struct{}) for _, v := range players { playerIds = append(playerIds, v.Id) if _, has := playerOpponentMap[v.Id]; !has { playerOpponentMap[v.Id] = v.Opponent } } // 计算比赛排序 \tplayerList, ok := pickTablePlayer(playerIds, playerOpponentMap) if !ok { return playerBattleList, emptyPlayer, ok } // 转换为二维数组 \tfor i := 0; i \u0026lt; len(playerList)/2; i++ { playerBattleList = append(playerBattleList, []int64{ playerList[i*2], playerList[i*2+1], }) } return } ","permalink":"https://blog.lvcshu.com/2022/07/29/%E7%91%9E%E5%A3%AB%E8%BD%AE/","summary":"工作原因接触到了瑞士轮这种赛制，记录一下瑞士轮比赛对手编排的算法\n瑞士轮有两个规则\n 选择积分相近的对手进行比赛 不会重复比赛  写出来的算法如下:\ntype player struct { Id int64 Score int64 Opponent map[int64]struct{} // 曾经遇到过的对手 } // pickTablePlayer 计算瑞士轮比赛排列 func pickTablePlayer(players []int64, playerOpponentMap map[int64]map[int64]struct{}) ([]int64, bool) { if len(players) \u0026lt; 2 { return players, true } whitePlayer := players[0] opponentMap, _ := playerOpponentMap[whitePlayer] for i := range players { if i != 0 { // 判断是否已经比过 \tif _, has := opponentMap[players[i]]; !has { // 选中 \tres := make([]int64, 2) res[0] = whitePlayer res[1] = players[i] // 组装剩下排序的数据 \tvar nextRound []int64 nextRound = append(nextRound, players[1:i].","title":"Go 实现瑞士轮排列算法"},{"content":"劳动节来给博客除除草！\n自从一加手机社区发布了官方公告说 Android 12 正式版本出来了之后我就一直在等系统更新的推送，谁知道从4月12日公告出来到今天我都没有收到推送，再加上一加的在 Android 12 后 HOS 会切换成 ColorOS，类原生的特点就没有了，OOS 虽说还会持续维护，但是我既然都用 OOS 了我为啥不自己刷个更加原生的系统呢？比如说 LineageOS。\n前期准备 说干就干，先去官网看下有没有支持，芜湖，有支持而且看了下文档还蛮完善的，备份好微信(这个手机里面唯一没有同步功能的app)的数据就打算开始刷机了。\n开刷 刷机的过程官方文档已经非常完善了，在这里不重复赘述。\n一些要注意的小问题 GAPPS GAPPS 一定要在首次启动系统之前刷入，不然就要双清，之前辛苦配置的东西都无了\nSafetyNet 在刷好系统之后，我自然是想打开 ingress 玩下，然后折腾了半天，一直在提醒 ”ingress 需要安全登录“，一开始还以为是代理的问题，疯狂切换代理都没有用，后来查到这个讨论发现是 SafetyNet 的问题，于是 Magisk 刷入了 MagiskHide Props Config、Universal SafetyNet Fix 两个模块解决了这个问题\nUniversal SafetyNet Fix 这个模块无需任何配置，直接刷入即可生效 MagiskHide Props Config 这个则需要在shell执行指令 props 按照提示选择即可。 相机 自带的相机 app 太拉了，直接停用，在 Google Camera Port 下载了个最新版本的相机，以及挑了个推荐的配置文件。\n使用感受 原生的系统真是舒服啊，没有了一些有的没有的app，动画啥的感觉要比HOS要好。高帧率、AOD、蓝牙HD音频编码、屏下指纹这些都没有啥大问题。\n甚至有些之前在HOS上面没有体验过的特性，比如说锁屏音乐可视化 总的来说挺满意的，再看看后续使用的过程中有没有啥坑了，就这样。\n","permalink":"https://blog.lvcshu.com/2022/05/01/oneplus-8t-%E5%88%B7%E5%85%A5-lineageos/","summary":"劳动节来给博客除除草！\n自从一加手机社区发布了官方公告说 Android 12 正式版本出来了之后我就一直在等系统更新的推送，谁知道从4月12日公告出来到今天我都没有收到推送，再加上一加的在 Android 12 后 HOS 会切换成 ColorOS，类原生的特点就没有了，OOS 虽说还会持续维护，但是我既然都用 OOS 了我为啥不自己刷个更加原生的系统呢？比如说 LineageOS。\n前期准备 说干就干，先去官网看下有没有支持，芜湖，有支持而且看了下文档还蛮完善的，备份好微信(这个手机里面唯一没有同步功能的app)的数据就打算开始刷机了。\n开刷 刷机的过程官方文档已经非常完善了，在这里不重复赘述。\n一些要注意的小问题 GAPPS GAPPS 一定要在首次启动系统之前刷入，不然就要双清，之前辛苦配置的东西都无了\nSafetyNet 在刷好系统之后，我自然是想打开 ingress 玩下，然后折腾了半天，一直在提醒 ”ingress 需要安全登录“，一开始还以为是代理的问题，疯狂切换代理都没有用，后来查到这个讨论发现是 SafetyNet 的问题，于是 Magisk 刷入了 MagiskHide Props Config、Universal SafetyNet Fix 两个模块解决了这个问题\nUniversal SafetyNet Fix 这个模块无需任何配置，直接刷入即可生效 MagiskHide Props Config 这个则需要在shell执行指令 props 按照提示选择即可。 相机 自带的相机 app 太拉了，直接停用，在 Google Camera Port 下载了个最新版本的相机，以及挑了个推荐的配置文件。\n使用感受 原生的系统真是舒服啊，没有了一些有的没有的app，动画啥的感觉要比HOS要好。高帧率、AOD、蓝牙HD音频编码、屏下指纹这些都没有啥大问题。\n甚至有些之前在HOS上面没有体验过的特性，比如说锁屏音乐可视化 总的来说挺满意的，再看看后续使用的过程中有没有啥坑了，就这样。","title":"Oneplus 8T 刷入 LineageOS"},{"content":"部署流程更新 众所周知，之前我的博客以及图片托管的服务是通过硬核的DNS分区域解析来实现流量的就近调度，而多个服务器之间的资源文件我一般使用syncthing来进行同步，这个方法显得比较粗糙，但是还挺有效的。最近折腾了下 cloudflare worker 感觉还不错，于是就把博客以及图片托管迁移到了 cloudflare worker 上来，这样一来可以白嫖到不错的全球加速(除中国大陆)，而且使用 workers 进行部署可以省下不少的服务器资源。\n这个就是我之前的发布工作流程\n在这次部署流程更新后他变成了这样，博客由于是 public 代码仓库，所以我的自动构建直接使用了 github action，只要基于之前的配置改改加上 publish 到 cloudflare workers 的 step 就可以直接用了。\n而静态文件托管的我一直是存在自建的 gitea 上面，所以配了个 drone 来执行自动 publish 到 cloudflare workers 的工作，总而言之也是挺香的。\n5月1日更新 又更改了下，用上了 vercel 的服务，实测这个服务提供的 cdn 要比 cloudflare 在中国大陆访问的快些。 博客主题更新 博客主题也好久没有更新了，这次更新主要是加上了几个能够改进访问体验的 feature。\n 添加了首页巨幕以及文章头图图片下面的背景颜色，能够自定义在图片还没有加载出来之前显示的颜色 将博客底部版权信息部分的版本号放进了一个js里面，这样就减少了版本号修改时候需要修改的位置 将原来的文章无头图从几张图片中随机选择一张作为头图改成了随机选择一个颜色作为头图  颜色随机取值这里，是取值RGB都在 110-87之间的值，这里的颜色饱和度比较低，看起来比较舒服\n","permalink":"https://blog.lvcshu.com/2022/04/17/%E5%8D%9A%E5%AE%A2%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2%E6%9B%B4%E6%96%B0/","summary":"部署流程更新 众所周知，之前我的博客以及图片托管的服务是通过硬核的DNS分区域解析来实现流量的就近调度，而多个服务器之间的资源文件我一般使用syncthing来进行同步，这个方法显得比较粗糙，但是还挺有效的。最近折腾了下 cloudflare worker 感觉还不错，于是就把博客以及图片托管迁移到了 cloudflare worker 上来，这样一来可以白嫖到不错的全球加速(除中国大陆)，而且使用 workers 进行部署可以省下不少的服务器资源。\n这个就是我之前的发布工作流程\n在这次部署流程更新后他变成了这样，博客由于是 public 代码仓库，所以我的自动构建直接使用了 github action，只要基于之前的配置改改加上 publish 到 cloudflare workers 的 step 就可以直接用了。\n而静态文件托管的我一直是存在自建的 gitea 上面，所以配了个 drone 来执行自动 publish 到 cloudflare workers 的工作，总而言之也是挺香的。\n5月1日更新 又更改了下，用上了 vercel 的服务，实测这个服务提供的 cdn 要比 cloudflare 在中国大陆访问的快些。 博客主题更新 博客主题也好久没有更新了，这次更新主要是加上了几个能够改进访问体验的 feature。\n 添加了首页巨幕以及文章头图图片下面的背景颜色，能够自定义在图片还没有加载出来之前显示的颜色 将博客底部版权信息部分的版本号放进了一个js里面，这样就减少了版本号修改时候需要修改的位置 将原来的文章无头图从几张图片中随机选择一张作为头图改成了随机选择一个颜色作为头图  颜色随机取值这里，是取值RGB都在 110-87之间的值，这里的颜色饱和度比较低，看起来比较舒服","title":"博客及相关服务部署更新"},{"content":"好久不见，新年开始一直忙着毕业设计和实习找新的工作，一直没有空去将一些折腾过的东西记录成为博客，最近在写毕业设计的间隙终于对博客进行了一波优化，顺便写篇博客记录一下。\n在过去的部署中，博客一直是采用多节点部署并且通过dnspod的分地区解析做流量调度，将流量解析到尽量近的节点来尽量保证博客访问的速度。而多个节点之间的博客文件同步一开始用的是定时任务从github上面更新，后来改成了使用syncthing进行同步，这种方法看起来比较蠢，但是也持续的保证了我的博客在这两年期间的顺畅访问。\n最近在翻sukka大佬的博客过程中，看到了 cloudflare worker 可以联合 kv 存储用来部署静态网站，于是乎我就先将自托管的图片提供服务(就是一个存了图片的http服务)，部署到了 cloudflare 上面，测试速度以及延迟也相当不错，所以就想彻底的把博客这一套东西完全迁移到 cloudflare 上面去。\n这样就能保证我博客在我不主动折腾的情况下保证极高的可靠性以及相对不错的响应速度。\n404页面异常 在 worker-site/index.js 文件中，有一段逻辑是控制在url无法获取到文件的时候返回 /404.html。但是一部署上去我就发现了不对劲，这个404页面直接源代码显示，并没有被浏览器渲染出来。\n经过F12大法查看network的response知道返回的数据中缺少了个指定响应数据格式的header。\n修复这个情况只需要在返回响应的时候加上相应的header即可，代码修改可以参考我提的PR\n参考链接  将 Hexo 部署到 Cloudflare Workers Site 上的趟坑记录  ","permalink":"https://blog.lvcshu.com/2022/03/25/blog-on-cloudflare-workers/","summary":"好久不见，新年开始一直忙着毕业设计和实习找新的工作，一直没有空去将一些折腾过的东西记录成为博客，最近在写毕业设计的间隙终于对博客进行了一波优化，顺便写篇博客记录一下。\n在过去的部署中，博客一直是采用多节点部署并且通过dnspod的分地区解析做流量调度，将流量解析到尽量近的节点来尽量保证博客访问的速度。而多个节点之间的博客文件同步一开始用的是定时任务从github上面更新，后来改成了使用syncthing进行同步，这种方法看起来比较蠢，但是也持续的保证了我的博客在这两年期间的顺畅访问。\n最近在翻sukka大佬的博客过程中，看到了 cloudflare worker 可以联合 kv 存储用来部署静态网站，于是乎我就先将自托管的图片提供服务(就是一个存了图片的http服务)，部署到了 cloudflare 上面，测试速度以及延迟也相当不错，所以就想彻底的把博客这一套东西完全迁移到 cloudflare 上面去。\n这样就能保证我博客在我不主动折腾的情况下保证极高的可靠性以及相对不错的响应速度。\n404页面异常 在 worker-site/index.js 文件中，有一段逻辑是控制在url无法获取到文件的时候返回 /404.html。但是一部署上去我就发现了不对劲，这个404页面直接源代码显示，并没有被浏览器渲染出来。\n经过F12大法查看network的response知道返回的数据中缺少了个指定响应数据格式的header。\n修复这个情况只需要在返回响应的时候加上相应的header即可，代码修改可以参考我提的PR\n参考链接  将 Hexo 部署到 Cloudflare Workers Site 上的趟坑记录  ","title":"博客迁移到cloudflare踩坑"},{"content":"今年真的是变化挺大的一年。我大四了，也算是步入了大学生活的最后一段时间，从三月份开始就离开了学校实习，在实习中我学到了许多，但是也确实占用了我大部分时间用于上班以及学习一些我之前没有学习的在工作中用到的知识和技术。\n博客写了啥 在编写那个服务器监控面板的时候我想把服务器上面的进程信息显示在上面，所以顺手写了一个文章\n Linux 进程信息格式化  这两篇是我在实习中所学习用到的东西，也写成了文章\n proto 通过字段名获取值 用于 gnet 的 Protocol buffers 编解码器  还有两篇是平时折腾的记录\n 解决全屏背景图卡顿 使用 Zerotier 异地组内网  可以看出来我今年写的博客少了很多，看看明年能不能试试写多一些\n代码写了啥 GITHUB 照惯例上绿点图\n可以明显的看到今年比去年相比，我的 github 代码提交的不是那么的活跃了。。那是因为实习的时候确实比在学校要忙\n今年新写了啥呢 还在维护啥? johnpoint.github.io: 博客的本体\nhexo-theme-XvA: 今年更新的也很少，就是更新了一些细节问题，升级了 jq 的版本，改进了 copyright 的样式，修复了背景图片卡顿的问题\n博客今年怎么样 今年终于有人评论了！\n更新的文章略少，不过貌似还是比去年的文章多一篇，天啊\n 今年更新了 6篇文章(包括本文) 友链增加了 0个大佬 评论 2条(哇塞，终于有活人来评论了！！虽然我没有回复)  完整数据-Google Sheet\n参与了啥活动  GDG devfest GuangZhou（延期了\u0026hellip;延期到 2022年1月8日的 2021 GDG devfest，不出啥大问题的话会去的）  看了啥 今年在我心目中排名第一的电影！ 《雄狮少年》\n无论从画面还是剧情还是音乐都很不错，可能晚点会把刚刚看完就说要写的影评咕出来 绝对不咕\n还有啥想说 去年开始的记账习惯最终还是在一次长时间中断记账后放弃了，看来用web记账还是不适合我，用手机记账又在今年的10月份重新开始，希望可以坚持下去吧。\n经过我这将近一年的实习，我还是发现有挺多的不足，明年希望有所改进吧。\n最后 2021 再见！\n","permalink":"https://blog.lvcshu.com/2021/12/26/2021-year-summary/","summary":"","title":"2021 年度简报"},{"content":"众所周知，世界上的 ipv4 地址已经快要枯竭 (错了就当我在瞎掰)，所以在国内不是所有的运营商都拥有公网 IP 地址，同时还有许多奇奇怪怪的需求 (比如说想异地联机打红警之类的)，想要实现异地组建内网的效果不得不要采取一些特别手段进行组网。其实异地组网的文章有不少，比如柠檬雨大佬的这篇文章 《异地也要玩局域网——使用N2N，实现异地服务器快速组建内网》，中间就用到了一个叫做 N2N 的软件来进行隧道的建立。但是吧，我在想用 N2N 进行组网的时候，遇到了不少问题，首先就是 windows 客户端 v2 版本的我只找到了一个网络博主自己编译的版本，而且国内服务器在获取客户端的时候非常慢。\n其中一度不想折腾想着使用那些现成的局域网对战平台来进行游戏 (对就是浩方) 但是下载注册 (这个平台注册居然还要身份证，就离谱，虽然我是用生成的身份证号码注册的) 之后，登录这边一直卡死在 loading，无奈我只能再看看有没有其他的方案。\n在一位 (非常非常非常想玩红警3的) 朋友的建议下，我去研究了下 ZeroTier 这个异地组网的解决方案，发现挺方便的。\n但是问题来了，在我用上了 ZeroTier 之后，隧道倒是建立了，但是不知道为何，有两个节点相互 ping 不通\n","permalink":"https://blog.lvcshu.com/2021/11/24/zerotier-%E6%9E%84%E5%BB%BA%E5%86%85%E7%BD%91/","summary":"众所周知，世界上的 ipv4 地址已经快要枯竭 (错了就当我在瞎掰)，所以在国内不是所有的运营商都拥有公网 IP 地址，同时还有许多奇奇怪怪的需求 (比如说想异地联机打红警之类的)，想要实现异地组建内网的效果不得不要采取一些特别手段进行组网。其实异地组网的文章有不少，比如柠檬雨大佬的这篇文章 《异地也要玩局域网——使用N2N，实现异地服务器快速组建内网》，中间就用到了一个叫做 N2N 的软件来进行隧道的建立。但是吧，我在想用 N2N 进行组网的时候，遇到了不少问题，首先就是 windows 客户端 v2 版本的我只找到了一个网络博主自己编译的版本，而且国内服务器在获取客户端的时候非常慢。\n其中一度不想折腾想着使用那些现成的局域网对战平台来进行游戏 (对就是浩方) 但是下载注册 (这个平台注册居然还要身份证，就离谱，虽然我是用生成的身份证号码注册的) 之后，登录这边一直卡死在 loading，无奈我只能再看看有没有其他的方案。\n在一位 (非常非常非常想玩红警3的) 朋友的建议下，我去研究了下 ZeroTier 这个异地组网的解决方案，发现挺方便的。\n但是问题来了，在我用上了 ZeroTier 之后，隧道倒是建立了，但是不知道为何，有两个节点相互 ping 不通","title":"使用 Zerotier 异地组内网"},{"content":"要写一个 TCP 服务端，实现处理在纯 TCP 流中传输的 Protocol buffers 数据。网络框架很早就选好了，用性能杰出的 gnet，问题是 gnet 的示例库里面没有直接解析纯 Protocol buffers 的编解码器，于是乎只能自己动手了\u0026hellip;\n协议分析 从 TCP 流里面传过来的是经过简单处理的 Protocol buffers 数据，他在数据的头携带了这个数据包的长度信息，像是这样\n[ 头 ][ 数据 ][ 头 ][ 数据 ][ 头 ][ 数据 ][ 头 ][ 数据 ][ 头 ][ 数据 ] 调用 golang 的 proto 官方库中的 func DecodeVarint(b []byte) (uint64, int) 方法可以从数据中拿到两个值，分别是 数据的完整长度、标明数据长度的头信息的长度。\n由于没有特定的协议在包与包之间进行明显的划分，所以得用他的头数据来进行分包。\n解码器 // 储存连接内的相关信息 type DataStruct struct { fullLength int lenNumLength int fullData []byte } func (d *Codec) Decode(c gnet.Conn) ([]byte, error) { ctx, ok := c.Context().(context.Context) if !ok { err := c.Close() if err != nil { return nil, nil } } // 从上下文里面拿出这个连接的编解码器储存 struct \tr, ok := ctx.Value(\u0026#34;codec\u0026#34;).(DataStruct) if !ok { err := c.Close() if err != nil { return nil, nil } } // 读取缓冲区内的所有信息 \tbytes := c.Read() // 判断是否已经开始读取包 \tif len(r.fullData) == 0 { // 调用函数获取头中带的信息 \tvar fullLength uint64 fullLength, r.lenNumLength = proto.DecodeVarint(bytes) r.fullLength = int(fullLength) fmt.Println(r.fullLength, r.lenNumLength) if r.fullLength == 0 { return nil, nil } } // 拿到当前时间已经被储存进 struct 的数据的长度 \tfullDataLong := len(r.fullData) // 把读到的数据一把梭全部拼进 fullData \tr.fullData = append(r.fullData, bytes...) // 判断长度是否符合要求 \tif len(r.fullData) \u0026gt;= r.fullLength+r.lenNumLength { c.ShiftN(r.fullLength + r.lenNumLength - fullDataLong) // 截取有效的数据 \tres := r.fullData[r.lenNumLength : r.fullLength+r.lenNumLength] // 连接的缓存清空 \tr.fullData = []byte{} ctx = context.WithValue(ctx, \u0026#34;codec\u0026#34;, r) c.SetContext(ctx) return res, nil } // 移动读取指针 \tc.ShiftN(len(bytes)) ctx = context.WithValue(ctx, \u0026#34;codec\u0026#34;, r) c.SetContext(ctx) return nil, nil } 上面那种解码方式是目前看运行状况来说暂时没有出现问题的方法，下面那一种则比较节省内存，两种解码方式区别主要是在于调用的 Read 函数不同，前者是把 gnet 的 ring buffer 里面的内容全部读取出来，而后者是先把头读取出来，拿到了完整的数据长度信息之后调用 ReadN 函数直接准确的将包体取出。\nfunc (d *Codec) Decode(c gnet.Conn) ([]byte, error) { ctx, ok := c.Context().(context.Context) if !ok { err := c.Close() if err != nil { return nil, nil } } // 从上下文里面拿出这个连接的编解码器储存 struct \tr, ok := ctx.Value(\u0026#34;codec\u0026#34;).(DataStruct) if !ok { err := c.Close() if err != nil { return nil, nil } } if len(r.fullData) == 0 { _, bytes := c.ReadN(10) var fullLength uint64 fullLength, r.lenNumLength = proto.DecodeVarint(bytes) r.fullLength = int(fullLength) fmt.Println(r.fullLength, r.lenNumLength) if r.fullLength == 0 { return nil, nil } } fullDataLong := len(r.fullData) n, bytes := c.ReadN(r.fullLength + r.lenNumLength - fullDataLong) r.fullData = append(r.fullData, bytes...) c.ShiftN(n) if len(r.fullData) \u0026gt;= r.fullLength+r.lenNumLength { res := r.fullData[r.lenNumLength :] r.fullData = []byte{} ctx = context.WithValue(ctx, \u0026#34;codec\u0026#34;, r) c.SetContext(ctx) return res, nil } ctx = context.WithValue(ctx, \u0026#34;codec\u0026#34;, r) c.SetContext(ctx) return nil, nil } 在代码中也可以看见，头数据中的包体长度信息我是存在连接的上下文中的，所以在 gnet 触发连接打开的事件时需要将储存信息的 struct 塞进上下文中。\nfunc (es *EventServer) OnOpened(c gnet.Conn) (out []byte, action gnet.Action) { ctx := context.WithValue(context.Background(), \u0026#34;codec\u0026#34;, DataStruct{}) c.SetContext(ctx) return } 编码器 编码器这个部分就非常简单了，直接调用 proto 库里面的 EncodeVarint 函数就可以生成这个包体的头，将头信息放在包体的前面就可以将这个数据发送到客户端了。\nfunc (d *Codec) Encode(c gnet.Conn, buf []byte) ([]byte, error) { buf = append(proto.EncodeVarint(uint64(len(buf))), buf...) return buf, nil } 2021-11-09 更新 大意了，之前用上下文存储中间信息的方法有 严重的性能问题，在调用 golang 原生的 context.WithValue 方法时候，会在传入的上下文下面创建一个子上下文，这就导致了在一次又一次解码中，上下文树越来越庞大，而且每一层上下文内部都存储了本次解码的 DataStruct，造成内存泄漏的问题。\n在苦苦查了好几天，并且修了几个有可能的内存泄漏隐患之后我才意识到这一点(秃头.jpg)\n然后再看了下 gnet.Conn 的一个实现的 Context() 方法，发现他只是将我们传进去的东西存在了一个 map 里面，并不需要使用 context 相关的，所以简单的解决方法就是直接将 DataStruct 传进去，目前来看是解决了内存泄漏的问题，代码如下\nfunc (d *Codec) Decode(c gnet.Conn) ([]byte, error) { // 从上下文里面拿出这个连接的编解码器储存 struct \tr, ok := c.Context().(DataStruct) if !ok { err := c.Close() if err != nil { return nil, nil } } if len(r.fullData) == 0 { _, bytes := c.ReadN(10) var fullLength uint64 fullLength, r.lenNumLength = proto.DecodeVarint(bytes) r.fullLength = int(fullLength) fmt.Println(r.fullLength, r.lenNumLength) if r.fullLength == 0 { return nil, nil } } fullDataLong := len(r.fullData) n, bytes := c.ReadN(r.fullLength + r.lenNumLength - fullDataLong) r.fullData = append(r.fullData, bytes...) c.ShiftN(n) if len(r.fullData) \u0026gt;= r.fullLength+r.lenNumLength { res := r.fullData[r.lenNumLength :] r.fullData = []byte{} c.SetContext(r) return res, nil } ctx = context.WithValue(ctx, \u0026#34;codec\u0026#34;, r) c.SetContext(r) return nil, nil } func (es *EventServer) OnOpened(c gnet.Conn) (out []byte, action gnet.Action) { var r = DataStruct{} c.SetContext(r) return } 2021-12-24 更新 最近 gnet 发布了 v1.6.x 新版本，新版本的 编解码器行为有所改变，所以需要改造一下代码\n主要的改动是在 gnet 库的 eventloop_unix.go 文件的 d1ca7f3 commit 中将进入 React 的时间点从返回的 packet 不为 nil 改为了返回的 err 不为 nil，所以在升级后需要做对应的修改\nvar ( ContinueRead = errors.New(\u0026#34;continue read\u0026#34;) ) func (d *Codec) Decode(c gnet.Conn) ([]byte, error) { // 从上下文里面拿出这个连接的编解码器储存 struct \tr, ok := c.Context().(DataStruct) if !ok { err := c.Close() if err != nil { return nil, nil } } if len(r.fullData) == 0 { _, bytes := c.ReadN(10) var fullLength uint64 fullLength, r.lenNumLength = proto.DecodeVarint(bytes) r.fullLength = int(fullLength) fmt.Println(r.fullLength, r.lenNumLength) if r.fullLength == 0 { return nil, ContinueRead } } fullDataLong := len(r.fullData) n, bytes := c.ReadN(r.fullLength + r.lenNumLength - fullDataLong) r.fullData = append(r.fullData, bytes...) c.ShiftN(n) if len(r.fullData) \u0026gt;= r.fullLength+r.lenNumLength { res := r.fullData[r.lenNumLength :] r.fullData = []byte{} c.SetContext(r) return res, nil } ctx = context.WithValue(ctx, \u0026#34;codec\u0026#34;, r) c.SetContext(r) return nil, ContinueRead } 参考资料  Go 语言设计与实现 \u0026gt; 上下文 Context \u0026gt; 传值方法  ","permalink":"https://blog.lvcshu.com/2021/09/17/tcp-protocol-buffers-codec/","summary":"要写一个 TCP 服务端，实现处理在纯 TCP 流中传输的 Protocol buffers 数据。网络框架很早就选好了，用性能杰出的 gnet，问题是 gnet 的示例库里面没有直接解析纯 Protocol buffers 的编解码器，于是乎只能自己动手了\u0026hellip;\n协议分析 从 TCP 流里面传过来的是经过简单处理的 Protocol buffers 数据，他在数据的头携带了这个数据包的长度信息，像是这样\n[ 头 ][ 数据 ][ 头 ][ 数据 ][ 头 ][ 数据 ][ 头 ][ 数据 ][ 头 ][ 数据 ] 调用 golang 的 proto 官方库中的 func DecodeVarint(b []byte) (uint64, int) 方法可以从数据中拿到两个值，分别是 数据的完整长度、标明数据长度的头信息的长度。\n由于没有特定的协议在包与包之间进行明显的划分，所以得用他的头数据来进行分包。\n解码器 // 储存连接内的相关信息 type DataStruct struct { fullLength int lenNumLength int fullData []byte } func (d *Codec) Decode(c gnet.","title":"用于 gnet 的 Protocol buffers 编解码器"},{"content":"早就在替换了新的主题后（也就是现在用的主题），发现主页滚动的时候特别的卡，但是在滚动部分没有背景图片的时候就不会掉帧，所以判断是背景图片的问题。\n而在我替换掉了 fixed 属性之后就又不卡了，从而断定就是这个属性导致博客滚动的时候出现性能问题。\n搜索资料发现了这篇文章 Fixed background image performance issue，遂按照其中的方式将背景设置为虚元素，那么在滚动的时候背景就不会频繁的进行重绘，从而解决了滚动到时候出现掉帧的问题，终于在鸽了半年之后让我的博客首页重回丝滑\u0026hellip;\n","permalink":"https://blog.lvcshu.com/2021/07/28/%E8%A7%A3%E5%86%B3%E5%85%A8%E5%B1%8F%E8%83%8C%E6%99%AF%E5%9B%BE%E5%8D%A1%E9%A1%BF/","summary":"早就在替换了新的主题后（也就是现在用的主题），发现主页滚动的时候特别的卡，但是在滚动部分没有背景图片的时候就不会掉帧，所以判断是背景图片的问题。\n而在我替换掉了 fixed 属性之后就又不卡了，从而断定就是这个属性导致博客滚动的时候出现性能问题。\n搜索资料发现了这篇文章 Fixed background image performance issue，遂按照其中的方式将背景设置为虚元素，那么在滚动的时候背景就不会频繁的进行重绘，从而解决了滚动到时候出现掉帧的问题，终于在鸽了半年之后让我的博客首页重回丝滑\u0026hellip;","title":"解决全屏背景图卡顿"},{"content":"很久没有更新博客了，一方面是出去实习比在学校的时候忙，真的很多东西等着我去学，太可怕了，另一方面就是懒\nprotobuf 真是个好东西，就是在你不知道具体结构的时候想要拿到特定字段的值有点小麻烦，好不容易折腾出来了，写篇博客记录一下\nfunc FindByName(name string, msg protoreflect.Message) (has bool, value protoreflect.Value, isList bool) { if name == \u0026#34;\u0026#34; { return false, *new(protoreflect.Value), false } msgDesc := msg.Descriptor() for i := 0; i \u0026lt; msgDesc.Fields().Len(); i++ { if msgDesc.Fields().Get(i).Kind() == protoreflect.MessageKind { sonMsg := msgDesc.Fields().Get(i) has, value, isList = FindByName(name, msg.Get(sonMsg).Message()) // type mismatch: cannot convert list to message \tif has { return has, value, isList } } if msgDesc.Fields().Get(i).Name() == protoreflect.Name(name) { return true, msg.Get(msgDesc.Fields().Get(i)), msgDesc.Fields().Get(i).IsList() } } return false, value, false } 这个还考虑到了在 proto message 里面嵌套了 message 的一种写法，仅供参考\nupdate:\n有点小坑，如果字段里面是个切片的话从源码那边看，使用 Interface() 函数获得的 interface 是这个切片的指针，通过反射拿到的类型是 Ptr，导致后续的处理变得有点麻烦，所以我直接在函数内部加了一手判断，直接判断是否为 List 类型，返回回来根据布尔值进行相应的处理。\nfunc (v Value) Interface() interface{} { switch v.typ { case nilType: return nil case boolType: return v.Bool() case int32Type: return int32(v.Int()) case int64Type: return int64(v.Int()) case uint32Type: return uint32(v.Uint()) case uint64Type: return uint64(v.Uint()) case float32Type: return float32(v.Float()) case float64Type: return float64(v.Float()) case stringType: return v.String() case bytesType: return v.Bytes() case enumType: return v.Enum() default: return v.getIface() } } func (v Value) getIface() (x interface{}) { *(*ifaceHeader)(unsafe.Pointer(\u0026amp;x)) = ifaceHeader{Type: v.typ, Data: v.ptr} return x } ","permalink":"https://blog.lvcshu.com/2021/06/11/proto%E9%80%9A%E8%BF%87%E5%AD%97%E6%AE%B5%E5%90%8D%E8%8E%B7%E5%8F%96%E5%80%BC/","summary":"很久没有更新博客了，一方面是出去实习比在学校的时候忙，真的很多东西等着我去学，太可怕了，另一方面就是懒\nprotobuf 真是个好东西，就是在你不知道具体结构的时候想要拿到特定字段的值有点小麻烦，好不容易折腾出来了，写篇博客记录一下\nfunc FindByName(name string, msg protoreflect.Message) (has bool, value protoreflect.Value, isList bool) { if name == \u0026#34;\u0026#34; { return false, *new(protoreflect.Value), false } msgDesc := msg.Descriptor() for i := 0; i \u0026lt; msgDesc.Fields().Len(); i++ { if msgDesc.Fields().Get(i).Kind() == protoreflect.MessageKind { sonMsg := msgDesc.Fields().Get(i) has, value, isList = FindByName(name, msg.Get(sonMsg).Message()) // type mismatch: cannot convert list to message \tif has { return has, value, isList } } if msgDesc.","title":"proto 通过字段名获取值"},{"content":"2021 年了，转头看了下自己的服务器面板，发现还是那个半成品的样子\u0026hellip;于是在这三天改了下代码，加入了 v2 api 接口，这个接口主要使用 Websocket 进行通信，虽然说服务端的压力其实不是很大，但是使用轮询进行数据的更新不仅会看到一坨一坨的请求，对我的渣渣电脑来说也有些吃力了，不过这篇文章的内容不是这个，改天再开一篇文章记录一下。\n进程查看其实是很早之前就想做进面板的功能之一，但是受限于并没有找到现成的 go 第三方或者官方库，所以就放了一放 （结果放了差不多一年），刚好这几天在改面板的代码，索性就顺手把它做了。\n进程查看没有库可以调用，就只能通过调用系统命令来进行查看，一般来说我看进程会使用 ps -aux，但是对于面板来说，这里输出的数据有点太多以及有点太乱（太乱指的是输出的数据不是计算机友好型结构），然后看了下网上网友们五花八门的命令，左拼右凑之后，最后成品是用的 ps axc -o pid,user,stat,pcpu,pmem,command --sort -pcpu --no-header | sed 's/\\ \\+/\\ /g' 最终得到的数据是没有表头、连续空格被替换成一个空格的数据，我感觉这就够了，其余的交给前端处理。\n前端代码截取如下\nlet ps = server.Ps.split(\u0026#39;\\n\u0026#39;); ps.forEach(item = \u0026gt;{ if (item.split(\u0026#34; \u0026#34;).length \u0026gt; 3) { item = item.split(\u0026#34; \u0026#34;) if (item[0] === \u0026#34;\u0026#34;) { item = item.slice(1, item.length) } let i = { PID: item[0], User: item[1], State: item[2], Pcpu: item[3], Pmem: item[4], Command: item.slice(5, item.length).toString().replaceAll(\u0026#34;,\u0026#34;, \u0026#34; \u0026#34;), } this.psData.push(i) } }) 最后效果还不错~\n","permalink":"https://blog.lvcshu.com/2021/02/02/linux-%E8%BF%9B%E7%A8%8B%E4%BF%A1%E6%81%AF%E6%A0%BC%E5%BC%8F%E5%8C%96/","summary":"2021 年了，转头看了下自己的服务器面板，发现还是那个半成品的样子\u0026hellip;于是在这三天改了下代码，加入了 v2 api 接口，这个接口主要使用 Websocket 进行通信，虽然说服务端的压力其实不是很大，但是使用轮询进行数据的更新不仅会看到一坨一坨的请求，对我的渣渣电脑来说也有些吃力了，不过这篇文章的内容不是这个，改天再开一篇文章记录一下。\n进程查看其实是很早之前就想做进面板的功能之一，但是受限于并没有找到现成的 go 第三方或者官方库，所以就放了一放 （结果放了差不多一年），刚好这几天在改面板的代码，索性就顺手把它做了。\n进程查看没有库可以调用，就只能通过调用系统命令来进行查看，一般来说我看进程会使用 ps -aux，但是对于面板来说，这里输出的数据有点太多以及有点太乱（太乱指的是输出的数据不是计算机友好型结构），然后看了下网上网友们五花八门的命令，左拼右凑之后，最后成品是用的 ps axc -o pid,user,stat,pcpu,pmem,command --sort -pcpu --no-header | sed 's/\\ \\+/\\ /g' 最终得到的数据是没有表头、连续空格被替换成一个空格的数据，我感觉这就够了，其余的交给前端处理。\n前端代码截取如下\nlet ps = server.Ps.split(\u0026#39;\\n\u0026#39;); ps.forEach(item = \u0026gt;{ if (item.split(\u0026#34; \u0026#34;).length \u0026gt; 3) { item = item.split(\u0026#34; \u0026#34;) if (item[0] === \u0026#34;\u0026#34;) { item = item.slice(1, item.length) } let i = { PID: item[0], User: item[1], State: item[2], Pcpu: item[3], Pmem: item[4], Command: item.","title":"Linux 进程信息格式化"},{"content":"2020 年的开头我们并不知道接下来的这一年是那么的艰难，幸好春节前我就已经在某些地方得知了疫情的消息并且准备了一些口罩，减轻了疫情高峰期时口罩的使用压力。\nBilibili 跨年晚会仿佛就发生在昨天，又到了 2020 年的圣诞节，得开始写年度总结了，总感觉这一年啥都没有干就到年末了（\n博客写了啥 寒假刚放假回到家重整了一下家里的网络，所以就有了这篇 配置 IPTV-NET VLAN 单线复用\nArchlinux 系统体验报告 写了下我使用 Archlinux 的体验，实际上是 水文章 传教\n普普通通的折腾\n Tiny File Manager 使用 Joplin：笔记软件的新选择 Notion：好用的现代笔记软件 liunx jetbrains 软件输入中文 git 同步上游代码 编译安装 python 3.9 使用 Webdav 备份  更新了下 hexo 主题、给博客加进了图片渐进式加载的特性: 博客主题更新 \u0026amp;\u0026amp; 一些碎碎念\n给管理的 VPS 增加了登录推送提醒功能，提高(有限的)安全性: vps 登录推送\n然后之前服役的 Oneplus6 顺利退(mai)役(diao) 然后入手了一部 Oneplus8T: Oneplus 8T 到手，实际上没过多久我又买了台 Google Pixel 1，还(gu)没(gu)来(gu)得(gu)及(gu)写(gu)。\n按照惯例写参加了每年举办的 USTC Hackergame，也是第一次写 writeup: Hackergame 2020 writeups\n还有还有，手残的我做了一个可以放在桌面上的天气时钟摆件: NodeMCU 制作桌面天气时钟，这个摆件自带空气质量检测功能，摆在桌子上还是不错的\n代码写了啥 GITHUB 照惯例上绿点图\n今年新写了啥呢 RssReader: 实在是找不到简单又好用的跨平台 RSS 阅读器了，索性就自己做了一个，顺便练下 Vue，加了 PWA 之后手机上的使用体验跟 App 已经相差不大了\nWeather-Card: 结合硬件的一个代码项目，主要就是一个天气摆件，天气数据是从和风天气的接口获取的，NodeMCU 是真的好用\nOh-My-Profiles: 用python 写的一个集中存放配置文件的脚本，自动将你指定的文件归在同一个文件夹内并软链接到它原来的位置，同时提供加密压缩\nCanteen-Go: 私有项目，安卓期末项目的后端，使用 Go+echo+gorm 编写\nschoolDaily: 一个私有项目，主要是方便我学校生活的，有电费监控、学分计算啥的，前端随便写写，后端用的 python\n还在维护啥? johnpoint.github.io: 博客的本体肯定是有在维护的，最近还把自动构建从 Trvais 改到 Github Action\nControlCenter-\u0026gt;Server/Client/Web: 这个也在维护，打算晚点加入自动签发证书的功能\nhexo-theme-XvA: 还会改改 CSS 之类的，大量改动可能要等放假才有空了\n博客今年怎么样 还是那个样\u0026hellip;\n 今年更新了 16篇文章(包括本文) 友链增加了 0个大佬 评论 0条(嘤嘤嘤，永远没有人评论)  完整数据-Google Sheet\n参与了啥活动  GDG devfest GuangZhou  还有啥想说 不知不觉也写了不少，看起来今年还是过得挺充实的嘛，从 10 月份开始，我也开始记账了，主要是想知道我平时的花销都在哪里 结果发现VPS占了好大一部分开支，2020 也快要过去了，希望 2021 年我技术水平再提升下吧，也快要出去实习了，心慌张.jpg\n","permalink":"https://blog.lvcshu.com/2020/12/23/2020%E5%B9%B4%E5%BA%A6%E7%AE%80%E6%8A%A5/","summary":"\u003cp\u003e2020 年的开头我们并不知道接下来的这一年是那么的艰难，幸好春节前我就已经在某些地方得知了疫情的消息并且准备了一些口罩，减轻了疫情高峰期时口罩的使用压力。\u003c/p\u003e\n\u003cp\u003eBilibili 跨年晚会仿佛就发生在昨天，又到了 2020 年的圣诞节，得开始写年度总结了，总感觉这一年啥都没有干就到年末了（\u003c/p\u003e","title":"2020 年度简报"},{"content":"其实我眼馋青萍空气检测仪很久了，但是要700+的价格实在是下不了手，于是萌生了自己做一个类似的桌面摆件的想法，一方面是想尝试下制作包含硬件的小玩意，一方面确实是想整一个摆件放在桌面。\n选型 芯片 在正式开始采购元件以及编码之前要先选定这个摆件将要采用的元件，因为是第一次真正意义上做这种加入了硬件的摆件，所以选择了对新手比较友好的 NodeMCU 上面有 ESP8266 芯片，这样的话就可以同时解决网络通信的问题，同时 NodeMCU 支持 Arduino 方式编程，这就很方便了，网上有各种各样的库可以给我调用。\n屏幕 由于是桌面摆件肯定要有个界面展示出来，OLED 屏幕成本太高了不考虑，最终选定了 ST7796 这块带触摸的 4 英寸 TFT 屏幕，一方面是价格还可以接受，另一方面是触摸屏也可以方便后续可以满足我可能突然想做触摸交互功能的想法（也许会一直只是想做）。\n传感器 PM2.5 什么的数据公开的 API 其实已经够了，其实青萍空气检测仪打动我的点是那个二氧化碳检测的功能，所以这个摆件的二氧化碳检测功能是肯定要安排上的，空气检测模块就在淘宝那里找了个 SGP30，这个模块可以检测 CO2和 TVOC，也够用了。\n编码 其实写这篇文章的时候，这个摆件的主要功能已经写完了，目前有这些功能\n OTA 升级，不用插 USB 就可以刷新固件 保存配置文件开机进行自动配置 WIFI 连接失败自身开启热点让用户进行配网 WEB 界面修改配置 WEB 界面管理密码验证 NTP 校对时间 通过和风天气 API 获取天气数据 监测 CO2 和 TVOC 天气预警信息显示 白天黑夜天气图标切换  引用库 TFT_eSPI.h SPI.h TFT屏幕驱动 https://github.com/Bodmer/TFT_eSPI Arduino_JSON.h JSON 解析 https://github.com/arduino-libraries/Arduino_JSON NTP.h NTP对时 https://github.com/sstaub/NTP Adafruit_SGP30.h SGP30 驱动 https://github.com/adafruit/Adafruit_SGP30 ArduinoOTA.h OTA 支持 https://github.com/jandrassy/ArduinoOTA ESP8266WiFi.h\u0026gt; ESP8266WiFiMulti.h ESP8266HTTPClient.h FS.h LittleFS.h WiFiClient.h ESP8266WebServer.h https://github.com/esp8266/Arduino 天气图标 天气图标由于我不想转换图片格式所以我选择自己用 TFT_eSPI 库里面的绘图函数自己重新绘制图标，但是由于太懒，所以目前只绘制了我这边有出现过的天气，然后我又想不能晚上也显示太阳吧，于是又绘制了一部分图标，加上了夜晚图标切换功能。\nAPI 代理 在调试 api 的过程中我发现和风天气 API 有些地方返回的数据太多了，有些数据用不上，然后数据量太多有可能会触发软件看门狗导致 Reset，所以用 python 的 flask 糊了个洗数据的服务端。\n成品 欢迎给我 Star~ https://github.com/johnpoint/Weather-Card\n本体 WEB 管理界面 后续 后续打算想想怎么把屏幕的布局改一下，右下角似乎有一些空，然后有可能做个 3D 打印的外壳。\n嗯，ESP8266 真香，玩硬件真的是好容易产生 快感(??) 成就感。\n","permalink":"https://blog.lvcshu.com/2020/12/02/esp8266-weather-card/","summary":"\u003cp\u003e其实我眼馋青萍空气检测仪很久了，但是要700+的价格实在是下不了手，于是萌生了自己做一个类似的桌面摆件的想法，一方面是想尝试下制作包含硬件的小玩意，一方面确实是想整一个摆件放在桌面。\u003c/p\u003e","title":"NodeMCU 制作桌面天气时钟"},{"content":"webdav 服务端 使用 cloudreve 自带 webdav\n客户端 cadaver\n备份 记录登录信息 .netrc\nmachine WEBDAVURL login USERNAME password PASSWORD 使用脚本 figlet webdav backup echo \u0026#34;==========================================================================\u0026#34; export t=`date +%Y-%m-%d` echo \u0026#34;Backup: \u0026#34; $t printf \u0026#34;集中配置文件 [执行中]\u0026#34; mkdir config cp .ssh/config config ...... printf \u0026#34;\\r集中配置文件 [完成] \\n\u0026#34; printf \u0026#34;归档配置文件 [执行中]\u0026#34; zip -q backup.zip config -r rm config -rf printf \u0026#34;\\r归档配置文件 [完成] \\n\u0026#34; ...... printf \u0026#34;\\r归档密钥文件 [完成] \\n\u0026#34; echo \u0026#34;put backup-\u0026#34;$t\u0026#34;.zip\u0026#34; \u0026gt; webdav echo \u0026#34;bye\u0026#34; \u0026gt;\u0026gt; webdav cadaver WEBDAVURL \u0026lt; webdav rm webdav rm backup-$t.zip echo \u0026#34;==========================================================================\u0026#34; printf \u0026#34;备份完成\u0026#34; ","permalink":"https://blog.lvcshu.com/2020/11/07/webdav-backup/","summary":"webdav 服务端 使用 cloudreve 自带 webdav\n客户端 cadaver\n备份 记录登录信息 .netrc\nmachine WEBDAVURL login USERNAME password PASSWORD 使用脚本 figlet webdav backup echo \u0026#34;==========================================================================\u0026#34; export t=`date +%Y-%m-%d` echo \u0026#34;Backup: \u0026#34; $t printf \u0026#34;集中配置文件 [执行中]\u0026#34; mkdir config cp .ssh/config config ...... printf \u0026#34;\\r集中配置文件 [完成] \\n\u0026#34; printf \u0026#34;归档配置文件 [执行中]\u0026#34; zip -q backup.zip config -r rm config -rf printf \u0026#34;\\r归档配置文件 [完成] \\n\u0026#34; ...... printf \u0026#34;\\r归档密钥文件 [完成] \\n\u0026#34; echo \u0026#34;put backup-\u0026#34;$t\u0026#34;.zip\u0026#34; \u0026gt; webdav echo \u0026#34;bye\u0026#34; \u0026gt;\u0026gt; webdav cadaver WEBDAVURL \u0026lt; webdav rm webdav rm backup-$t.","title":"使用 Webdav 备份"},{"content":"最终成绩 Sat Nov 7 09:59:22 AM CST 2020 当前分数：1500， 总排名：225 / 2415 binary：0 ， general：850 ， math：300 ， web：350 啊，我真的是太菜了（\n只做出了一点点题目\n签到 谢邀，利益相关：老签到出题人了。 今年出题组的要求是「来参加我们比赛的同学很多都是初学者，我们的签到题要清晰明确一点，让同学们轻松签到。」 我完全明白了，签到题就是送 flag，送就送，我最会送了.jpg 首先写好题目介绍：「你需要点击下面蓝色的 “打开/下载题目” 按钮，在打开的网页上获取到形如 flag{...} 的 flag，回到本页面，将其完整填写到下面的文本框中，并点击灰色的 “提交” 按钮即可完成本题。」 然后写一个 flag 提取器，选手要多少个 flag，我就给多少个 flag，绿色背景，红色加粗，显眼的位置，标准的格式，这都不叫送，那还有什么叫做送。 点击 「打开/下载题目」 按钮，打开 flag 提取器，获取第一个 flag 吧！ 提示：完成题目遇到困难？你可以参考 2018 年签到题题解 与 2019 年签到题题解。 F12 定位到拖动条，将最大值改为 1 然后将条拖到最大就可以得到 flag\n\u0026lt;input type=\u0026#34;range\u0026#34; id=\u0026#34;number\u0026#34; name=\u0026#34;number\u0026#34; class=\u0026#34;form-control\u0026#34; value=\u0026#34;0\u0026#34; min=\u0026#34;0\u0026#34; max=\u0026#34;1\u0026#34; step=\u0026#34;0.00001\u0026#34;\u0026gt; 猫咪问答++ 在科大西区的研究生食堂旁边，有块水泥石板盛产肥猫。 每一个晴朗的中午，其上都会有花花白白的猫咪慵懒地晒着太阳。 而许多吃完午饭的同学，也可以趁此良机大肆撸猫。 但是突然从某一天起，水泥石板上多了一只猫首猫身的动物，拦住前来撸猫的同学，用它精心准备好的谜语考验他们。 只有全部答对了才可以撸猫，如果不小心答错了它就会炸毛给你看。 为了让每日撸猫活动恢复正轨，热心的 LUG 协会同学把这些谜题放到了这里。 如果你能答对所有的谜题，就会有 flag 作为奖励。 提示：正如撸猫不必亲自到现场，解出谜题也不需要是科大在校学生。解题遇到困难？你可以参考 2018 年猫咪问答题解。  手动数，数量为 12 搜索到了 wikipedia -\u0026gt; RFC1149   A typical MTU is 256 milligrams. Some datagram padding may be needed.\n  https://ftp.lug.ustc.edu.cn/活动/2019.09.21_SFD/slides/闪电演讲/Teeworlds/ \u0026ndash;\u0026gt; Teeworlds 答案 9\n  百度地图街景手动数 答案 9\n  https://news.ustclug.org/2019/12/hackergame-2019/ \u0026ndash;\u0026gt; 答案 17098\n  2048 路漫漫其修远兮，FLXG 永不放弃！ 要实现 FLXG，你需要过人的智慧，顽强的意志，和命运的眷属。只有在 2048 的世界里证明自己拥有这些宝贵的品质，实现「大成功」，你才有资格扛起 FLXG 的大旗。 真就是 2048，看下 js 文件，发现里面有个 game_manager.js，粗略的浏览下逻辑，发现这么一句\nif (merged.value === 16384) self.won = true; 打断点，手动修改变量值，就成功了\n一闪而过的 Flag 深秋清晨，也西湖畔。一位可怜的同学蜷在路边的长椅上，用粗糙的手指敲击着残旧的神船笔记本，反复试图打开桌面上的一个程序。程序每次运行时隐约可见黑色控制台上有 flag 一闪而过。 在他的脚边搭着一块用废弃纸箱剪成的牌子，上面写着「我很可爱，请给我 flag」。路上的人行色匆匆，而那地上用来盛 flag 的饭盒依旧空空如也。 一位诗人同学路过，见此情景，遂把牌子改成了：「flag 来了，可是我什么也看不见！」 而你作为一名新生，不由动了恻隐之心。望着诗人潇洒远去的背影，你可以赶在下午诗人回来之前，帮助这位可怜的人，用 flag 装满他的饭盒吗? 啊这、啊这，我觉得这个 flag 是白给的啊，程序运行以后我瞬间截图就可以拿到 flag 了，之前还以为要录像逐帧判断\u0026hellip;\n从零开始的记账工具人 如同往常一样，你的 npy 突然丢给你一个购物账单：“我今天买了几个小玩意，你能帮我算一下一共花了多少钱吗？” 你心想：又双叒叕要开始吃土了 这不是很简单吗？电子表格里面一拖动就算出来了 只不过拿到账单之后你才注意到，似乎是为了剁手时更加的安心，这次的账单上面的金额全使用了中文大写数字 注意：请将账单总金额保留小数点后两位，放在 flag{} 中提交，例如总金额为 123.45 元时，你需要提交 flag{123.45} 文件下载\n首先另存为 csv，使用 python 将 csv 转换为 json 下面比较好处理\n统计源代码:\nimport json def cover(i): for j in range(0, len(text)): if text[j] == i: return j yuan = 0 jiao = 0 fen = 0 text = [\u0026#34;零\u0026#34;, \u0026#34;壹\u0026#34;, \u0026#34;贰\u0026#34;, \u0026#34;叁\u0026#34;, \u0026#34;肆\u0026#34;, \u0026#34;伍\u0026#34;, \u0026#34;陆\u0026#34;, \u0026#34;柒\u0026#34;, \u0026#34;捌\u0026#34;, \u0026#34;玖\u0026#34;, \u0026#34;拾\u0026#34;] with open(\u0026#39;bills.json\u0026#39;, \u0026#39;r\u0026#39;) as f: a = json.load(f) for i in a: y = i[\u0026#34;mon\u0026#34;].split(\u0026#34;元\u0026#34;) num = int(i[\u0026#34;num\u0026#34;]) for j in y: if \u0026#34;角\u0026#34; in j: jj = j.split(\u0026#34;角\u0026#34;) jiao += cover(jj[0])*num if len(jj) \u0026gt; 1 and \u0026#34;分\u0026#34; in jj[1]: fen += cover(jj[1].split(\u0026#34;分\u0026#34;)[0])*num continue if \u0026#34;分\u0026#34; in j: fen += cover(j.split(\u0026#34;分\u0026#34;)[0].replace(\u0026#34;零\u0026#34;, \u0026#34;\u0026#34;))*num continue for i in range(0, len(j)): if j[i] == \u0026#34;整\u0026#34;: continue if j[i] == \u0026#34;佰\u0026#34;: continue if i+1 \u0026lt; len(j): if j[i+1] == \u0026#34;拾\u0026#34;: yuan += cover(j[i])*10*num elif j[i+1] == \u0026#34;佰\u0026#34;: yuan += cover(j[i])*100*num else: if j[i] != \u0026#34;拾\u0026#34; and j[i] != \u0026#34;佰\u0026#34;: yuan += cover(j[i])*num if i-1 \u0026lt; 0 and j[i] == \u0026#34;拾\u0026#34;: yuan += 10*num jiao += int(fen/10) fen = fen % 10*0.01 yuan += int(jiao/10) jiao = jiao % 10*0.1 print(yuan+jiao+fen) print(\u0026#34;y\u0026#34;, yuan) print(\u0026#34;j\u0026#34;, jiao) print(\u0026#34;f\u0026#34;, fen) 答案 20262.53\n来自一教的图片 小 P 在一教做傅里叶光学实验时，在实验室电脑的模拟程序里发现了这么一张的图片： 数理基础并不扎实的小 P 并不知道什么东西成像会是这个样子：又或许什么东西都不是，毕竟这只是模拟 ... 但可以确定的是，这些看似奇怪的花纹里确实隐藏着一些信息，或许是地下金矿的藏宝图也未可知。 很简单，题目给足了提示，做一下傅立叶逆变换就可以得到\n超简单的世界模拟器 你知道生命游戏（Conway\u0026#39;s Game of Life）吗？ 你的任务是在生命游戏的世界中，复现出蝴蝶扇动翅膀，引起大洋彼岸风暴的效应。 通过改变左上角 15x15 的区域，在游戏演化 200 代之后，如果被特殊标注的正方形内的细胞被“清除”，你将会得到对应的 flag： “清除”任意一个正方形，你将会得到第一个 flag。同时“清除”两个正方形，你将会得到第二个 flag。 注: 你的输入是 15 行文本，每行由 15 个 0 或者 1 组成，代表该区域的内容。 蝴蝶效应 我的解:\n000000000000000 000000000000000 000000000000000 000000000000000 000000110000000 000001111000000 000001101100000 000000011000000 000000000000000 000000000000000 000000110000000 000001111000000 000001101100000 000000011000000 000000000000000 参考了 知乎:生命游戏（Game of Life）有哪些图形？\n233 同学的 Docker 233 同学在软工课上学到了 Docker 这种方便的东西，于是给自己的字符串工具项目写了一个 Dockerfile。 但是 233 同学突然发现它不小心把一个私密文件（flag.txt）打包进去了，于是写了一行命令删掉这个文件。 「既然已经删掉了，应该不会被人找出来吧？」233 想道。 Docker Hub 地址：8b8d3c8324c7/stringtool\n从 Dockerfile 里面的命令来看\n/bin/sh -c rm /code/flag.txt flag 保存在了 /code 里面\n看起来只需要提取 docker layers 里面的内容就好了，问题是我不会 搜索到了 Is there a way to tag a previous layer in a docker image or revert a commit? \ndocker save imagename $(sudo docker history -q imagename | tail -n +2 | grep -v \\\u0026lt;missing\\\u0026gt; | tr \u0026#39;\\n\u0026#39; \u0026#39; \u0026#39;) \u0026gt; image-caching.tar 使用这命令就把 layers 全部提取出来，接下来就每个 layers 都看看就好了\nflag{Docker_Layers!=PS_Layers_hhh}\n从零开始的火星文生活 一年一度的 Hackergame 就要到了，L 同学打算叫上 Q 同学一起去参加，却一连几天都见不到 Q 同学的人影。然而在比赛开始的前一天晚上却收到了来自 Q 同学的邮件： Subject: 绝密！不要外传！！！ Body: 详情见附件 From: Q L 同学打开附件一看，傻眼了，全都是意义不明的汉字。机智的 L 同学想到 Q 同学平时喜欢使用 GBK 编码，也许是打开方式不对。结果用 GBK 打开却看到了一堆夹杂着日语和数字的火星文…… L 同学彻底懵逼了，几经周折，TA 找到了科大最负盛名的火星文专家 (你)。依靠多年的字符编码解码的经验，你可以破译 Q 同学发来的火星文是什么意思吗？ 注：正确的 flag 全部由 ASCII 字符组成！ 文件内容：\n脦脪鹿楼脝脝脕脣 拢脠拢谩拢茫拢毛拢氓拢貌拢莽拢谩拢铆拢氓 碌脛路镁脦帽脝梅拢卢脥碌碌陆脕脣脣眉脙脟碌脛 拢忙拢矛拢谩拢莽拢卢脧脰脭脷脦脪掳脩 拢忙拢矛拢谩拢莽 路垄赂酶脛茫拢潞 拢忙拢矛拢谩拢莽拢没拢脠拢麓拢枚拢鲁拢脽拢脝拢玫拢脦拢脽拢梅拢卤拢脭拢猫拢脽拢鲁拢卯拢茫拢掳拢盲拢卤拢卯拢莽拢脽拢麓拢脦拢盲拢脽拢盲拢鲁拢茫拢掳拢脛拢卤拢卯拢脟拢脽拢鹿拢帽拢脛拢虏拢脪拢赂拢猫拢贸拢媒 驴矛脠楼卤脠脠眉脝陆脤篓脤谩陆禄掳脡拢隆 虏禄脪陋脭脵掳脩脮芒路脻脨脜脧垄脳陋路垄赂酶脝盲脣没脠脣脕脣拢卢脪陋脢脟卤禄路垄脧脰戮脥脭茫赂芒脕脣拢隆 额。。。这题目，我搜索 拢 utf8 的时候正好搜到了 代码中包含的中文全为乱码，编码问题求请教！ 然后看了下回答\nalcarl 2018-01-09 01:25:21 +08:00 via Android ❤️ 3 先把这段字保存成 gb2312 编码的文件，然后转换成 utf8 编码，保存，然后再转换成 8859-1 保存，然后当成 gbk 打开就好了，=͟͟͞͞(꒪ᗜ꒪ ‧̣̥̇) 字是下面这样的 类：包含对文件的操作（为了便于调试和观察，我把网页信息写入了文件中，所以有了这个文件操作类） 参考 http://blog.zeerd.com/ffmpeg-c2c3-bug/ 然后按照这操作就\u0026hellip;.就出来了\u0026hellip;\n我攻破了 Ｈａｃｋｅｒｇａｍｅ 的服务器，偷到了它们的 ｆｌａｇ，现在我把 ｆｌａｇ 发给你： ｆｌａｇ｛Ｈ４ｖ３＿ＦｕＮ＿ｗ１Ｔｈ＿３ｎｃ０ｄ１ｎｇ＿４Ｎｄ＿ｄ３ｃ０Ｄ１ｎＧ＿９ｑＤ２Ｒ８ｈｓ｝ 快去比赛平台提交吧！ 不要再把这份信息转发给其他人了，要是被发现就糟糕了！ 从零开始的 HTTP 链接 众所周知，数组下标应当从 0 开始。 同样的，TCP 端口也应当从 0 开始。为了实践这一点，我们把一个网站架设在服务器的 0 号端口上。 你能成功连接到 0 号端口并拿到 flag 吗？ 点击下面的打开题目按钮是无法打开网页的，因为普通的浏览器会认为这是无效地址。 地址: http://202.38.93.111:0/\n从题目就可以看出来，应该自己构造 http 请求就可以得到 flag\n我的解法：\n网上找了个 C 实现的 http get (来源)\n#include \u0026lt;stdio.h\u0026gt;#include \u0026lt;sys/socket.h\u0026gt;#include \u0026lt;sys/types.h\u0026gt;#include \u0026lt;time.h\u0026gt;#include \u0026lt;errno.h\u0026gt;#include \u0026lt;signal.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;string.h\u0026gt;#include \u0026lt;unistd.h\u0026gt;#include \u0026lt;sys/wait.h\u0026gt;#include \u0026lt;sys/time.h\u0026gt;#include \u0026lt;netinet/in.h\u0026gt;#include \u0026lt;arpa/inet.h\u0026gt; #define IPSTR \u0026#34;202.38.93.111\u0026#34; //服务器IP地址; #define PORT 0 #define BUFSIZE 1024  int main(int argc, char **argv) { int sockfd, ret, i, h; struct sockaddr_in servaddr; char str1[4096], str2[4096], buf[BUFSIZE], *str; socklen_t len; fd_set t_set1; struct timeval tv; //创建套接字  if ((sockfd = socket(AF_INET, SOCK_STREAM, 0)) \u0026lt; 0 ) { printf(\u0026#34;创建网络连接失败,本线程即将终止---socket error!\\n\u0026#34;); exit(0); }; bzero(\u0026amp;servaddr, sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_port = htons(PORT); if (inet_pton(AF_INET, IPSTR, \u0026amp;servaddr.sin_addr) \u0026lt;= 0 ){ printf(\u0026#34;创建网络连接失败,本线程即将终止--inet_pton error!\\n\u0026#34;); exit(0); }; if (connect(sockfd, (struct sockaddr *)\u0026amp;servaddr, sizeof(servaddr)) \u0026lt; 0){ printf(\u0026#34;连接到服务器失败,connect error!\\n\u0026#34;); exit(0); } printf(\u0026#34;与远端建立了连接\\n\u0026#34;); memset(str2, 0, 4096); str=(char *)malloc(128); len = strlen(str2); sprintf(str, \u0026#34;%d\u0026#34;, len); memset(str1, 0, 4096); strcat(str1, \u0026#34;GET / HTTP/1.1\\n\u0026#34;); strcat(str1, \u0026#34;Host: 202.38.93.111\\n\u0026#34;); strcat(str1, \u0026#34;\\n\\n\u0026#34;); // strcat(str1, str2);  strcat(str1, \u0026#34;\\r\\n\\r\\n\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;,str1); ret = write(sockfd,str1,strlen(str1)); if (ret \u0026lt; 0) { printf(\u0026#34;发送失败！错误代码是%d，错误信息是\u0026#39;%s\u0026#39;\\n\u0026#34;,errno, strerror(errno)); exit(0); }else{ printf(\u0026#34;消息发送成功，共发送了%d个字节！\\n\\n\u0026#34;, ret); } FD_ZERO(\u0026amp;t_set1); FD_SET(sockfd, \u0026amp;t_set1); while(1){ sleep(2); tv.tv_sec= 0; tv.tv_usec= 0; h= 0; // printf(\u0026#34;---------------\u0026gt;1\\n\u0026#34;);  h= select(sockfd +1, \u0026amp;t_set1, NULL, NULL, \u0026amp;tv); // printf(\u0026#34;---------------\u0026gt;2\\n\u0026#34;);  //if (h == 0) continue;  if (h \u0026lt; 0) { close(sockfd); printf(\u0026#34;在读取数据报文时SELECT检测到异常，该异常导致线程终止！\\n\u0026#34;); return -1; }; if (h \u0026gt; 0){ memset(buf, 0, 4096); i= read(sockfd, buf, 4095); if (i==0){ close(sockfd); printf(\u0026#34;读取数据报文时发现远端关闭，该线程终止！\\n\u0026#34;); return -1; } printf(\u0026#34;%s\\n\u0026#34;, buf); break; } } close(sockfd); return 0; } 得到 index.html 文件获知关键信息\n\u0026lt;script\u0026gt; const term = new Terminal(); const fitAddon = new FitAddon.FitAddon(); term.loadAddon(fitAddon); term.open(document.getElementById(\u0026#34;terminal\u0026#34;)); fitAddon.fit(); window.addEventListener(\u0026#39;resize\u0026#39;, function(event) { fitAddon.fit(); }); var firstmsg = true; const socket = new WebSocket( \u0026#34;ws://202.38.93.111:0/shell\u0026#34; ); const attachAddon = new AttachAddon.AttachAddon(socket); term.loadAddon(attachAddon); socket.onclose = event =\u0026gt; { term.write(\u0026#34;\\nConnection closed\u0026#34;); }; socket.onmessage = event =\u0026gt; { if (firstmsg) { firstmsg = false; let token = new URLSearchParams(window.location.search).get(\u0026#34;token\u0026#34;); window.history.replaceState({}, null, \u0026#39;/\u0026#39;); if (token) { localStorage.setItem(\u0026#39;token\u0026#39;, token); } else { token = localStorage.getItem(\u0026#39;token\u0026#39;); } if (token) socket.send(token + \u0026#34;\\n\u0026#34;); } }; term.focus(); \u0026lt;/script\u0026gt; 然后又整了个 C++ 的 websocket，连上他的服务器，发送 token，flag 到手\neasywsclient: connecting: host=202.38.93.111 port=0 path=/shell Connected to: ws://202.38.93.111:0/shell \u0026gt;\u0026gt;\u0026gt; 2533:MEUCIQCz8PiKvLdy1K7+TZJTwqM581W17UdJRfk3Q6hxPtr6sQIgb+Cy14NALA4ETpFQfXyfDhIxz10fyy0+t7GDEhEpS3c= \u0026gt;\u0026gt;\u0026gt; Please input your token: \u0026gt;\u0026gt;\u0026gt; flag{TCP_P0RT_0_1s_re5erved_BUT_w0rks_e7e56860a1} 不经意传输 解密消息 某同学在某不知名百科网站上看到一个神奇的密码学协议，叫做「不经意传输」（Oblivious transfer）。 于是他按照网站上描述的「1–2 oblivious transfer」自己实现了协议中一方的逻辑，你可以作为另一方与之进行交互。 完全按照百科网站上的算法来实现的协议应该不会有什么问题吧？ 点击下载 源代码 除了网页终端，你也可以通过 nc 202.38.93.111 10031 来连接 源代码\n搜索一下题目里面的 1–2 oblivious transfer 查到了 这个\n然后打开 python 照上面的步骤一步一步就可以拿到解密的消息\nflag{U_R_0n_Th3_ha1f_way_0f_succe55_w0rk_h4rder!_163a930598}\n超安全的代理服务器 找到 Secret 在 2039 年，爆发了一场史无前例的疫情。为了便于在各地的同学访问某知名大学「裤子大」的网站进行「每日健康打卡」，小 C 同学为大家提供了这样一个代理服务。曾经信息安全专业出身的小 C 决定把这个代理设计成最安全的代理。 提示：浏览器可能会提示该 TLS 证书无效，与本题解法无关，信任即可。 公告：题目帮助页面（https://146.56.228.227/help）右下角的「管理中心」链接有误，应该与首页相同，都是指向 http://127.0.0.1:8080/ 地址 https://146.56.228.227/\n首先进入页面看看～\nNotice: 我们已经向您 推送（PUSH） 了最新的 Secret ，但是你可能无法直接看到它。 去 google 了一下，找到了 How to Test HTTP/2 Push using Google Chrome 按照里面的指引，安装了 HTTP/2 and SPDY indicator 扩展，打开以后看到了\nThe net-internals events viewer and related functionality has been removed. Please use chrome://net-export to save netlogs and the external netlog_viewer to view them. 导出了一下 log，然后在 netlog_viewer 里面寻找这一个 http/2 会话，然后很容易就可以看到\nt=1410 [st=281729] HTTP2_SESSION_SEND_RST_STREAM --\u0026gt; description = \u0026#34;Duplicate pushed stream with url: https://146.56.228.227/e3b2a173-d763-409e-807c-584d13a10c92\u0026#34; --\u0026gt; error_code = \u0026#34;7 (REFUSED_STREAM)\u0026#34; --\u0026gt; stream_id = 6 访问上面出现的 url，获得 flag flag{d0_n0t_push_me}\n参考链接  维基百科: 以鸟类为载体的网际协议 USTC LUG FTP 百度地图-街景 USTC LUG NEWS stackoverflow: How to convert CSV file to multiline JSON? 知乎: 生命游戏（Game of Life）有哪些图形？ stackoverflow: Is there a way to tag a previous layer in a docker image or revert a commit?  v2ex: 代码中包含的中文全为乱码，编码问题求请教！ CSDN: C语言实现HTTP的GET和POST请求-一路奔跑94 github: core1011/websocket wikipedia: Oblivious_transfer How to Test HTTP/2 Push using Google Chrome  ","permalink":"https://blog.lvcshu.com/2020/11/04/2020-hackergame-writeups/","summary":"最终成绩 Sat Nov 7 09:59:22 AM CST 2020 当前分数：1500， 总排名：225 / 2415 binary：0 ， general：850 ， math：300 ， web：350 啊，我真的是太菜了（\n只做出了一点点题目\n签到 谢邀，利益相关：老签到出题人了。 今年出题组的要求是「来参加我们比赛的同学很多都是初学者，我们的签到题要清晰明确一点，让同学们轻松签到。」 我完全明白了，签到题就是送 flag，送就送，我最会送了.jpg 首先写好题目介绍：「你需要点击下面蓝色的 “打开/下载题目” 按钮，在打开的网页上获取到形如 flag{...} 的 flag，回到本页面，将其完整填写到下面的文本框中，并点击灰色的 “提交” 按钮即可完成本题。」 然后写一个 flag 提取器，选手要多少个 flag，我就给多少个 flag，绿色背景，红色加粗，显眼的位置，标准的格式，这都不叫送，那还有什么叫做送。 点击 「打开/下载题目」 按钮，打开 flag 提取器，获取第一个 flag 吧！ 提示：完成题目遇到困难？你可以参考 2018 年签到题题解 与 2019 年签到题题解。 F12 定位到拖动条，将最大值改为 1 然后将条拖到最大就可以得到 flag\n\u0026lt;input type=\u0026#34;range\u0026#34; id=\u0026#34;number\u0026#34; name=\u0026#34;number\u0026#34; class=\u0026#34;form-control\u0026#34; value=\u0026#34;0\u0026#34; min=\u0026#34;0\u0026#34; max=\u0026#34;1\u0026#34; step=\u0026#34;0.00001\u0026#34;\u0026gt; 猫咪问答++ 在科大西区的研究生食堂旁边，有块水泥石板盛产肥猫。 每一个晴朗的中午，其上都会有花花白白的猫咪慵懒地晒着太阳。 而许多吃完午饭的同学，也可以趁此良机大肆撸猫。 但是突然从某一天起，水泥石板上多了一只猫首猫身的动物，拦住前来撸猫的同学，用它精心准备好的谜语考验他们。 只有全部答对了才可以撸猫，如果不小心答错了它就会炸毛给你看。 为了让每日撸猫活动恢复正轨，热心的 LUG 协会同学把这些谜题放到了这里。 如果你能答对所有的谜题，就会有 flag 作为奖励。 提示：正如撸猫不必亲自到现场，解出谜题也不需要是科大在校学生。解题遇到困难？你可以参考 2018 年猫咪问答题解。  手动数，数量为 12 搜索到了 wikipedia -\u0026gt; RFC1149   A typical MTU is 256 milligrams.","title":"Hackergame 2020 writeups"},{"content":"来了来了，Android R 他朝我们走来了\n刚刚忍不住剁手了香气四溢的 Oneplus 8T，也把我手中的已经伊拉克成色的 Oneplus 6 给以旧换新处理掉了，就例行来说一下 Android 11 以及这个看起来很香的 Oneplus 8T 的体验\n这次拿到手 1+ 8T 默认搭载的是国内的 H2OS 系统，也是安卓11,但是由于我想体验更多的原生的功能以及软件，所以就在一加官网想找 1+ 8T 的 OTA 包，结果发现并没有，最后在 [XDA论坛找到了包]，顺便就把手机解锁 + Root 一口气搞定了。\n其中有个小插曲就是在安装 Riru - Enhanced mode for Storage Isolation (Storage Redirect) 后手机起不来了，有可能是兼容性的问题，在折腾了几个热心群友提供的方法后还是没有解决问题，想着手机里面也没有啥资料索性就重置手机了。\n搞定了一堆帐号登录之类的事情之后终于可以安心的进入系统看看。\nemmmmm 满满的 OneUI 风格，有一说一还是挺好看的。\n跟随系统安装的软件有 一加社区、一加搬家、亚马逊、网飞等，除了网飞之外的大部分预装软件都可以卸载掉。\n设置界面 UI + 氧视窗 Google Assistant 今日日程 这个日程提醒真的方便好用，特别是我这种要看在哪里上课的人。\n充电屏保 自定义各种东西 锁屏 通知栏 使用体验 终于用上了高刷屏幕，有一说一区别还是很大的，动画效果柔滑了很多，相对的电量消耗感觉就变大了，这次 65W 的充电功率也很顶，就是充电头有点大，上图给你们看下\n续航和装了什么软件来压制国内软件毒瘤晚点写（或许\n","permalink":"https://blog.lvcshu.com/2020/10/21/oneplus-8t/","summary":"\u003cp\u003e\u003cdel\u003e来了来了，Android R 他朝我们走来了\u003c/del\u003e\u003c/p\u003e\n\u003cp\u003e刚刚忍不住剁手了香气四溢的 Oneplus 8T，也把我手中的已经伊拉克成色的 Oneplus 6 给以旧换新处理掉了，就例行来说一下 Android 11 以及这个看起来很香的 Oneplus 8T 的体验\u003c/p\u003e","title":"Oneplus 8T 到手"},{"content":"环境 Ubuntu 20.04.1 LTS focal x86_64\n下载 \u0026amp;\u0026amp; 解压缩 wget https://www.python.org/ftp/python/3.9.0/Python-3.9.0.tar.xz 解压xz文件需要软件包 xz-utils\ntar -Jxvf Python-3.9.0.tar.xz 编译 \u0026amp;\u0026amp; 安装 cd Python-3.9.0 ./configure make make install 错误解决方法 No module named zlib 编译步骤中使用 ./configure --with-zlib pip is configured with locations that require TLS/SSL, however the ssl module in Python is not available. 安装软件包\nlibssl-dev libncurses5-dev libsqlite3-dev libreadline-dev libtk8.5 libgdm-dev libdb4o-cil-dev libpcap-dev ","permalink":"https://blog.lvcshu.com/2020/10/09/upgrade-to-python-3.9/","summary":"环境 Ubuntu 20.04.1 LTS focal x86_64\n下载 \u0026amp;\u0026amp; 解压缩 wget https://www.python.org/ftp/python/3.9.0/Python-3.9.0.tar.xz 解压xz文件需要软件包 xz-utils\ntar -Jxvf Python-3.9.0.tar.xz 编译 \u0026amp;\u0026amp; 安装 cd Python-3.9.0 ./configure make make install 错误解决方法 No module named zlib 编译步骤中使用 ./configure --with-zlib pip is configured with locations that require TLS/SSL, however the ssl module in Python is not available. 安装软件包\nlibssl-dev libncurses5-dev libsqlite3-dev libreadline-dev libtk8.5 libgdm-dev libdb4o-cil-dev libpcap-dev ","title":"编译安装 python 3.9"},{"content":"国内的云服务器大多数都自带了 ssh 登录提示功能，这个功能我觉得不错，但是在很多并没有深度定制系统镜像的云服务器服务商那里就没有远程登录提醒功能了，于是写了一个小脚本来实现远程登录就将登录信息推送至 telegram 的功能\n文件名 00-ssh-login-alarm-telegram.sh (其实也可以自己自定义)，将文件放在 /etc/profile.d 目录下。\n#!/bin/bash  #填入 telegram bot 的 token token= #填自己telegram的id id= #vps ip vpsip=$(curl -s ip.sb -4) #登录时间 logintime=$(TZ=UTC-8 date \u0026#39;+%Y-%m-%d %H:%M:%S\u0026#39;) #远程登录的ip loginip=$(who -u am i 2\u0026gt;/dev/null| awk \u0026#39;{print $NF}\u0026#39;|sed -e \u0026#39;s/[()]//g\u0026#39;) #ip归属asn组织名称 loginfrom=$(curl -s https://api.ip.sb/geoip/${loginip} | jq .asn_organization) curl -s \u0026#34;https://api.telegram.org/bot${token}/sendMessage?chat_id=${id}\u0026#34; --data-binary \u0026#34;\u0026amp;text=NewLogin:%0AVPS: ${vpsip}%0ATime: ${logintime}%0ALogin from:%0A${loginip}%0A${loginfrom}\u0026#34; \u0026gt; /dev/null 因为用到了 jq 作为解析 json 的工具，所以需要在包管理器中自行安装。\n使用效果：\nNewLogin: VPS: ***.***.***.*** Time: 2020-09-13 12:41:24 Login from: ***.***.***.*** \u0026#34;asn_organization\u0026#34; 脚本使用的 api 来自 ip.sb\n2021-10-20 更新 脚本中间更新了几个版本，现在的脚本已经可以实现之前所缺少的一些功能\n 显示登录用户名 不阻塞登录用户的 TTY  #!/bin/bash  #填入 telegram bot 的 token token= #填自己telegram的id id= localip=$(who -u am i 2\u0026gt;/dev/null| awk \u0026#39;{print $NF}\u0026#39;|sed -e \u0026#39;s/[()]//g\u0026#39;) echo \u0026#39;localip=$(curl -s ip.sb -4)\u0026#39; \u0026gt; tg.sh echo \u0026#39;user=$(whoami)\u0026#39; \u0026gt;\u0026gt; tg.sh echo \u0026#39;logintime=$(TZ=UTC-8 date \u0026#34;+%Y-%m-%d %H:%M:%S\u0026#34;)\u0026#39; \u0026gt;\u0026gt; tg.sh echo \u0026#39;loginip=\u0026#39;${localip} \u0026gt;\u0026gt; tg.sh echo \u0026#39;loginfrom=$(curl -s https://api.ip.sb/geoip/${loginip} | jq -r .asn_organization)\u0026#39; \u0026gt;\u0026gt; tg.sh echo \u0026#39;curl -s \u0026#34;https://api.telegram.org/bot\u0026#39;${token}\u0026#39;/sendMessage?chat_id=\u0026#39;${id}\u0026#39;\u0026#34; --data-binary \u0026#34;\u0026amp;text=NewLogin:%0AVPS:${user}@${localip}%0ATime: ${logintime}%0ALogin from:%0A${loginip}%0A${loginfrom}\u0026#34; \u0026gt; /dev/null \u0026amp;\u0026amp; rm tg.sh\u0026#39; \u0026gt;\u0026gt; tg.sh bash tg.sh \u0026amp; ","permalink":"https://blog.lvcshu.com/2020/09/13/vps-%E7%99%BB%E5%BD%95%E6%8E%A8%E9%80%81/","summary":"国内的云服务器大多数都自带了 ssh 登录提示功能，这个功能我觉得不错，但是在很多并没有深度定制系统镜像的云服务器服务商那里就没有远程登录提醒功能了，于是写了一个小脚本来实现远程登录就将登录信息推送至 telegram 的功能\n文件名 00-ssh-login-alarm-telegram.sh (其实也可以自己自定义)，将文件放在 /etc/profile.d 目录下。\n#!/bin/bash  #填入 telegram bot 的 token token= #填自己telegram的id id= #vps ip vpsip=$(curl -s ip.sb -4) #登录时间 logintime=$(TZ=UTC-8 date \u0026#39;+%Y-%m-%d %H:%M:%S\u0026#39;) #远程登录的ip loginip=$(who -u am i 2\u0026gt;/dev/null| awk \u0026#39;{print $NF}\u0026#39;|sed -e \u0026#39;s/[()]//g\u0026#39;) #ip归属asn组织名称 loginfrom=$(curl -s https://api.ip.sb/geoip/${loginip} | jq .asn_organization) curl -s \u0026#34;https://api.telegram.org/bot${token}/sendMessage?chat_id=${id}\u0026#34; --data-binary \u0026#34;\u0026amp;text=NewLogin:%0AVPS: ${vpsip}%0ATime: ${logintime}%0ALogin from:%0A${loginip}%0A${loginfrom}\u0026#34; \u0026gt; /dev/null 因为用到了 jq 作为解析 json 的工具，所以需要在包管理器中自行安装。\n使用效果：\nNewLogin: VPS: ***.***.***.*** Time: 2020-09-13 12:41:24 Login from: ***.","title":"vps 登录推送"},{"content":"  首先你得有中文输入法\n  在启动脚本 /PATH/bin/xxx.sh 上面添加一行 export LC_ALL=zh_CN.UTF-8\n  ","permalink":"https://blog.lvcshu.com/2020/06/13/liunx-jetbrains-%E8%BD%AF%E4%BB%B6%E8%BE%93%E5%85%A5%E4%B8%AD%E6%96%87/","summary":"  首先你得有中文输入法\n  在启动脚本 /PATH/bin/xxx.sh 上面添加一行 export LC_ALL=zh_CN.UTF-8\n  ","title":"liunx jetbrains 软件输入中文"},{"content":"git remote add upstream 上游地址 git fetch upstream git checkout master git merge upstream/master git merge upstream/master git push origin master  Github:syncing a fork\n ","permalink":"https://blog.lvcshu.com/2020/05/31/git-%E5%90%8C%E6%AD%A5%E4%B8%8A%E6%B8%B8%E4%BB%A3%E7%A0%81/","summary":"git remote add upstream 上游地址 git fetch upstream git checkout master git merge upstream/master git merge upstream/master git push origin master  Github:syncing a fork\n ","title":"git 同步上游代码"},{"content":"从几年前开始使用 Telegram 开始，即使身边的人大部分都在使用微信但 Telegram 一直就是我首选的即时通讯软件，就是因为 Telegram 的整体感觉比微信更加像是一个即时通讯软件，并且 Telegram 开放的 bot api 让我一陷进去就无法自拔。\n今天就简单的写一写在我记忆里面的 Telegram 中文使用者群体里面所见到的 spammer 以及反 spammer 的一些事情。\nspammer 分类 截至到目前，我所见过的广告帐号主要分为以下几类\n  色情\n 色情频道推广 色情 GIF/图片 分发机器人，带频道推广 私聊问你要不要拍一些色图    卖东西\n 卖高仿鞋    黑产\n 各种涨粉 个人信息售卖 四件套 实体储蓄卡+身份证+手机卡+U盾（取款密码+网银登录密码 售卖（四件套解释-知乎） 出售科学上网工具 出售各种帐号(twitter,facebook,微博) 三网数据    币圈\n 拉人 推荐各种币    传教\n 法轮功 Arch神教    外语\n 各种看不懂的语言    spammer 行为分类   公开群类\n 进群发送一些无意义的问好的消息，并且展露自己的广告iID 进群不说话，但是会私聊群成员进行推广 进群后发送转发的频道的消息    私聊类\n 会先了解你是不是中国人，然后假装是一个对中国很有兴趣的外国人，然后就会宣传法轮功    拉群类\n 会将你拉进一些莫名其妙的群里面，一般以币圈的群居多    爆破类\n 进群就批量发送 spam 消息，刷屏来进行爆破骚扰    spammer 等级区分 反 spam 史 这一步部分虽然美其名曰 史 但是这些阶段并没有什么明显的分界线，目前来看这几个方案都是并存的状态，这几个方案及其项目目前的活跃程度不一，但在笔者有限的视野里面也的确有在运行。\n第一阶段 - 手动处理 一开始也是处理 spammer 比较原始的方式，就是利用 telegram 的比较完善的群组管理的功能进行广告内容的清理，同时因为能够清除成员发送的所有消息，所以其实效果还不错（在有管理员在线的情况下）\n第二阶段 - Bot 群管 代表：GroupButler\n第二阶段就进入了 bot 管理群组的阶段，依赖于 telegram 强大开放的 bot api，有大佬构造出了一个通用的群组管理 bot，群管 bot 的功能高低不一，取决于开发者的水平以及他的开发意愿，总的来说的确有一定的抑制 spammer 的炸群活动，对于传播广告的 spammer 还是没有很到位的解决方法。\n第三阶段 - 公共黑名单服务 代表：CNBL / CNBLR / SCP-079\n第三阶段出现了公共广告黑名单服务，这些服务由开发者直接提供 bot 服务，并且广告的判定权利掌握在项目管理者以及群内管理员所有。\n这些公共黑名单往往都会依托于其具有一定规模的用户量来完善黑名单，从而使得抗 spam 变得更主动，只要有一个 spammer 在一个群内被识别了，有这些 bot 在的群里面也会被联合踢出。\n但是因为这些公共黑名单服务是由人来进行手动操作，所以也会有误操作的可能性，还记得在几年前我就被误操作了一次，所以我就被大量的群踢掉了（QAQ）\n第四阶段 - 百花齐放 第四阶段就是各种机器人百花齐放的时代，有答题验证的、有发表情包验证的还有通过另外的验证手段验证的。\n目前采用的反 spam 策略 目前我管理的群有两种验证方式，两个 bot 都是我自己写的。\n答题 因为其中一个群是属于一个播客的听友群，所以采取的验证策略是提问播客相关的问题，效果拔群.jpg\n通过外部链接获取验证码 第二现场 目前的入群验证是由我开发的，验证方式要沿用之前通过外部链接获取的方式。\n目前验证机制是这样：\n新人进群 --\u0026gt; bot 计算 url 并且嵌入 url 的 hash 中 --\u0026gt; 反馈给用户 --\u0026gt; 用户访问外部链接执行 js 获取验证码 --\u0026gt; 到群组中发送验证码 --\u0026gt; 验证完成 由于url的计算是有当前时间戳作为变量，所以其实不是很需要担心被破解\n黑名单主动处理 因为我的 bot 默认会在欢迎消息中打出新进群用户的昵称，所以我必须要在欢迎之前先过滤一次用户名，来保证不帮助他卖广告。\n","permalink":"https://blog.lvcshu.com/2020/05/28/telegram-spammer/","summary":"从几年前开始使用 Telegram 开始，即使身边的人大部分都在使用微信但 Telegram 一直就是我首选的即时通讯软件，就是因为 Telegram 的整体感觉比微信更加像是一个即时通讯软件，并且 Telegram 开放的 bot api 让我一陷进去就无法自拔。\n今天就简单的写一写在我记忆里面的 Telegram 中文使用者群体里面所见到的 spammer 以及反 spammer 的一些事情。\nspammer 分类 截至到目前，我所见过的广告帐号主要分为以下几类\n  色情\n 色情频道推广 色情 GIF/图片 分发机器人，带频道推广 私聊问你要不要拍一些色图    卖东西\n 卖高仿鞋    黑产\n 各种涨粉 个人信息售卖 四件套 实体储蓄卡+身份证+手机卡+U盾（取款密码+网银登录密码 售卖（四件套解释-知乎） 出售科学上网工具 出售各种帐号(twitter,facebook,微博) 三网数据    币圈\n 拉人 推荐各种币    传教\n 法轮功 Arch神教    外语\n 各种看不懂的语言    spammer 行为分类   公开群类","title":"Telegram spammer 二三事"},{"content":"好久没有更新博客啦，上来写点碎碎念\n博客主题更新 最近在上网课之余腾出手来将 Hexo 主题做了一点点更新，主要是将入口页面做的漂亮了一点，加上了背景图片以及把顶栏 CSS 调整成了透明来更加适应图片背景。\n然后发现如果顶栏一直透明的话滚动到了文章列表会比较难看，就加了一点 js 使顶栏能自己切换透明以及白色。\n启用渐进式 JPEG 图片 渐进式图片转换 因为上文提到的博客主题的更新，所以一进博客就要加载一张大背景图，如果还采用原来的线性加载的 jpg 图片的话会造成观感的不和谐，所以就将网站的图片进行了转换，使图片支持渐进式加载，这里的转换用到了 python 脚本\nfrom PIL import Image # pip3 install pillow origin_file_path = \u0026#39;./t.jpeg\u0026#39; progressive_file_path = \u0026#39;./o.jpeg\u0026#39; original_image = Image.open(origin_file_path) original_image.convert(\u0026#39;RGB\u0026#39;) original_image.save(progressive_file_path, optimize=True, quality=100, progressive=True) PNG 转 JPG 同样也使用了 python 脚本，这里顺便将图片也进行了渐进式 jpeg 的转换\nimport os import cv2 import sys import numpy as np from PIL import Image # pip3 install pillow path = \u0026#34;./\u0026#34; print(path) for filename in os.listdir(path): if os.path.splitext(filename)[1] == \u0026#39;.png\u0026#39;: # print(filename) img = cv2.imread(path + filename) print(filename.replace(\u0026#34;.png\u0026#34;,\u0026#34;.jpg\u0026#34;)) newfilename = filename.replace(\u0026#34;.png\u0026#34;,\u0026#34;.jpg\u0026#34;) # cv2.imshow(\u0026#34;Image\u0026#34;,img) # cv2.waitKey(0) cv2.imwrite(path + newfilename,img) origin_file_path = path + newfilename progressive_file_path = path + newfilename original_image = Image.open(origin_file_path) original_image.convert(\u0026#39;RGB\u0026#39;) original_image.save(progressive_file_path, optimize=True, quality=100, progressive=True) os.remove(path+filename)% iconfont 使用体验 写这套主题的时候，我有一点使用 icon 图标的需求，虽然说 fontawesome.com 的图标品种十分丰富，但是似乎有些图标要使用的话要付费，对于我这种(穷)学生党来说有点难受，然后我想起了阿里巴巴开的 iconfont 图标库，第一次使用之后就爱上了。\n它不仅提供常规的 icon 还提供了彩色的 icon，还是免费的(指没有商业使用的情况下)，爱了爱了，博客主题项目的图标就是使用的 iconfont 的图标\n更改 DNS 服务商 之前使用的是 NS1 的免费 DNS 解析服务，虽然有分区域解析的功能，但是貌似效果不是很显著，趁着腾讯云的云解析正在搞活动买了一年的个人专业版(钱包 -￥36)来试用下，看了下可以区分境内境外解析，速度提升效果还可以\nEOF\n","permalink":"https://blog.lvcshu.com/2020/04/19/%E5%8D%9A%E5%AE%A2%E4%B8%BB%E9%A2%98%E6%9B%B4%E6%96%B0%E4%BB%A5%E5%8F%8A%E4%B8%80%E4%BA%9B%E7%A2%8E%E7%A2%8E%E5%BF%B5/","summary":"\u003cp\u003e好久没有更新博客啦，上来写点碎碎念\u003c/p\u003e","title":"博客主题更新 \u0026\u0026 一些碎碎念"},{"content":"2020年的春节是我过得最“憋屈”的一次春节，整整一个月我除了必要的出门以外从大年初一开始我就一直待在了家里，更令我觉得“绝望”的是因为疫情原因我还没法回学校。。。\n0 而理所当然的我也加入了网课大军，而记笔记成了我的一个难题，因为如果利用纸质笔记本来进行笔记的工作，那么在电脑屏幕上面显示的内容就需要我手抄 (我才不是懒) ，会有点割裂，所以我一直在寻找一个令我满意的笔记软件，当然，国内的公司我是不怎么考虑的了，因为我还想做一些网页存档。so，我在前些时候发了 一篇文章 ，简要的体验了一下 “开源拖拉机” joplin ，有一说一 joplin 的使用体验真的只是仅仅能用的级别，长期使用下还是不能做到体验顺滑。\n1 接下来我就去体验了一下大名鼎鼎的巨硬出的 OneNote ，使用体验的确十分惊艳，其中文字图片混排的使用方式其实很适合上课的笔记，但是为什么我后来也放弃了 OneNote 呢，原因就在于我是个实打实的跨平台用户，从 windows 到 安卓 到 Linux，都是我比较主要使用的操作系统，OneNote 的客户端功能不统一的弊端就出现了，而且情况十分严重，web、移动端、win10 PWA 版和 office 2016版这四个版本的客户端其中的功能 都 不 一 样，就很气，所以使用体验就比 joplin 还要割裂，最后忍无可忍就放弃了 OneNote。\n最后我只能把我的视线投向了目前还很火的 Notion，用 EDU 教育邮箱注册可以获得永久的免费个人订阅。\n2 入坑，简单的试了下发现还不赖，排版功能虽然说没有 OneNote 那种几乎无限制的容器布局，但是 Notion 的块布局也相对比较自由，排版功能已经满足了我，页面套娃功能也非常不错，页面层级理论上来说可以是无限的。\n值得着重讲下的就是 Notion 自带的数据库功能，其实就是将表格抽象成数据库，并且可以让数据库在几种不同的视图中来回切换，我简单的利用他这个功能做了个订阅服务续费管理的数据库\n上图就是我做的一个小工具，在临近续费期的时候他最前面一格就会标红，代码也很简单\nif(prop(\u0026#34;周期\u0026#34;) == \u0026#34;月付\u0026#34;, if(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;months\u0026#34;), now(), \u0026#34;days\u0026#34;) \u0026lt;= 10, \u0026#34;🔴 还有 \u0026#34; + format(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;months\u0026#34;), now(), \u0026#34;days\u0026#34;)) + \u0026#34; 天\u0026#34;, \u0026#34;🔵 还有 \u0026#34; + format(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;months\u0026#34;), now(), \u0026#34;days\u0026#34;)) + \u0026#34; 天\u0026#34;), if(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;years\u0026#34;), now(), \u0026#34;days\u0026#34;) \u0026lt;= 10, \u0026#34;🔴 还有 \u0026#34; + format(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;years\u0026#34;), now(), \u0026#34;days\u0026#34;)) + \u0026#34; 天\u0026#34;, \u0026#34;🔵 还有 \u0026#34; + format(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;years\u0026#34;), now(), \u0026#34;days\u0026#34;)) + \u0026#34; 天\u0026#34;)) 这就是 Notion 其中一个让我用起来很舒服的功能，就是你可以用简单的逻辑语句做出一些自己想要的小功能。\n还有一个对我很友好的优点是 Notion 他网页版本的功能是全的，WEB党万岁！\n美中不足的是安卓端的编辑功能以及操作逻辑没有那么流畅，仍然需要继续完善。\n 本文在 Notion 上编辑完成\n ","permalink":"https://blog.lvcshu.com/2020/03/23/notion%E5%A5%BD%E7%94%A8%E7%9A%84%E7%8E%B0%E4%BB%A3%E7%AC%94%E8%AE%B0%E8%BD%AF%E4%BB%B6/","summary":"2020年的春节是我过得最“憋屈”的一次春节，整整一个月我除了必要的出门以外从大年初一开始我就一直待在了家里，更令我觉得“绝望”的是因为疫情原因我还没法回学校。。。\n0 而理所当然的我也加入了网课大军，而记笔记成了我的一个难题，因为如果利用纸质笔记本来进行笔记的工作，那么在电脑屏幕上面显示的内容就需要我手抄 (我才不是懒) ，会有点割裂，所以我一直在寻找一个令我满意的笔记软件，当然，国内的公司我是不怎么考虑的了，因为我还想做一些网页存档。so，我在前些时候发了 一篇文章 ，简要的体验了一下 “开源拖拉机” joplin ，有一说一 joplin 的使用体验真的只是仅仅能用的级别，长期使用下还是不能做到体验顺滑。\n1 接下来我就去体验了一下大名鼎鼎的巨硬出的 OneNote ，使用体验的确十分惊艳，其中文字图片混排的使用方式其实很适合上课的笔记，但是为什么我后来也放弃了 OneNote 呢，原因就在于我是个实打实的跨平台用户，从 windows 到 安卓 到 Linux，都是我比较主要使用的操作系统，OneNote 的客户端功能不统一的弊端就出现了，而且情况十分严重，web、移动端、win10 PWA 版和 office 2016版这四个版本的客户端其中的功能 都 不 一 样，就很气，所以使用体验就比 joplin 还要割裂，最后忍无可忍就放弃了 OneNote。\n最后我只能把我的视线投向了目前还很火的 Notion，用 EDU 教育邮箱注册可以获得永久的免费个人订阅。\n2 入坑，简单的试了下发现还不赖，排版功能虽然说没有 OneNote 那种几乎无限制的容器布局，但是 Notion 的块布局也相对比较自由，排版功能已经满足了我，页面套娃功能也非常不错，页面层级理论上来说可以是无限的。\n值得着重讲下的就是 Notion 自带的数据库功能，其实就是将表格抽象成数据库，并且可以让数据库在几种不同的视图中来回切换，我简单的利用他这个功能做了个订阅服务续费管理的数据库\n上图就是我做的一个小工具，在临近续费期的时候他最前面一格就会标红，代码也很简单\nif(prop(\u0026#34;周期\u0026#34;) == \u0026#34;月付\u0026#34;, if(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;months\u0026#34;), now(), \u0026#34;days\u0026#34;) \u0026lt;= 10, \u0026#34;🔴 还有 \u0026#34; + format(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;months\u0026#34;), now(), \u0026#34;days\u0026#34;)) + \u0026#34; 天\u0026#34;, \u0026#34;🔵 还有 \u0026#34; + format(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;months\u0026#34;), now(), \u0026#34;days\u0026#34;)) + \u0026#34; 天\u0026#34;), if(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;years\u0026#34;), now(), \u0026#34;days\u0026#34;) \u0026lt;= 10, \u0026#34;🔴 还有 \u0026#34; + format(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;years\u0026#34;), now(), \u0026#34;days\u0026#34;)) + \u0026#34; 天\u0026#34;, \u0026#34;🔵 还有 \u0026#34; + format(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;years\u0026#34;), now(), \u0026#34;days\u0026#34;)) + \u0026#34; 天\u0026#34;)) 这就是 Notion 其中一个让我用起来很舒服的功能，就是你可以用简单的逻辑语句做出一些自己想要的小功能。","title":"Notion：好用的现代笔记软件"},{"content":"2020年的春节是我过得最“憋屈”的一次春节，整整一个月我除了必要的出门以外从大年初一开始我就一直待在了家里，更令我觉得“绝望”的是因为疫情原因我还没法回学校。。。\n0 而理所当然的我也加入了网课大军，而记笔记成了我的一个难题，因为如果利用纸质笔记本来进行笔记的工作，那么在电脑屏幕上面显示的内容就需要我手抄 (我才不是懒) ，会有点割裂，所以我一直在寻找一个令我满意的笔记软件，当然，国内的公司我是不怎么考虑的了，因为我还想做一些网页存档。so，我在前些时候发了 一篇文章 ，简要的体验了一下 “开源拖拉机” joplin ，有一说一 joplin 的使用体验真的只是仅仅能用的级别，长期使用下还是不能做到体验顺滑。\n1 接下来我就去体验了一下大名鼎鼎的巨硬出的 OneNote ，使用体验的确十分惊艳，其中文字图片混排的使用方式其实很适合上课的笔记，但是为什么我后来也放弃了 OneNote 呢，原因就在于我是个实打实的跨平台用户，从 windows 到 安卓 到 Linux，都是我比较主要使用的操作系统，OneNote 的客户端功能不统一的弊端就出现了，而且情况十分严重，web、移动端、win10 PWA 版和 office 2016版这四个版本的客户端其中的功能 都 不 一 样，就很气，所以使用体验就比 joplin 还要割裂，最后忍无可忍就放弃了 OneNote。\n最后我只能把我的视线投向了目前还很火的 Notion，用 EDU 教育邮箱注册可以获得永久的免费个人订阅。\n2 入坑，简单的试了下发现还不赖，排版功能虽然说没有 OneNote 那种几乎无限制的容器布局，但是 Notion 的块布局也相对比较自由，排版功能已经满足了我，页面套娃功能也非常不错，页面层级理论上来说可以是无限的。\n值得着重讲下的就是 Notion 自带的数据库功能，其实就是将表格抽象成数据库，并且可以让数据库在几种不同的视图中来回切换，我简单的利用他这个功能做了个订阅服务续费管理的数据库\n上图就是我做的一个小工具，在临近续费期的时候他最前面一格就会标红，代码也很简单\nif(prop(\u0026#34;周期\u0026#34;) == \u0026#34;月付\u0026#34;, if(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;months\u0026#34;), now(), \u0026#34;days\u0026#34;) \u0026lt;= 10, \u0026#34;🔴 还有 \u0026#34; + format(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;months\u0026#34;), now(), \u0026#34;days\u0026#34;)) + \u0026#34; 天\u0026#34;, \u0026#34;🔵 还有 \u0026#34; + format(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;months\u0026#34;), now(), \u0026#34;days\u0026#34;)) + \u0026#34; 天\u0026#34;), if(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;years\u0026#34;), now(), \u0026#34;days\u0026#34;) \u0026lt;= 10, \u0026#34;🔴 还有 \u0026#34; + format(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;years\u0026#34;), now(), \u0026#34;days\u0026#34;)) + \u0026#34; 天\u0026#34;, \u0026#34;🔵 还有 \u0026#34; + format(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;years\u0026#34;), now(), \u0026#34;days\u0026#34;)) + \u0026#34; 天\u0026#34;)) 这就是 Notion 其中一个让我用起来很舒服的功能，就是你可以用简单的逻辑语句做出一些自己想要的小功能。\n还有一个对我很友好的优点是 Notion 他网页版本的功能是全的，WEB党万岁！\n美中不足的是安卓端的编辑功能以及操作逻辑没有那么流畅，仍然需要继续完善。\n 本文在 Notion 上编辑完成\n ","permalink":"https://blog.lvcshu.com/2020/03/23/notion%E5%A5%BD%E7%94%A8%E7%9A%84%E7%8E%B0%E4%BB%A3%E7%AC%94%E8%AE%B0%E8%BD%AF%E4%BB%B6/","summary":"2020年的春节是我过得最“憋屈”的一次春节，整整一个月我除了必要的出门以外从大年初一开始我就一直待在了家里，更令我觉得“绝望”的是因为疫情原因我还没法回学校。。。\n0 而理所当然的我也加入了网课大军，而记笔记成了我的一个难题，因为如果利用纸质笔记本来进行笔记的工作，那么在电脑屏幕上面显示的内容就需要我手抄 (我才不是懒) ，会有点割裂，所以我一直在寻找一个令我满意的笔记软件，当然，国内的公司我是不怎么考虑的了，因为我还想做一些网页存档。so，我在前些时候发了 一篇文章 ，简要的体验了一下 “开源拖拉机” joplin ，有一说一 joplin 的使用体验真的只是仅仅能用的级别，长期使用下还是不能做到体验顺滑。\n1 接下来我就去体验了一下大名鼎鼎的巨硬出的 OneNote ，使用体验的确十分惊艳，其中文字图片混排的使用方式其实很适合上课的笔记，但是为什么我后来也放弃了 OneNote 呢，原因就在于我是个实打实的跨平台用户，从 windows 到 安卓 到 Linux，都是我比较主要使用的操作系统，OneNote 的客户端功能不统一的弊端就出现了，而且情况十分严重，web、移动端、win10 PWA 版和 office 2016版这四个版本的客户端其中的功能 都 不 一 样，就很气，所以使用体验就比 joplin 还要割裂，最后忍无可忍就放弃了 OneNote。\n最后我只能把我的视线投向了目前还很火的 Notion，用 EDU 教育邮箱注册可以获得永久的免费个人订阅。\n2 入坑，简单的试了下发现还不赖，排版功能虽然说没有 OneNote 那种几乎无限制的容器布局，但是 Notion 的块布局也相对比较自由，排版功能已经满足了我，页面套娃功能也非常不错，页面层级理论上来说可以是无限的。\n值得着重讲下的就是 Notion 自带的数据库功能，其实就是将表格抽象成数据库，并且可以让数据库在几种不同的视图中来回切换，我简单的利用他这个功能做了个订阅服务续费管理的数据库\n上图就是我做的一个小工具，在临近续费期的时候他最前面一格就会标红，代码也很简单\nif(prop(\u0026#34;周期\u0026#34;) == \u0026#34;月付\u0026#34;, if(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;months\u0026#34;), now(), \u0026#34;days\u0026#34;) \u0026lt;= 10, \u0026#34;🔴 还有 \u0026#34; + format(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;months\u0026#34;), now(), \u0026#34;days\u0026#34;)) + \u0026#34; 天\u0026#34;, \u0026#34;🔵 还有 \u0026#34; + format(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;months\u0026#34;), now(), \u0026#34;days\u0026#34;)) + \u0026#34; 天\u0026#34;), if(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;years\u0026#34;), now(), \u0026#34;days\u0026#34;) \u0026lt;= 10, \u0026#34;🔴 还有 \u0026#34; + format(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;years\u0026#34;), now(), \u0026#34;days\u0026#34;)) + \u0026#34; 天\u0026#34;, \u0026#34;🔵 还有 \u0026#34; + format(dateBetween(dateAdd(prop(\u0026#34;上次付款\u0026#34;), 1, \u0026#34;years\u0026#34;), now(), \u0026#34;days\u0026#34;)) + \u0026#34; 天\u0026#34;)) 这就是 Notion 其中一个让我用起来很舒服的功能，就是你可以用简单的逻辑语句做出一些自己想要的小功能。","title":"Notion：好用的现代笔记软件"},{"content":"前几天 Linux 中国发了一篇文章，里面介绍了 Joplin 这一款开源的笔记本软件，对于一个平时有那么一点待办事项的我来说，产生了一点点想尝试的念头。然后就去安装并体验了一下，总的来说，体验不错，但是仍然有着一点瑕疵。\n使用体验 优点  支持 markdown、html 待办事项可以定时提醒 网页摘抄可以直接截取网页的 HTML 代码保存 中文本地化并不完全  一些坑  onedriver 速度慢 Dropbox Linux 版本无法授权 坚果云 webdav 有频率限制 自建 webdav 有点麻烦以及不能保证速度 linux 桌面版本有时会无端卡顿 加密密钥不能编辑管理  安装 桌面端，我使用的是 Linux 系统，直接下载官网的 AppImage 文件，开箱即用。移动端直接从 GooglePlay 下载安装即可。\n配置同步 一开始我使用的同步策略是使用自建 webdav 进行同步，但是效果不佳，后来我就去尝试使用了国内的坚果云 webdav 进行同步笔记，但是由于坚果云的 webdav 有频繁操作的保护，所以几乎是不可用的状态。\n无奈之下我只能粗暴的选择直接进行文件同步，首先使用的 resilio sync 未知原因的同步速度十分缓慢(内网)，所以最后选择了同类型的软件 synthing\n加密配置 Joplin 还自带加密的功能，但是加密的功能稍微有点设计缺陷，主要是操作了逻辑的缺陷，他没有设计加密密钥的删除功能，所以加密如果禁用再重新打开是不能用回之前的密钥的，只能重新生成，而且如果两个设备都生成了密钥两边都会有两把密钥，有点看不顺眼。\n正确的操作逻辑：\n启用加密--\u0026gt;同步--\u0026gt;输入密码 参考链接  Joplin：真正的 Evernote 开源替代品 Syncthing – 数据同步利器\u0026mdash;自己的网盘，详细安装配置指南，内网使用，发现服务器配置 Joplin 同步到坚果云 webdav Syncthing 官网   PS:本篇文章在 Joplin 上完成\n ","permalink":"https://blog.lvcshu.com/2020/02/22/joplin%E7%AC%94%E8%AE%B0%E8%BD%AF%E4%BB%B6%E7%9A%84%E6%96%B0%E9%80%89%E6%8B%A9/","summary":"前几天 Linux 中国发了一篇文章，里面介绍了 Joplin 这一款开源的笔记本软件，对于一个平时有那么一点待办事项的我来说，产生了一点点想尝试的念头。然后就去安装并体验了一下，总的来说，体验不错，但是仍然有着一点瑕疵。\n使用体验 优点  支持 markdown、html 待办事项可以定时提醒 网页摘抄可以直接截取网页的 HTML 代码保存 中文本地化并不完全  一些坑  onedriver 速度慢 Dropbox Linux 版本无法授权 坚果云 webdav 有频率限制 自建 webdav 有点麻烦以及不能保证速度 linux 桌面版本有时会无端卡顿 加密密钥不能编辑管理  安装 桌面端，我使用的是 Linux 系统，直接下载官网的 AppImage 文件，开箱即用。移动端直接从 GooglePlay 下载安装即可。\n配置同步 一开始我使用的同步策略是使用自建 webdav 进行同步，但是效果不佳，后来我就去尝试使用了国内的坚果云 webdav 进行同步笔记，但是由于坚果云的 webdav 有频繁操作的保护，所以几乎是不可用的状态。\n无奈之下我只能粗暴的选择直接进行文件同步，首先使用的 resilio sync 未知原因的同步速度十分缓慢(内网)，所以最后选择了同类型的软件 synthing\n加密配置 Joplin 还自带加密的功能，但是加密的功能稍微有点设计缺陷，主要是操作了逻辑的缺陷，他没有设计加密密钥的删除功能，所以加密如果禁用再重新打开是不能用回之前的密钥的，只能重新生成，而且如果两个设备都生成了密钥两边都会有两把密钥，有点看不顺眼。\n正确的操作逻辑：\n启用加密--\u0026gt;同步--\u0026gt;输入密码 参考链接  Joplin：真正的 Evernote 开源替代品 Syncthing – 数据同步利器\u0026mdash;自己的网盘，详细安装配置指南，内网使用，发现服务器配置 Joplin 同步到坚果云 webdav Syncthing 官网   PS:本篇文章在 Joplin 上完成","title":"Joplin：笔记软件的新选择"},{"content":"最近我的 ikoula 杜甫频繁出现问题，再三考虑之下还是将杜甫退掉了，然后在 letbox 重新买了一个大盘鸡作为我的储存服务器+PT 盒子。\n但是 PT 下载好了的文件我得拉回本地，所以我就想在服务器上建个私有云盘，但是试来试去都没有啥好用的，最后用到了 Tiny File Manager\n安装的话也很简单，只需要你的服务器上有网页服务器和 php 环境即可，将 tinyfilemanager.php 和 translation.json 放到目录下就好了\n为了安全起见，我还在 nginx 上设置了权限限制，让这个目录下面的文件只能通过这个 php 文件下载。\nlocation / { deny all; } location /index.php { allow all; } ","permalink":"https://blog.lvcshu.com/2020/02/14/tiny-file-manager-%E4%BD%BF%E7%94%A8/","summary":"最近我的 ikoula 杜甫频繁出现问题，再三考虑之下还是将杜甫退掉了，然后在 letbox 重新买了一个大盘鸡作为我的储存服务器+PT 盒子。\n但是 PT 下载好了的文件我得拉回本地，所以我就想在服务器上建个私有云盘，但是试来试去都没有啥好用的，最后用到了 Tiny File Manager\n安装的话也很简单，只需要你的服务器上有网页服务器和 php 环境即可，将 tinyfilemanager.php 和 translation.json 放到目录下就好了\n为了安全起见，我还在 nginx 上设置了权限限制，让这个目录下面的文件只能通过这个 php 文件下载。\nlocation / { deny all; } location /index.php { allow all; } ","title":"Tiny File Manager 使用"},{"content":"-` johnpoint@archlinux .o+` ------------------- `ooo/ OS: Arch Linux x86_64 `+oooo: Host: ×××××××××××× `+oooooo: Kernel: 5.4.8-arch1-1 -+oooooo+: Uptime: 18 hours, 43 mins `/:-:++oooo+: Packages: 1389 (pacman) `/++++/+++++++: Shell: zsh 5.7.1 `/++++++++++++++: Resolution: 1920x1080, 1920x1080 `/+++ooooooooooooo/` DE: Plasma ./ooosssso++osssssso+` WM: KWin .oossssso-````/ossssss+` Theme: Breeze [GTK2/3] -osssssso. :ssssssso. Icons: breeze [GTK2/3] :osssssss/ osssso+++. Terminal: konsole /ossssssss/ +ssssooo/- Terminal Font: Cascadia Code 11 `/ossssso+/:- -:/+osssso+- CPU: Intel i5-8250U (8) @ 3.400GHz `+sso+:-` `.-/+oso: GPU: Intel UHD Graphics 620 `++:. `-/+/ Memory: ×××××××××××× .` `/ 今天写一下在这段时间 Archlinux 的使用体验。\n从去年上半年开始我先是使用的 Ubuntu 18.04 作为我的笔记本电脑兼主用电脑使用，Ubuntu 的桌面版本的使用体验其实已经不逊于 Windows 系统（除了 office 套件还是 Windows 上好用），开源的 office 套件方案（Libreoffice）也已经相对成熟也可以在大部分时间下代替 MS office 存在。\n前些时候，我也写过一篇 Archlinux 的安装指南（传送门），但是那时候我是在虚拟机里面安装的，主要是怕翻车（逃\n在 2019 年下半年，我才在 Yuuta 的一条频道消息的提醒下想起了那被我遗忘的 Archlinux 遂备份文件准备把主用的系统换过去。\n使用体验  桌面环境: 纯净的 KDE 体验，在我这里没有出现啥奇怪的问题 网页浏览: 选用了 Chromium，体验与其他平台的 Chrome 基本一致 视频: VLC 我觉得是最好用的播放器 文档编辑: Libreoffice 体验一般，就是能用的程度 代码:  VScode 跨平台体验一致 Netbean 跨平台体验一致   视频编辑: 无此需求 游戏:  Steam 我 想/能 玩的游戏都运行正常(缺氧 \u0026amp;\u0026amp; 异星工厂) Minecraft Java 跨平台    坑  内核升级的时候 wifi 的内核驱动模块不能自己挂载，往往需要自己重新加载 由于内核版本太高，有一次编译出来的 go 可执行文件放到了服务器上时提示 glibc 版本不存在 ","permalink":"https://blog.lvcshu.com/2020/01/13/arch-%E7%B3%BB%E7%BB%9F%E4%BD%93%E9%AA%8C%E6%8A%A5%E5%91%8A/","summary":"","title":"Archlinux 系统体验报告"},{"content":"家里的弱电箱因为前期设计失误所以电视那里只有一条网线，而如果我想将 wifi 信号在屋子里面相对良好的覆盖的话我也要将无线路由器设置在电视机附近，但是 IPTV 也需要占用一条网线，一开始我们的解决方案是用一条劈叉的网线，但是数据传输会有质量问题，所以趁着暑假我就尝试着解决这个问题。\n设置光猫 首先利用广东电信的光猫超级账户\nSuperUser: telecomadmin PassWord: nE7jA%5m 进行 VLAN 绑定\n设置路由器 注意：在进行这一个篇章的时候建议先对路由器的设置进行记录，以免机毁人亡\n交换机设置 光猫 --\u0026gt; WAN -------\u0026gt; LAN1(IPTV) | |----\u0026gt; CPU(NET) 然后就好了～\n还可以顺便获取到 ipv6，双倍的快乐\n","permalink":"https://blog.lvcshu.com/2020/01/09/%E9%85%8D%E7%BD%AE-iptv-net-vlan-%E5%8D%95%E7%BA%BF%E5%A4%8D%E7%94%A8/","summary":"家里的弱电箱因为前期设计失误所以电视那里只有一条网线，而如果我想将 wifi 信号在屋子里面相对良好的覆盖的话我也要将无线路由器设置在电视机附近，但是 IPTV 也需要占用一条网线，一开始我们的解决方案是用一条劈叉的网线，但是数据传输会有质量问题，所以趁着暑假我就尝试着解决这个问题。\n设置光猫 首先利用广东电信的光猫超级账户\nSuperUser: telecomadmin PassWord: nE7jA%5m 进行 VLAN 绑定\n设置路由器 注意：在进行这一个篇章的时候建议先对路由器的设置进行记录，以免机毁人亡\n交换机设置 光猫 --\u0026gt; WAN -------\u0026gt; LAN1(IPTV) | |----\u0026gt; CPU(NET) 然后就好了～\n还可以顺便获取到 ipv6，双倍的快乐","title":"配置 IPTV-NET VLAN 单线复用"},{"content":"又是一年圣诞节，2019 年也来到了尾声，2018 年的年度简报感觉就是在不久之前写的，时间过得真的快。又是时候来给过去的 2019 年做一个简报以及总结。\n Photo by Fabrizio Verrecchia on Unsplash\n 学习 今年学习了什么？感觉没有什么大的方向，《计算机网络》的学习还在鸽，《算法》依然静静的躺在我的书架上。\n 新学习了 Go，目前在用 Go 写一个自己用的服务器监控/控制中心   johnpoint/CenterDash \u0026lt;\u0026ndash; 不用点进去了，是私有仓库\n  Java 方面学校的期末项目本来想体验一下小组合作的感觉的，但是没有想到组员相当不给力，最后项目完成的很差劲 (主要是我也不想帮忙\u0026hellip;太懒)   johnpoint/GalaxyExpress \u0026lt;\u0026ndash; 不用点进去了，是私有仓库，太差了说不定哪一天我就删掉了\n  给博客写了一套主题 hexo-theme-XvA   johnpoint/hexo-theme-XvA\n  数据结构跟着学校学感觉还是进度太慢，寒假可能要自己看看《算法》了  Github 的一年 博客 概览  今年更新了 27篇文章(包括本文) 友链增加了 11个大佬 评论 0条  Google Analytics 参与活动  GDG devfest GuangZhou  2019 计划完成情况  预习JAVA (完成) 把 业余无线电牌照 考到手 (未完成) 继续学习算法知识 (完成) ","permalink":"https://blog.lvcshu.com/2019/12/23/2019%E5%B9%B4%E5%BA%A6%E7%AE%80%E6%8A%A5/","summary":"\u003cp\u003e又是一年圣诞节，2019 年也来到了尾声，2018 年的年度简报感觉就是在不久之前写的，时间过得真的快。又是时候来给过去的 2019 年做一个简报以及总结。\u003c/p\u003e","title":"2019 年度简报"},{"content":"function getSong(name) { window.location.href = \u0026#34;https://y.qq.com/portal/search.html#page=1\u0026amp;searchid=1\u0026amp;remoteplace=txt.yqq.top\u0026amp;t=song\u0026amp;w=\u0026#34; + name; var muname = $(\u0026#39;.js_song\u0026#39;)[0].href.replace(\u0026#39;https://y.qq.com/n/yqq/song/\u0026#39;, \u0026#39;C400\u0026#39;).replace(\u0026#39;.html\u0026#39;, \u0026#39;\u0026#39;); var qq = \u0026#34;0\u0026#34;; var guid = \u0026#34;0\u0026#34;; $.ajax({ url: \u0026#34;https://c.y.qq.com/base/fcgi-bin/fcg_music_express_mobile3.fcg?g_tk=0\u0026amp;loginUin=\u0026#34; + qq + \u0026#34;\u0026amp;hostUin=0\u0026amp;format=json\u0026amp;inCharset=utf8\u0026amp;outCharset=utf-8\u0026amp;notice=0\u0026amp;platform=yqq\u0026amp;needNewCode=0\u0026amp;cid=205361747\u0026amp;uin=\u0026#34; + qq + \u0026#34;\u0026amp;songmid=\u0026#34; + muname.replace(\u0026#39;C400\u0026#39;, \u0026#39;\u0026#39;) + \u0026#34;\u0026amp;filename=\u0026#34; + muname + \u0026#34;.m4a\u0026amp;guid=\u0026#34; + guid, success: function (data) { data = JSON.parse(data); vkey = data.data.items[0].vkey; console.log($(\u0026#39;.js_song\u0026#39;)[0].href.replace(\u0026#39;https://y.qq.com/n/yqq/song/\u0026#39;, \u0026#39;http://isure.stream.qqmusic.qq.com/C400\u0026#39;).replace(\u0026#39;.html\u0026#39;, \u0026#39;.m4a?guid=\u0026#39; + guid + \u0026#39;\u0026amp;vkey=\u0026#39; + vkey + \u0026#39;\u0026amp;uin=\u0026#39; + qq + \u0026#39;\u0026amp;fromtag=66\u0026#39;)) window.open($(\u0026#39;.js_song\u0026#39;)[0].href.replace(\u0026#39;https://y.qq.com/n/yqq/song/\u0026#39;, \u0026#39;http://isure.stream.qqmusic.qq.com/C400\u0026#39;).replace(\u0026#39;.html\u0026#39;, \u0026#39;.m4a?guid=\u0026#39; + guid + \u0026#39;\u0026amp;vkey=\u0026#39; + vkey + \u0026#39;\u0026amp;uin=\u0026#39; + qq + \u0026#39;\u0026amp;fromtag=66\u0026#39;)) } }) } ","permalink":"https://blog.lvcshu.com/2019/12/12/js-%E6%8F%90%E5%8F%96qq%E9%9F%B3%E4%B9%90%E7%9B%B4%E9%93%BE/","summary":"function getSong(name) { window.location.href = \u0026#34;https://y.qq.com/portal/search.html#page=1\u0026amp;searchid=1\u0026amp;remoteplace=txt.yqq.top\u0026amp;t=song\u0026amp;w=\u0026#34; + name; var muname = $(\u0026#39;.js_song\u0026#39;)[0].href.replace(\u0026#39;https://y.qq.com/n/yqq/song/\u0026#39;, \u0026#39;C400\u0026#39;).replace(\u0026#39;.html\u0026#39;, \u0026#39;\u0026#39;); var qq = \u0026#34;0\u0026#34;; var guid = \u0026#34;0\u0026#34;; $.ajax({ url: \u0026#34;https://c.y.qq.com/base/fcgi-bin/fcg_music_express_mobile3.fcg?g_tk=0\u0026amp;loginUin=\u0026#34; + qq + \u0026#34;\u0026amp;hostUin=0\u0026amp;format=json\u0026amp;inCharset=utf8\u0026amp;outCharset=utf-8\u0026amp;notice=0\u0026amp;platform=yqq\u0026amp;needNewCode=0\u0026amp;cid=205361747\u0026amp;uin=\u0026#34; + qq + \u0026#34;\u0026amp;songmid=\u0026#34; + muname.replace(\u0026#39;C400\u0026#39;, \u0026#39;\u0026#39;) + \u0026#34;\u0026amp;filename=\u0026#34; + muname + \u0026#34;.m4a\u0026amp;guid=\u0026#34; + guid, success: function (data) { data = JSON.parse(data); vkey = data.data.items[0].vkey; console.log($(\u0026#39;.js_song\u0026#39;)[0].href.replace(\u0026#39;https://y.qq.com/n/yqq/song/\u0026#39;, \u0026#39;http://isure.stream.qqmusic.qq.com/C400\u0026#39;).replace(\u0026#39;.html\u0026#39;, \u0026#39;.m4a?guid=\u0026#39; + guid + \u0026#39;\u0026amp;vkey=\u0026#39; + vkey + \u0026#39;\u0026amp;uin=\u0026#39; + qq + \u0026#39;\u0026amp;fromtag=66\u0026#39;)) window.open($(\u0026#39;.js_song\u0026#39;)[0].href.replace(\u0026#39;https://y.qq.com/n/yqq/song/\u0026#39;, \u0026#39;http://isure.","title":"js 提取 QQ 音乐直链"},{"content":"最近开的 Google I/O 大会公布了 Android Q beta3 的几款适配的机型，我的 Oneplus 6 恰好也在其中\n最近我心心念念想着更新的 Android 10 终于向 Oneplus 6 推送了，不过是 Open beta 版本，着意味着这个版本的系统还有可能有着不稳定的情况，尽管如此，我还是第一时间通过手刷更新包进行了更新。\n上一次使用 Android 10 是在五个月以前了，当时的 Android 10 还没有确定改名，也有许多很致命的 BUG，体验大翻车，狼狈的回滚回了 Pie，现在正式的 Openbeta出来体验了两天说下感想\n 新的手势小白条是真的好用 好像不能隐藏刘海了，表示有点难受 返回手势会和有的左边侧栏拉出手势冲突 动画效果多了，视觉效果变顺滑 耗电量似乎比 Pie 大，也有可能是动画效果变多了导致的 应用抽屉在 工作空间 与 个人空间 进行切换的时候好像有点不顺畅，需要拉屏幕上三分之一才可以拉动 黑暗模式好评（虽然说傻雕微信一如既往的亮瞎眼） 权限管理好评（有只有“应用在前台允许”这个选项） Magisk 运行正常 自动亮度无效 有几个软件不适配 ","permalink":"https://blog.lvcshu.com/2019/10/21/android-q-%E5%86%8D%E4%BD%93%E9%AA%8C/","summary":"\u003cp\u003e\u003cdel\u003e最近开的 Google I/O 大会公布了 Android Q beta3 的几款适配的机型，我的 Oneplus 6 恰好也在其中\u003c/del\u003e\u003c/p\u003e","title":"Android 10 再体验"},{"content":"最近去看了下我的自动重连脚本的 log 文件夹\n文件太多， rm 命令会提示参数太多不能执行\n于是写了个 python 脚本来删除文件\nimport os for pathname,dirnames,filenames in os.walk(\u0026#39;/root\u0026#39;): for filename in filenames: if \u0026#39;net.log\u0026#39; in filename: file=os.path.join(pathname,filename) os.remove(file) print(\u0026#34;OK\u0026#34;) ","permalink":"https://blog.lvcshu.com/2019/10/20/linux%E5%88%A0%E9%99%A4%E5%A4%A7%E9%87%8F%E6%96%87%E4%BB%B6/","summary":"\u003cp\u003e最近去看了下我的自动重连脚本的 log 文件夹\u003c/p\u003e","title":"Linux 删除大量文件"},{"content":"写下我是怎么解决 deepin 应用字体异常的\nlinux 在国内推广的难度，我想大多数来自于国内的某些大公司在用户端对于 linux(不包含 android) 系统的不友好。\ndeepin 这家公司就做了许多移植软件，比如 Foxmail、TIM，尽管他们都是运行在定制的 wine 中的，但也算是能用了，美中不足的是，deepin-wine 的 windows 环境之中似乎没有字体文件，所以会造成软件界面的字体渲染出错。\n解决方法嘛，我从 win10 虚拟机里面把字体提取出来并做了个软链接(节省空间)到容器的字体文件夹(~/.deepinwine/Deepin-Foxmail/drive_c/windows/Fonts)就好了。\n","permalink":"https://blog.lvcshu.com/2019/10/12/deepin%E5%BA%94%E7%94%A8%E5%AD%97%E4%BD%93%E5%BC%82%E5%B8%B8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","summary":"\u003cp\u003e写下我是怎么解决 deepin 应用字体异常的\u003c/p\u003e","title":"deepin 应用字体异常解决方法"},{"content":"最近在折腾博客的字体，最终选定了这几个字体作为网站的字体\n莫名绕口\n 方正兰亭纤黑 方正粗金陵 Times New Roman Times serif  问题来了，在方正网站上面获取字体的授权是非商业的授权。即使我都是非商业的用途，但是为了减少我的风险，我还是选择把字体和项目分开(怕死.jpg)。\nemmmmm 我不把字体整进主题里面我怎么去使用字体咧？网上的 font CDN 也不大可能有方正的字体\u0026hellip;\n最后就把字体放上了一个资源服务器 cdn.6-d.cc 我的图片之类的外链的东西都全部扔在上面，就把字体扔到了 https://cdn.6-d.cc/font/ 上面，如果你打开 F12-\u0026gt;network 然后刷新的话，应该能发现有两个后缀为 ttf 的资源是从 cdn.6-d.cc 加载的。\n配置 CORS 事情并没有那么简单，从别的域名引用是一种叫做跨域请求的请求 莫名绕口×2 ，但是这种请求会撞上浏览器的一种叫做 Same-origin policy(同源策略) 的安全策略，好消息是这个策略也有相应的绕过方法 Cross-origin resource sharing(CORS 跨来源资源共享) 这种技术规范就可以通过添加标头来进行资源的跨域名调用。顺便他还可以对资源的调用范围作出限制，毕竟我可不想碰到方正的法务团队(逃)。\n具体配置如下\nlocation /font { set $cors_origin \u0026#34;\u0026#34;; if ($http_origin ~* \u0026#34;^https://blog.lvcshu.com$\u0026#34;) { set $cors_origin $http_origin; } if ($http_origin ~* \u0026#34;^https://johnpoint.github.io$\u0026#34;) { set $cors_origin $http_origin; } if ($http_origin ~* \u0026#34;^https://lvcshu.netlify.com$\u0026#34;) { set $cors_origin $http_origin; } if ($request_method = \u0026#39;OPTIONS\u0026#39;) { return 204; } add_header Access-Control-Allow-Origin $cors_origin always; add_header Access-Control-Allow-Headers \u0026#34;Content-Type, Authorization\u0026#34; always; add_header Access-Control-Allow-Methods \u0026#34;GET, POST, OPTIONS, PUT, PATCH, DELETE, HEAD\u0026#34; always; add_header Access-Control-Max-Age 86400 always; } 修改 CSS 但是如果在主题的项目 CSS 里面写死我的 url 的话，因为上面有域名限制是不会生效的，可不能这样误导别人啊 QAQ，所以就把 CSS 的字体的声明在项目中删去了，要想正确加载字体只需要在 all.css 中加入这一句\n@font-face{font-family:\u0026#34;FZJL\u0026#34;;src:url(\u0026#39;字体所在url\u0026#39;)} @font-face{font-family:\u0026#34;FZLT\u0026#34;;src: url(\u0026#39;字体所在url\u0026#39;)} 即可生效\n参考  nginx 处理跨域 (cors) nginx 指定多个域名跨域请求配置 ","permalink":"https://blog.lvcshu.com/2019/10/07/%E9%85%8D%E7%BD%AEcors%E5%B0%8F%E8%AE%B0/","summary":"\u003cp\u003e最近在折腾博客的字体，最终选定了这几个字体作为网站的字体\u003c/p\u003e","title":"配置CORS小记"},{"content":"一直以来我都是用着 Telegram bot 来作为 RSS 推送阅读的阅读器，直到前几天我的 bot 突然宕机，我就懒得恢复了 因为我忘记他在哪个服务器上了嘤嘤嘤\n所以我就扒拉了下少数派的文章找到了几个 Android 上的 RSS 阅读器，分别是 FeedMe、Read、Newsfold 来进行体验并且筛选出一个我接下来要长期用的 RSS 阅读器。\n我评判的标准很简单，就是易用以及美观。\nRead 我首先使用的是 Read 这个 app，其实它同时可以进行 RSS 源的抓取工作，是一个比较全能的 RSS 阅读器，但是易用性上有一定的瑕疵:\n 只能一个个源分开阅读，没有汇总 缺少手势控制，标记所有文章为已读只能通过菜单 打开原网页需要拉到最下方，不是很方便  FeedMe \u0026amp; Newsfold 这个 app，在易用性上就比 Read 做得好许多，FeedMe 使用的界面设计遵循了 Google 的 MD2 标准 (现在 Google 自己都不遵守了) 而后者使用的设计则是偏向于极简的风格，手势操作等功能两者都做得不错，而 Nwefold 的设计就更加吸引我。\n可以看得出来界面是经过了用心的设计的\nNewsfold Google Play 下载\n","permalink":"https://blog.lvcshu.com/2019/09/25/rss-on-android/","summary":"\u003cp\u003e一直以来我都是用着 Telegram bot 来作为 RSS 推送阅读的阅读器，直到前几天我的 bot 突然宕机，我就懒得恢复了 \u003cdel\u003e因为我忘记他在哪个服务器上了嘤嘤嘤\u003c/del\u003e\u003c/p\u003e","title":"app推荐:安卓上好用的 RSS 客户端们"},{"content":"之前在 ikoula 买了个 8.99o/mo 的独服用来刷 PT ，最近看了下 ikoula 终于加上了 18.04 的镜像，就去升级了下。\n就在我用着之前开启 IPv6 的方法准备开启 IPv6 的时候，就发现怎样都不能成功。\n后来 ikoula 的客服告诉我 发现 ubuntu 18.04 的网络配置默认使用了 netplan 这个软件，就记录下怎么配置 ikoula 的 IPv6。\n配置文件在 /etc/netplan/01-netcfg.yaml\n原来的内容:\n# Network configuration file# Auto generated by Ikoulanetwork:version:2renderer:networkdethernets:eth0:dhcp4:noaddresses:[AAA.BBB.CCC.DDD/24]gateway4:AAA.BBB.CCC.1nameservers:addresses:[213.246.36.14,213.246.33.144,80.93.83.11]要改成这样\n# Network configuration file# Auto generated by Ikoulanetwork:version:2renderer:networkdethernets:eth0:dhcp4:noaddresses:[AAA.BBB.CCC.DDD/24,\u0026#34;2a00:c70:1:AAA:BBB:CCC:DDD:1/96\u0026#34;]gateway4:AAA.BBB.CCC.1gateway6:2a00:c70:1:AAA:BBB:CCC::1nameservers:addresses:[213.246.36.14,213.246.33.144,80.93.83.11]修改好了以后要用 netplan try 验证下格式有没有问题，没有问题 netplan 就会问是否加载配置，加载即可。\n参考:\n https://www.snel.com/support/how-to-configure-ipv6-with-netplan-on-ubuntu-18-04/ https://npchk.info/ikoula-ipv6/ ","permalink":"https://blog.lvcshu.com/2019/08/19/ikoula-%E7%8B%AC%E6%9C%8D-%E9%85%8D%E7%BD%AEipv6/","summary":"\u003cp\u003e之前在 ikoula 买了个 8.99o/mo 的独服用来刷 PT ，最近看了下 ikoula 终于加上了 18.04 的镜像，就去升级了下。\u003c/p\u003e","title":"ikoula Ubuntu 18.04 独服配置 IPv6"},{"content":"之前博客用的主题是移植自 Typecho 的 Maupassant 主题，简洁，也挺好看，就是有点略显单调\n，暑假也有点闲 于是就有了自己写一个适合自己的主题的想法。\n折腾了下就有了现在我用的这个主题 XvA 名字瞎起的没啥含义\n特性  自适应屏幕的大小 disqus 支持，还加上了 lazyload gitalk 支持 夜间模式 回到最顶按钮 自动生成友链页面（这个当时折腾了我好久 QAQ）  以下内容就是 Github 的 README  一个简约单的 HEXO 主题\nContents 目录  Install 安装 Configuration 配置 Demo 演示 TODO 待实现 Thanks 致谢 LICENSE 许可协议  Install 安装 git clone https://github.com/johnpoint/hexo-theme-XvA themes/XvA cd themes/XvA cp _config.example.yml _config.yml Configuration 配置 # 导航栏menu:Home:/Archives:/archivespost_copyright:enable:falseauthor:copyright_text:本作品采用\u0026lt;a rel=\u0026#34;license\u0026#34; href=\u0026#34;http://creativecommons.org/licenses/by-sa/4.0/\u0026#34;\u0026gt;知识共享署名-相同方式共享 4.0 国际许可协议\u0026lt;/a\u0026gt;进行许可。loading:falsetotop:truefancybox:truesitesince:#页脚版权信息，年份 Footer copyright information, filled in the year# 侧边栏# sidebarwidget:tag:enable:falsecount:10friends:# 友情链接 Linksenable:false# Links# 友情链接friends:pagetitle:list:- title:# 标题img:# 头像 Avatarurl:# 链接地址desc:# 简介 descriptionsidebar:false# 显示在侧边栏 Displayed in the sidebarpage:false# 在独立页面显示 Displayed on a separate page# 评论 二选一# pick one of twocomment:disqus:enable:falseshortname:lazyload:falsegitalk:# See https://github.com/gitalk/gitalk#Installenable:falseowner:repo:oauth:client_id:client_secret:admin:# - johnpoint# 网站统计analytics:google:enable:falseid:#UA-xxxxxx-xbusuanzi:# 不蒜子网站统计enable:falsetext:head: # 描述 示例:本站访客数 Example:viewend: # 描述 单位 示例:人次 Example:times# 效果: 本站访客数 233 人次# effect: view 233 timestagscloud:color:enable:falsestart:# Start color. You can use hex (#b700ff), rgba (rgba(183, 0, 255, 1)), hsla (hsla(283, 100%, 50%, 1)) or color keywords. This option only works when color is true.end:# End color. You can use hex (#b700ff), rgba (rgba(183, 0, 255, 1)), hsla (hsla(283, 100%, 50%, 1)) or color keywords. This option only works when color is true.text:min:20# 最小字体大小 Minimal font sizemax:40# 最大字体大小 Maximum font sizeunit:px# 字体尺寸单位 Unit of font sizeDemo 演示  hexo-theme-xva.github.io/ johnpoint\u0026rsquo;s blog  TODO 待实现  侧边栏友情链接 disqus google analytics 文章版权声明 highlight.js 代码高亮 独立友链页面 独立标签云 添加不蒜子访客统计 disqus lazyload 修复手机部分字体不兼容 图片窗口内打开 回到顶部 加载进度条 夜间模式 代码高亮优化 侧边目录优化 Gitment Gitalk 支持 添加动画效果 不蒜子阅读量统计 多语言支持 一言 支持  Thanks 致谢  twbs/bootstrap jQuery HubSpot/pace hexojs/hexo gitalk/gitalk  LICENSE 许可协议 GNU General Public License v3.0\n","permalink":"https://blog.lvcshu.com/2019/08/13/%E5%86%99%E4%BA%86%E4%B8%AAhexo%E4%B8%BB%E9%A2%98/","summary":"\u003cp\u003e之前博客用的主题是移植自 Typecho 的 \u003ca href=\"https://github.com/tufu9441/maupassant-hexo\"\u003eMaupassant\u003c/a\u003e 主题，简洁，也挺好看，就是有点略显单调\u003c/p\u003e","title":"写了个 Hexo 主题 hexo-theme-XvA"},{"content":"前不久转坑到 1 password 的我在看见了 keeweb 这一项目时又有了重回 keepass 的想法。\n在 Letitfly 大佬的频道看见了 这样一条消息，便抱着试一试的态度去尝试了一下 keeweb\n优点：\n 界面好看 使用简单 支持较为全面 跨平台 可以自行搭建 -\u0026gt; 我自建的在这 有自动备份  缺点：\n 缺少自动填充功能  上一些图：\n","permalink":"https://blog.lvcshu.com/2019/07/28/keepass%E5%AE%A2%E6%88%B7%E7%AB%AFkeeweb%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C/","summary":"\u003cp\u003e前不久转坑到 1 password 的我在看见了 keeweb 这一项目时又有了重回 keepass 的想法。\u003c/p\u003e","title":"keepass 客户端：keeweb 使用体验"},{"content":"前不久转坑到 1 password 的我在看见了 keeweb 这一项目时又有了重回 keepass 的想法。\n在 Letitfly 大佬的频道看见了 这样一条消息，便抱着试一试的态度去尝试了一下 keeweb\n优点：\n 界面好看 使用简单 支持较为全面 跨平台 可以自行搭建 -\u0026gt; 我自建的在这 有自动备份  缺点：\n 缺少自动填充功能  上一些图：\n","permalink":"https://blog.lvcshu.com/2019/07/28/keepass%E5%AE%A2%E6%88%B7%E7%AB%AFkeeweb%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C/","summary":"\u003cp\u003e前不久转坑到 1 password 的我在看见了 keeweb 这一项目时又有了重回 keepass 的想法。\u003c/p\u003e","title":"keepass 客户端：keeweb 使用体验"},{"content":"最近心痒痒想折腾下新的系统，顺便记录一下。\n介绍 Alpine Linux是一个由社区开发的Linux操作系统，该操作系统以安全为理念，面向x86路由器、防火墙、虚拟专用网、IP电话盒及服务器而设计。 摘自维基百科我是怎么发现这个系统的呢，前一阵子我在折腾 Docker 的时候我就发现 nginx 的官方 docker 仓库里面有一些 tag 的大小有很大的区别\n所以我就去 Google 了一下 alpine 的含义，就发现了这样的一个精简的 Linux 系统。\n安装 安装体验 ★★★★\n在官网下载 STANDARD 镜像大小仅 112 MB，可以说是特别小了，我去隔壁看一下 Arch 哇，比 Arch 的安装镜像（615 MB）还要小诶。\n安装过程简单明了。\n然后经过等待就搞定系统的安装了，虽然没有 GUI 但是安装体验还是挺好的。\n使用 包管理 alpine 使用的包管理器叫做 apk，查询有无相应的包可以使用 Alpine Linux Packages 进行查询。\n当然也可以使用 apk 的 apk search 命令进行查询。\n修改国内镜像源 我使用 tuna 的源\n修改 /etc/apk/repositories\nhttps://mirrors.ustc.edu.cn/alpine/v3.10/main https://mirrors.ustc.edu.cn/alpine/v3.10/community https://mirrors.ustc.edu.cn/alpine/edge/main https://mirrors.ustc.edu.cn/alpine/edge/community https://mirrors.ustc.edu.cn/alpine/edge/testing 修改 SSH 设置 alpine 默认的 ssh 设置是不能远程链接的。。。\n修改 /etc/ssh/sshd_config\n添加 PermitRootLogin yes 即可\n差不多就写到这~\n","permalink":"https://blog.lvcshu.com/2019/07/24/linux%E5%AE%B6%E6%97%8F-alpine%E4%BD%93%E9%AA%8C/","summary":"\u003cp\u003e最近心痒痒想折腾下新的系统，顺便记录一下。\u003c/p\u003e","title":"Linux 家族:Alpine 体验"},{"content":"买了天猫精灵方糖也有半年了 差不多 就写 水 一篇文章说说使用体验吧。\n外观 怎么说呢，中规中矩吧，说不上好看，但是它静静的躺在那也不会对你的视觉有所干扰，我还是蛮喜欢这个造型的\n音质 不算太差，可以听\n语音识别 处于能用就行的状态，唤醒词是 “天猫精灵” 和 “你好，天猫“ 误判率还是不算太低\n对于指令的响应不是很快，有时候我说完之后就 没有反应 ，有时候指令会 识别成歌名\n语音反馈有些难受，其实回答的字句库是足够丰富的，但是怎么不能 统一一下声音 呢？有很大概率在你的两次唤醒时对你的应答是不一样声音回答的。\n唤醒词不能更换，显得有点傻气，因为 唤醒词有点长\n广告 怎么说呢没倒是没有无缘无故就播放广告的程度，但是在几乎每一次应答之后就会顺带的噼里啪啦说上一大堆 很烦\n音乐 曲库还行，就是播放音乐之前自以为是的点评 透着傻气\n","permalink":"https://blog.lvcshu.com/2019/06/22/%E5%A4%A9%E7%8C%AB%E7%B2%BE%E7%81%B5-%E4%BD%93%E9%AA%8C/","summary":"\u003cp\u003e买了天猫精灵方糖也有半年了 \u003cdel\u003e差不多\u003c/del\u003e 就写 \u003cdel\u003e水\u003c/del\u003e 一篇文章说说使用体验吧。\u003c/p\u003e","title":"天猫精灵体验"},{"content":"之前的 hexo 博客我都是在电脑上进行生成然后 push 上 github repo，现在感觉有些麻烦 就是懒 所以就想着能不能用 travis-ci 自动化构建博客。\n准备 创建分支 我采用的方法是在 github 仓库上创建两个分支，master 和 source，分别存放生成的网站文件以及源文件。\n编写 travis 配置文件 文件内容如下：\nlanguage:node_jsnode_js:stablebranches:only:- sourcecache:apt:trueyarn:truedirectories:- node_modulesbefore_install:- git config --global user.name \u0026#34;johnpoint\u0026#34;- git config --global user.email \u0026#34;me@lvcshu.com\u0026#34;- curl -o- -L https://yarnpkg.com/install.sh | bash- export PATH=$HOME/.yarn/bin:$PATH- npm install -g hexo-cliinstall:- yarnscript:- npm install hexo-renderer-pug --save- npm install hexo-renderer-sass --save- npm install hexo-generator-feed --save- hexo clean- hexo generateafter_success:- mkdir push- cd ./push- git clone https://github.com/johnpoint/johnpoint.github.io .- rm * -rf- cp ../public/* . -r- git add --all .- git commit -m \u0026#34;Travis CI Auto Builder\u0026#34;- git push --quiet https://$REPO_TOKEN@github.com/johnpoint/johnpoint.github.iomaster配置 github 密钥 因为之前我是打开了 github 的双因素认证，所以 push 不能使用原来的 github 用户名 + 密码的方式进行身份认证了。\n在上图的地方加入 name 为 REPO_TOKEN，value 为 Personal access tokens\n等待开始构建 一般来说要做的工作就已经完成了，只需要静静的等待 travis-ci 的构建完成，这篇文章就是通过自动构建生成的\n","permalink":"https://blog.lvcshu.com/2019/06/15/%E4%BD%BF%E7%94%A8-travis-ci-%E8%87%AA%E5%8A%A8%E5%8C%96%E6%9E%84%E5%BB%BA%E5%8D%9A%E5%AE%A2/","summary":"\u003cp\u003e之前的 hexo 博客我都是在电脑上进行生成然后 push 上 github repo，现在感觉有些麻烦 \u003cdel\u003e就是懒\u003c/del\u003e 所以就想着能不能用 travis-ci 自动化构建博客。\u003c/p\u003e","title":"使用 travis-ci 自动化构建博客"},{"content":"电脑又出问题了\n升级了 ubuntu 19.04 以后我发现因为内核的更新，之前的驱动安装方法 已经失效了，所以就去寻找了新的安装方法\n感谢  tomaspinho/rtl8821ce  安装 sudo apt install dkms git -y git clone https://github.com/tomaspinho/rtl8821ce cd rtl8821ce 注意：之后就要断网，我是直接关掉了网络服务\n./dkms-install.sh 完成后加载模块\nsudo modprobe 8821ce 完成撒花～\n","permalink":"https://blog.lvcshu.com/2019/06/06/ubuntu%E5%AE%89%E8%A3%85rtl8821ce%E9%A9%B1%E5%8A%A8/","summary":"\u003cp\u003e\u003cdel\u003e电脑又出问题了\u003c/del\u003e\u003c/p\u003e","title":"Ubuntu 安装 rtl8821ce 驱动"},{"content":"在几次使用 Chrome 发现了网页的色彩渲染似乎有些问题\n如图\n可以很明显的发现色彩不一致，一开始我还以为是我的显示器的问题，直到发现了上面那一张图。\n然后经过简单的搜索我也得到了修复的方法\n打开 chrome://flags/#force-color-profile，将色彩配置设置为sRGB\n调整好以后效果就是这样的啦~\n","permalink":"https://blog.lvcshu.com/2019/06/04/%E4%BF%AE%E5%A4%8Dchrome%E8%89%B2%E5%B7%AE%E9%97%AE%E9%A2%98/","summary":"\u003cp\u003e在几次使用 Chrome 发现了网页的色彩渲染似乎有些问题\u003c/p\u003e","title":"修复Chrome色差问题"},{"content":"=。=\n给我的 Ubuntu 控制台窗口做了一些优化 (?)\n因为觉得原来默认的 Bash 太丑了\n就像这样\n然后现在改成了这样\n方法 修改 .bashrc\nexport PS1=\u0026#34;[ \\[\\033[1;32m\\]\\W\\[\\033[0m\\]\\]\\[\\033[1;32m\\[\\033[0m\\] ] $\u0026#34; alias short=\u0026#39;export PS1=\u0026#34;[ \\[\\033[1;32m\\]\\W\\[\\033[0m\\]\\]\\[\\033[1;32m\\[\\033[0m\\] ] $ \u0026#34;\u0026#39; alias long=\u0026#39;export PS1=\u0026#34;[ \\[\\033[1;33m\\]\\u \\[\\033[1;32m\\]\\w\\[\\033[0m\\] ] $ \u0026#34; \u0026#39; ","permalink":"https://blog.lvcshu.com/2019/05/28/%E4%BC%98%E5%8C%96bash%E6%8E%A7%E5%88%B6%E5%8F%B0%E6%98%BE%E7%A4%BA/","summary":"\u003cp\u003e=。=\u003c/p\u003e","title":"优化Bash控制台显示"},{"content":"最近刺激战场正式结束了公测并且改名成为和平精英割草正式经营\n按理来说这个游戏跟我是没有啥关系的，反正我又不玩，但是腾讯这种为了过审而采取的策略真的是emmmmm一言难尽\n就很奇怪，固然，血腥的内容的确有可能对青少年的身心发展有所影响，但是将血腥的内容魔改了以后会不会对青少年的世界观的形成产生影响呢？\n最近还看到了一个很滑稽的新闻（当然这新闻是编的）\n 【少年失手打死人却不承认：他没有和我挥手】 2035年，某地发生一起少年恶性伤人事件，一名17岁少年在和11岁少年争抢喜羊羊玩具时失手将对方打死。但17岁少年被逮捕后拒不承认杀人事实，他理由是对方只是装模作样流了些红色液体，并没有死，该少年甚至还反问， “他要是真死了，为什么不向我挥手？” 来源: https://t.me/XiaoNa_QAQ/2277\n","permalink":"https://blog.lvcshu.com/2019/05/12/%E5%92%8C%E5%B9%B3%E7%B2%BE%E8%8B%B1%E6%9C%89%E6%84%9F/","summary":"\u003cp\u003e最近刺激战场正式结束了公测并且改名成为和平精英\u003cdel\u003e割草\u003c/del\u003e正式经营\u003c/p\u003e","title":"和平精英有感"},{"content":"最近开的 Google I/O 大会公布了 Android Q beta3 的几款适配的机型，我的 Oneplus 6 恰好也在其中\n开心!!\n然后今天在刷入了 Android Q beta3 OOS 版后发现了不少的问题，毕竟 BETA 嘛，还不是正式版本，也可以理解，主要我能体验到的几点是:\n 通知栏图标太大了 快捷键 只有 三大金刚 说好的全面屏手势呢？ 设置了 PIN 码以后如果重启手机的话是 不能 成功的通过验证的 指纹解锁是 无效 的 SmartLock 内 没有 面部解锁 Google Assistant 不能 通过 \u0026lsquo;OK，google\u0026rsquo; 唤醒 通知采用的是右滑消除，左滑会有延迟提醒等更多的功能，行为模式需要一定的时间习惯 权限管理细致了许多 流畅度在我的体验里面没有特别的改变 USB 传文件似乎会导致系统错误？？（遇到过一次没有严格证实 动画的渐变变得更好看了 似乎没有找到隐藏刘海的选项  笔记 记录下 adb 跳过手机开机设置向导的方法，实测有效!!\nadb shell settings put secure user_setup_complete 1 adb shell settings put global device_provisioned 1 然后重启\n 此方法来源于: Android 跳过Gapps开机引导\n","permalink":"https://blog.lvcshu.com/2019/05/10/android-q-%E5%88%9D%E4%BD%93%E9%AA%8C/","summary":"\u003cp\u003e最近开的 Google I/O 大会公布了 Android Q beta3 的几款适配的机型，我的 Oneplus 6 恰好也在其中\u003c/p\u003e","title":"Android Q 初体验"},{"content":" Arch Linux（或 Arch /ˈɑːrtʃ/)）是一款基于 x86-64 架构的 Linux发行版。\n  Arch Linux 采用滚动发行模式来获取系统更新和软件的最新版本。系统安装映像只简单地包含系统主要组件。\n  Arch Linux 以社区 Wiki 的形式提供文档，称为 ArchWiki。该 Wiki 经常编有特定主题的最新信息，受到了 Linux 社区的广泛认可，内容也应用在 Arch Linux 以外的领域。\n 这三句话贯穿了我安装 Arch 全过程，就记录一下 免得我忘了 吧。\n下载安装镜像 安装镜像很小，直接下载即可\n\u0026raquo;传送门\u0026laquo;\n安装环境  VirtualBox Graphical User Interface Version 5.2.18_Ubuntu r123745  Memory: 4096 MB CPU: 4 BIOS 启动 Storage: 35 GB Network: NAT    安装 验证网络连接 ping archlinux.org 更新系统时间 timedatectl set-ntp true 设置分区 硬盘分区 fdisk /dev/sda 输入 n 新建分区 然后一路回车默认 最后 w 改变写入硬盘 格式化分区 mkfs.ext4 /dev/sda1 安装系统 准备 挂载分区 mount /dev/sda1 /mnt 设置软件源 在 Wiki 的 镜像源页面挑选适合的镜像。\n我选择阿里的源\n编辑源列表\nvim /etc/pacman.d/mirrorlist 添加\nServer = http://mirrors.aliyun.com/archlinux/$repo/os/$arch 安装基础系统 pacstrap /mnt base base-devel 设置新安装的系统 genfstab -U /mnt \u0026gt;\u0026gt; /mnt/etc/fstab 切换到新系统\narch-chroot /mnt 安装必要的软件 pacman -S vim nano 设置时区 ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime hwclock --systohc 设置本地化文本编码 nano /etc/locale.gen 加入\nzh_CN.UTF-8 UTF-8 执行\nlocale-gen nano /etc/locale.conf 加入\nLANG=en_US.UTF-8 设置 hostname \u0026amp;\u0026amp; HOST 编辑 /etc/hostname\nnano /etc/hosts 127.0.0.1 localhost ::1 localhost 127.0.1.1 arch.localdomain arch 账户设置 修改 root 密码 passwd 添加账户 useradd -m johnpoint passwd johnpoint 设置开机引导 安装 Grub pacman -S grub 部署 Grub grub-install --target=i386-pc /dev/sda grub-mkconfig -o /boot/grub/grub.cfg 至此，arch 就安装完成了，图形界面什么的 咕咕咕 下次再说\n","permalink":"https://blog.lvcshu.com/2019/05/07/%E5%AE%89%E8%A3%85arch%E7%AC%94%E8%AE%B0/","summary":"\u003cblockquote\u003e\n\u003cp\u003eArch Linux（或 Arch /ˈɑːrtʃ/)）是一款基于 x86-64 架构的 Linux发行版。\u003c/p\u003e\n\u003c/blockquote\u003e","title":"安装Arch笔记"},{"content":"博客终于在无数次的 想配置 TLS1.3 和 \u0026ldquo;啊好麻烦啊，不上了\u0026rdquo; 中一直没有上 TLS1.3\n借着更新 DNMP-lvcshu 项目中的 NGINX 模块，顺便把 TLS1.3 的支持给加上了，其实也没有做啥改变，就把 NGINX 的版本升级到了 1.15.11 就好了 其实是我太菜\n然后项目里 NGINX 的本来基于 UBUNTU 的镜像换成了 alpine 版本的镜像，体积： 45MB \u0026ndash;\u0026gt; 7MB，更加轻量化了呢。\n最麻烦的还是修改配置文件，毕竟每一个网站都要手动加上 TLS1.3 的相关配置，看起来分发 NGINX 配置文件的小工具也要提上日程了呢（四面杵鸽.jpg\n","permalink":"https://blog.lvcshu.com/2019/04/11/%E5%8D%9A%E5%AE%A2%E6%94%AF%E6%8C%81tls-1.3/","summary":"\u003cp\u003e博客终于在无数次的 想配置 TLS1.3 和 \u0026ldquo;啊好麻烦啊，不上了\u0026rdquo; 中一直没有上 TLS1.3\u003c/p\u003e","title":"博客支持 TLS 1.3"},{"content":"我们已经被微信捆住了\n先看看 微信，是一个生活方式\n微信= GFW – 一天世界\n先说好话 不可否认的是腾讯的微信的产生的确是即时通信软件的一个巨大的进步 不对啊\u0026hellip;其实都知道微信的一些功能其实并不是自己原创的，但是还是得益于微信的诞生使得熟人社交走进了我们的视线，balabala懒得吹下去了\n各种群 就我的感觉而言，微信不是一个恰当的通知发放的平台，有几点原因：\n 成员权限管理缺失 同时只能容纳一条群通知 消息各平台不能同步 消息无云端备份 消息排版几乎没有  首先，群员权限管理严重残废导致微信群内是不能进行禁言的操作的。\n而且，群友们显而易见的是一个比较容易忽略禁言令的群体。\n从而，导致了明明群名挂着的 禁言 形同虚设，通知与刷屏齐飞，往往不能很方便的看到通知。\n然后，微信的群公告是藏在微信群详情的菜单里面的，而展现在对话区域的内容与其他一般的聊天内容相比只是多出了 @所有人 这几个字，没有明显的区分度。\n更别说微信自己引以为傲的不保存聊天记录所以不能做到云备份聊天数据了，保存没有保存腾讯自己心里应该有数，就造成了微信的聊天记录其实是不可靠的。\n各种被要求关注的公众号 就以共青团员要关注的公众号来说，其实感觉已经比较过分了，从一开始的 广东共青团 到 广东青年之声 再到 广东学联，做个团员也太麻烦了吧，如果说关注一个公众号进行通知推送尚可理解，但是 强迫 关注三个公众号未免有点过分\n微信的封闭 不可否认的是微信的生态是业内的领先水平，但是对于我这样的自由爱好者来说，微信的生态从另一种层面来说就是一种封闭的表现，从微信聊天到公众号的休闲阅读再到微信支付，体验的一致感是有了，但是流量一经微信的入口，就几乎没有任何出口再次让流量进入自由的互联网了，微信仿佛互联网上的孤岛，看似链接了互联网的丰富内容，其实你永远处于微信的牢笼里。\n微信真的成为了生活方式 最后的最后，我是真的没有想到，真的会有人发短信让我去看微信\u0026hellip;\n微信像一条绳子，先把一部分人捆住了，然后再让那一部分人把另一部分人捆住。\n","permalink":"https://blog.lvcshu.com/2019/04/03/%E6%88%91%E4%BB%AC%E5%B7%B2%E7%BB%8F%E8%A2%AB%E5%BE%AE%E4%BF%A1%E6%8D%86%E4%BD%8F%E4%BA%86/","summary":"\u003cp\u003e我们已经被微信捆住了\u003c/p\u003e","title":"我们已经被微信捆住了"},{"content":"一直好奇主机商们是怎么把一台独立服务器分成 VPS 来售卖的，这几天就去玩了 下 Proxmox VE\n环境  Ubuntu 18.04.2 桌面版 VirtualBox Graphical User Interface Version 5.2.18_Ubuntu r123745 Proxmox-ve_5.3-2  安装 由于我手头上实在是没有空余的机器，所以我向我的笔记本 伸出了邪恶的手 ，新建了一个虚拟机，分配给它 4G 内存， 50G 硬盘 。安装时候直接在 官网-下载 下载 Proxmox VE 5.3 ISO Installer iso 镜像，像平时安装系统一样安装上去，完全傻瓜式。\n安装好以后就会提示你登录并给了你一个网页的地址，就像这样\n但是我们的是虚拟机所以需要在 Settings-\u0026gt;Network-\u0026gt;Adapter 1-\u0026gt;Advanced-\u0026gt;Port Forwarding 配置端口转发\n然后在浏览器访问 https://127.0.0.1:映射的端口 就可以看见面板了。\n使用 面板的右上角有 [创建虚拟机] [创建 CT] 的按钮，分别对应虚拟化技术 KVM 以及 OpenVZ（LXC？）\n镜像下载 KVM 直接下载官方的安装镜像，并把镜像放置在\n/var/lib/vz/template/iso\nOpenVZ 需要到 OpenVZ 官网的 下载页面 下载\n放置目录是\n/var/lib/vz/template/cache\n网卡 \u0026amp; NAT 由于我是虚拟机开虚拟机，并且没有公网ip，所以我们需要通过 NAT(Network Address Translation)来对流量转发，不然就是单机游戏啦\n母鸡的配置 编辑文件 /etc/network/interfaces 添加\nauto vmbr2 iface vmbr4 inet static address 10.97.0.254 netmask 255.255.255.0 bridge-ports none bridge-stp off bridge-fd 0 post-up echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward post-up iptables -t nat -A POSTROUTING -s \u0026#39;10.97.0.0/24\u0026#39; -o vmbr0 -j MASQUERADE post-down iptables -t nat -D POSTROUTING -s \u0026#39;10.97.0.0/24\u0026#39; -o vmbr0 -j MASQUERADE post-up iptables -t nat -A PREROUTING -i vmbr0 -p tcp --dport 1024 -j DNAT --to 10.97.0.1:22 post-down iptables -t nat -D PREROUTING -i vmbr0 -p tcp --dport 1024 -j DNAT --to 10.97.0.1:22 然后执行 /etc/init.d/networking restart\n就能添加一张网卡，这张网卡主要是用于接下来的小鸡的流量转发用的，他会把所有的流量转向母鸡可以连接外网的网卡。\n小鸡的配置 按照上面的信息随机应变 (?) 就好，网管要填 母鸡的IP\nTips:  这里的配置主要是开 CT 容器，KVM 的或许以后会更 咕咕咕 centos 7 的 OpenVZ 镜像貌似有问题，密码是没有办法输对的  最后 开了三台服务器～\n参考  Proxmox VE三种方法配置NAT小鸡和IPv6地址 Proxmox VE安装和KVM开设教程 OpenVZ安装指南 ","permalink":"https://blog.lvcshu.com/2019/03/17/%E5%88%9D%E6%8E%A2proxmox-ve/","summary":"\u003cp\u003e一直好奇主机商们是怎么把一台独立服务器分成 VPS 来售卖的，这几天就去玩了 下 Proxmox VE\u003c/p\u003e","title":"初探 Proxmox VE"},{"content":"自从把主力的系统从 windows 转向了 ubuntu 了以后，感觉 ubuntu 实在是比 windows 要方便许多 （除了进行文档处理的操作以外）\n，所以我一直以来使用的是 Google 推出的在线文档处理网站，基础功能是有了，但是远远没有微软的 office 成熟。我也曾经尝试过开源的 libreoffice 以及 金山公司推出的 WPS office for linux。但是他们都各有缺点。一是与 M$ office 不是完美的兼容，二是软件体积臃肿，多出来很多没有必要存在的功能（说的就是 WPS ）。\n然后我才发现了 office 365 online 神器一般的存在，因为他几乎不会占据电脑的本地资源，与 M$ office 完全兼容，功能齐全(跟电脑上的桌面版已经没有什么区别了！！)，文件是储存在 onedrive 上的，非常方便。 爽到了啊！！！\n","permalink":"https://blog.lvcshu.com/2019/03/02/office-365-online-%E5%A4%AA%E5%A5%BD%E7%94%A8%E5%95%A6/","summary":"\u003cp\u003e自从把主力的系统从 windows 转向了 ubuntu 了以后，感觉 ubuntu 实在是比 windows 要方便许多 （除了进行文档处理的操作以外）\u003c/p\u003e","title":"office 365 online 太好用啦!"},{"content":" 这是一篇笔记\n  内容：Github commit添加verified标识\n 就是一直以来都 懒得 忙得没有将这个事情做好 但是其实这个东西好像并没有什么用\n用户端 生成 GPG 密钥对 gpg --gen-key gpg --list-keys 列出 GPG 密钥对 导出 public 文件 gpg --armor --output public-key.txt --export E081E7D64************29B7080083 gpg --armor --output private-key.txt --export-secret-keys 配置本地 Git git config --global user.signingkey E081E7D64************29B7080083 git config --global commit.gpgsign true Github 端 cat public-key.txt 将结果填入 Personal settings-\u0026gt;SSH and GPG keys\n保存\n-EOF-\n","permalink":"https://blog.lvcshu.com/2019/02/09/github-commit%E6%B7%BB%E5%8A%A0verified%E6%A0%87%E8%AF%86/","summary":"\u003cblockquote\u003e\n\u003cp\u003e这是一篇笔记\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e内容：Github commit添加verified标识\u003c/p\u003e\n\u003c/blockquote\u003e","title":"Github commit添加verified标识"},{"content":"话说用了那么久小米手环，其实感觉还是比较不错的，唯一美中不足的就是小米手环的附属应用 小米运动(mi fit)\n实在是令人失望，不仅仅是因为广告，而且他本身的功能并不是很周全，比如睡觉似乎只能统计在晚上的睡觉时间，而不能统计午觉。\n解决方案 使用第三方 app\nnotify \u0026amp; fitness for mi band\n优势  统计精度 比 小米运动 强 可以全天统计睡眠 没有广告！！！ 可以连接小米体重秤 与 小米运动 相比 毫不逊色 专注 没有 乱七八糟 的社交功能 更多 的自定义功能 可以连接 Google fit 无需 依赖 小米运动  劣势  专业功能需要专业版的授权 $3.14 (反正我是果断购买了) 可定制选项 过多 所以可能容易使人 凌乱 可能是我比较蠢,哭  软件截图  Google play: notify \u0026amp; fitness for mi band\n","permalink":"https://blog.lvcshu.com/2019/01/22/app%E6%8E%A8%E8%8D%90notify-fitness-for-mi-band/","summary":"\u003cp\u003e话说用了那么久小米手环，其实感觉还是比较不错的，唯一美中不足的就是小米手环的附属应用 \u003ccode\u003e小米运动(mi fit)\u003c/code\u003e\u003c/p\u003e","title":"app推荐:notify \u0026 fitness for mi band"},{"content":"话说用了那么久小米手环，其实感觉还是比较不错的，唯一美中不足的就是小米手环的附属应用 小米运动(mi fit)\n实在是令人失望，不仅仅是因为广告，而且他本身的功能并不是很周全，比如睡觉似乎只能统计在晚上的睡觉时间，而不能统计午觉。\n解决方案 使用第三方 app\nnotify \u0026amp; fitness for mi band\n优势  统计精度 比 小米运动 强 可以全天统计睡眠 没有广告！！！ 可以连接小米体重秤 与 小米运动 相比 毫不逊色 专注 没有 乱七八糟 的社交功能 更多 的自定义功能 可以连接 Google fit 无需 依赖 小米运动  劣势  专业功能需要专业版的授权 $3.14 (反正我是果断购买了) 可定制选项 过多 所以可能容易使人 凌乱 可能是我比较蠢,哭  软件截图  Google play: notify \u0026amp; fitness for mi band\n","permalink":"https://blog.lvcshu.com/2019/01/22/app%E6%8E%A8%E8%8D%90notify-fitness-for-mi-band/","summary":"\u003cp\u003e话说用了那么久小米手环，其实感觉还是比较不错的，唯一美中不足的就是小米手环的附属应用 \u003ccode\u003e小米运动(mi fit)\u003c/code\u003e\u003c/p\u003e","title":"app推荐:notify \u0026 fitness for mi band"},{"content":"emmmmm 众所周知由于中国的特殊情况使得中国的网络监管机制有别于外国，国内开展各项网络业务是需要经过备案的，而备案过程比较繁琐而且需要上传持证照，我是不太喜欢这个玩意儿的，所以我的博客也没备案。\n使用 CDN 备案既有好处也有坏处，备案了以后国内的各种云服务是没有限制的，包括阿里云、腾讯云各种云的位于国机房的服务器都可以用来搭网站，还可以使用国内的 CDN 服务。但是我的博客没备案阿\u0026hellip;所以之前一直是使用的 DO 美国服务器，备案是不需要了，但网络世界不会忽略物理中对光的速度限制，延迟坏的很大的很，所以就琢磨着用一下 CDN ( Content Delivery Network 内容分发网络 ) 诶作为穷人的我当然是选择去 白嫖使用免费的 CDN 啦，我使用的是 CloudFlare 这个服务商，这个服务商真的是一言难尽，的确他的数据中心遍布世界，除了中国 所以就造成了 CloudFlare 的服务在中国显得不那么给力，后来我还是放弃了使用 CloudFlare 作为 CDN 的方案 才不是因为 CloudFlare 要氪金才能使用自己证书这个原因 反正后来就没用 CDN 了\n也不是没有想过用其他家的 CDN 。就是要么贵要么比CloudFlare效果差。\n更换 DNS 然后，这几天比较有空 才不是我考试前摸鱼 就想着换一下 DNS 解析提供商，之前是一直用的 CloudFlare 的 DNS 后来就算没使用 CDN 功能还继续在用，但是好像 CloudFlare 的 DNS 在国内有些节点不知道被谁糟蹋了（狗头保命）使用体验不佳，所以就把 DNS 迁移到了 NS1。\n说说 NS1  NS1.com是国外一家提供专业的DNS域名解析服务商，除了付费的DNS域名解析外，还提供了免费的DNS域名解析套餐，免费额度为500k Queries 、50 Records 、1 Built-in Monitor 、1 Filter Chain 和NS1 API，基本上可以满足日常建站的需要了。 节选自 NS1 DNS域名解析使用-Master/Slave主从DNS和世界各地分区解析\n 就是这样，看起来很专业，事实上也是很专业的。\n但是就是有一个比较麻烦的是注册的时候需要使用信用卡进行验证（好像是不支持银联的？） 反正我注册了。\n功能特别丰富而且统计功能也很强大，现在用着最好用的工具就是他分区域解析了 CloudXNS虽然说更加强大，但是也要持证照 #碎碎念\n分区域解析 emmmmm这样就很简单了，设置 DNS 亚洲请求返回香港的服务器，欧洲请求返回欧洲服务器，其他请求通通丢到美国服务器。\n网站同步 其实更加好的选择是使用 nginx 反向代理 + 缓存，但是我比较懒 就用 git 来同步我的各种网站内容了，在 cron 写个定时任务美滋滋，要是详说下去就是个大坑了以后再说~~（发出了鸽子的声音~~\n相关链接 NS1 DNS域名解析使用-Master/Slave主从DNS和世界各地分区解析 NS1.com 博客双开，避免offline™\n","permalink":"https://blog.lvcshu.com/2019/01/14/%E7%9C%9F-%E5%A4%9A%E7%82%B9%E9%83%A8%E7%BD%B2%E5%8D%9A%E5%AE%A2/","summary":"\u003cp\u003eemmmmm 众所周知由于中国的特殊情况使得中国的网络监管机制有别于外国，国内开展各项网络业务是需要经过备案的，而备案过程比较繁琐而且需要上传持证照，我是不太喜欢这个玩意儿的，所以我的博客也没备案。\u003c/p\u003e","title":"真-多点部署博客"},{"content":"自从使用了 docker 作为基础环境以后，我想着写一个能够服务进行统一集中管理的面板，一方面不想使用市面上使用比较广泛面板 因为我做到他们不行啊啊啊，一方面也算是一种练习吧\n简述 抬头看下网站证书，yes！已经更换成泛域名证书啦~ 简单的说下现在已经实现的 满是bug的 功能，证书分发，前文提过我是集中一个面板进行管理，面板中集成一个文件 getcerfile.php 可以直接访问（当然是有鉴权的啦，证书什么的不鉴权放公网会凉的），证书选用 Let’s 签发泛域名证书这样就不用考虑证书签发的时候解析到底解析到哪台服务器上去了 不用造多轮子了，ye\n证书检测 这一部分主要是受了 Axton 大佬的启发 详情看 这篇文章 ，加上本人比较弱，且目前暂时还不想用上数据库存数据，所以目前是用文件 + shell 进行证书检查工作 配合 php 输出为不那么难看的页面 并且嵌入在面板中。\n效果图：\nemmmmmmmmm上传时发现自建图床好像出了问题。。考虑自己写一个？ 先咕咕咕为敬\n代码如下：\n#!/bin/sh  cat urlfile.list | while read line do touch \u0026#34;data/$line\u0026#34; touch \u0026#34;data/$line.ca\u0026#34; curl https://$line -v -s -o /dev/null 2\u0026gt;\u0026#34;data/$line.ca\u0026#34; datee=$(date +\u0026#39;%F %H:%M\u0026#39;) echo \u0026#34;最后检查: \u0026#34; $datee \u0026gt; \u0026#34;data/$line\u0026#34; data=$(cat \u0026#34;data/$line.ca\u0026#34; | grep \u0026#39;subject:\u0026#39;) echo \u0026#34;证书域名: \u0026#34; ${data##* subject: } \u0026gt;\u0026gt; \u0026#34;data/$line\u0026#34; data=$(cat \u0026#34;data/$line.ca\u0026#34; | grep \u0026#39;start date:\u0026#39;) data=$(date -d \u0026#34;${data##* start date: }\u0026#34; +\u0026#39;%F %H:%M:%S\u0026#39;) echo \u0026#34;签发日期: \u0026#34;${data} \u0026gt;\u0026gt; \u0026#34;data/$line\u0026#34; startdate=$data data=$(cat \u0026#34;data/$line.ca\u0026#34; | grep \u0026#39;expire date: \u0026#39;) data=$(date -d \u0026#34;${data##* expire date: }\u0026#34; +\u0026#39;%F %H:%M:%S\u0026#39;) echo \u0026#34;失效日期: \u0026#34; $data \u0026gt;\u0026gt; \u0026#34;data/$line\u0026#34; enddate=$data data=$(cat \u0026#34;data/$line.ca\u0026#34; | grep \u0026#39;issuer: \u0026#39;) echo \u0026#34;签发机构: \u0026#34;${data##* issuer: } \u0026gt;\u0026gt; \u0026#34;data/$line\u0026#34; data=$(cat \u0026#34;data/$line.ca\u0026#34; | grep \u0026#39;SSL certificate verify ok.\u0026#39;) echo \u0026#34;证书状态: \u0026#34;${data##* } \u0026gt;\u0026gt; \u0026#34;data/$line\u0026#34; startdate=$(date -d \u0026#34;${startdate}\u0026#34; +%s) enddate=$(date -d \u0026#34;${enddate}\u0026#34; +%s) datee=$(date -d \u0026#34;${datee}\u0026#34; +%s) long=$(($enddate-$startdate)) datee=$(($datee-$startdate)) datee=$(($datee*100)) hundred=100 persent=$(($datee/$long)) echo \u0026#34;\u0026lt;div class=\\\u0026#34;mdui-progress\\\u0026#34;\u0026gt;\u0026lt;div class=\\\u0026#34;mdui-progress-determinate\\\u0026#34; style=\\\u0026#34;width: ${persent}%;\\\u0026#34;\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;/div\u0026gt;\u0026#34; \u0026gt;\u0026gt; \u0026#34;data/$line\u0026#34; rm \u0026#34;data/$line.ca\u0026#34; done 展示的代码如下：\n\u0026lt;?php include_once \u0026#39;config.php\u0026#39;; if ($_COOKIE[\u0026#34;user\u0026#34;] == md5($username.$userpasswd)) { echo \u0026#39;\u0026lt;div class=\u0026#34;mdui-panel\u0026#34; mdui-panel\u0026gt;\u0026#39;; function listDir($dir) { if (is_dir($dir)) { if ($dh = opendir($dir)) { while (($file = readdir($dh)) !== false) { if ($file != \u0026#34;.\u0026#34; \u0026amp;\u0026amp; $file != \u0026#34;..\u0026#34;) { echo \u0026#39;\u0026lt;div class=\u0026#34;mdui-panel-item\u0026#34;\u0026gt;\u0026#39;; echo \u0026#39;\u0026lt;div class=\u0026#34;mdui-panel-item-header\u0026#34;\u0026gt;\u0026#39;.\u0026#39;\u0026lt;div class=\u0026#34;mdui-panel-item-title\u0026#34;\u0026gt;\u0026#39;.$file.\u0026#39;\u0026lt;/div\u0026gt;\u0026#39;.\u0026#39;\u0026lt;i class=\u0026#34;mdui-panel-item-arrow mdui-icon material-icons\u0026#34;\u0026gt;keyboard_arrow_down\u0026lt;/i\u0026gt;\u0026#39;.\u0026#39;\u0026lt;/div\u0026gt;\u0026#39;; echo \u0026#39;\u0026lt;div class=\u0026#34;mdui-panel-item-body\u0026#34;\u0026gt;\u0026#39;; $myfile = fopen(\u0026#34;$dir/$file\u0026#34;, \u0026#34;r\u0026#34;) or die(\u0026#34;Unable to open file!\u0026#34;); while (!feof($myfile)) { echo \u0026#39;\u0026lt;p\u0026gt;\u0026#39;.fgets($myfile) . \u0026#39;\u0026lt;/p\u0026gt;\u0026#39;; } echo \u0026#39;\u0026lt;/div\u0026gt;\u0026lt;/div\u0026gt;\u0026#39;; fclose($myfile); } } closedir($dh); } } else { echo $dir . \u0026#39;\u0026lt;br\u0026gt;\u0026#39;; } } listDir(\u0026#34;./data\u0026#34;); echo \u0026#39;\u0026lt;/div\u0026gt;\u0026#39;; } else { echo \u0026#39;error\u0026#39;; } ?\u0026gt; 证书分发 emmmm上面也看的出来我是用 user 和 passwd md5一下写进cookie进行验证的，需要验证的 域名直接存放在 urlfile.list 文件里面 (我实在是太菜了)\n同理分发证书也利用 cookie 进行身份验证\n\u0026lt;?php include_once \u0026#39;config.php\u0026#39;; if ($_COOKIE[\u0026#34;user\u0026#34;] == md5($username.$userpasswd)) { $myfile = fopen($_GET[\u0026#39;file\u0026#39;], \u0026#34;r\u0026#34;) or die(\u0026#34;Unable to open file!\u0026#34;); echo fread($myfile, filesize($_GET[\u0026#39;file\u0026#39;])); fclose($myfile); } else { header(\u0026#34;Location: /index.php\u0026#34;); } ?\u0026gt; 然后直接读取证书文件进行直接输出，同时 nginx 那儿对文件目录进行权限控制，获取证书使用\ncurl https://****/getcerfile.php?file=ssl/lvcshu.com/lvcshu.com.key -H \u0026#39;cookie: user=？？？\u0026#39; \u0026gt; lvcshu.com.key 获取，这样在需要部署证书服务器上定时执行脚本可以更新证书了，同时 泛域名证书 使用 acme.sh 进行自动续期 emmmmmmmm 差不多这样如各位大佬发现什么不妥地方记得及时联系我啊 QAQ Telegram:@johnpoint\n","permalink":"https://blog.lvcshu.com/2019/01/10/%E6%94%B9%E8%BF%9Bssl%E8%AF%81%E4%B9%A6%E7%9B%B8%E5%85%B3%E7%AD%96%E7%95%A5/","summary":"\u003cp\u003e自从使用了 docker 作为基础环境以后，我想着写一个能够服务进行统一集中管理的面板，一方面不想使用市面上使用比较广泛面板 \u003cdel\u003e因为我做到他们不行啊啊啊\u003c/del\u003e，一方面也算是一种练习吧\u003c/p\u003e","title":"改进SSL证书相关策略"},{"content":"首先 圣诞快乐~ 转眼间啊，2018年就快要过去了，是时候来 水 写一篇年终总结了\n Photo by Fabrizio Verrecchia on Unsplash\n 学习 这一年学了什么？  apache PHP javacript SQL docker  成果？ emmmmmmmm好像也没有什么成果可以出来说的，就简单的定制了几个 docker 并且写成了 docker-compose 使得我在部署服务器的时候能够更加方便，然后时间也比之前采用的脚本的编译安装要大大缩短，以后重装服务器就更加肆无忌惮了\n同时，初步的尝试使用 N2Nv2 的 peer to peer VPN 把所有的服务器链接成一个大内网，以后有什么证书之类的文件就可以通过内网进行传输了，并且我的电脑也连上了这个内网，使得我在外面（不在电脑身边）也能通过连接上我任意一台 VPS 来链接我的电脑。但是目前只是刚刚开始部署，估计完全搞定得到 2019 年了\u0026hellip;.\n还有这个！ 求star！！ johnpoint/anti-360browser.js\nGithub 的一年 那么 2019 加油哇~\n__ __ ___ ___ _ ___ __ / / / / |___ \\ / _ \\/ |( _ ) \\ \\ / / / / __) | | | | |/ _ \\ \\ \\ \\ \\ / / / __/| |_| | | (_) | / / \\_\\ /_/ |_____|\\___/|_|\\___/ /_/  2019 计划  预习JAVA 把 业余无线电牌照 考到手 继续学习算法知识 待定\u0026hellip;  ","permalink":"https://blog.lvcshu.com/2018/12/25/2018%E5%B9%B4%E5%BA%A6%E7%AE%80%E6%8A%A5/","summary":"首先 圣诞快乐~ 转眼间啊，2018年就快要过去了，是时候来 水 写一篇年终总结了\n Photo by Fabrizio Verrecchia on Unsplash\n 学习 这一年学了什么？  apache PHP javacript SQL docker  成果？ emmmmmmmm好像也没有什么成果可以出来说的，就简单的定制了几个 docker 并且写成了 docker-compose 使得我在部署服务器的时候能够更加方便，然后时间也比之前采用的脚本的编译安装要大大缩短，以后重装服务器就更加肆无忌惮了\n同时，初步的尝试使用 N2Nv2 的 peer to peer VPN 把所有的服务器链接成一个大内网，以后有什么证书之类的文件就可以通过内网进行传输了，并且我的电脑也连上了这个内网，使得我在外面（不在电脑身边）也能通过连接上我任意一台 VPS 来链接我的电脑。但是目前只是刚刚开始部署，估计完全搞定得到 2019 年了\u0026hellip;.\n还有这个！ 求star！！ johnpoint/anti-360browser.js\nGithub 的一年 那么 2019 加油哇~\n__ __ ___ ___ _ ___ __ / / / / |___ \\ / _ \\/ |( _ ) \\ \\ / / / / __) | | | | |/ _ \\ \\ \\ \\ \\ / / / __/| |_| | | (_) | / / \\_\\ /_/ |_____|\\___/|_|\\___/ /_/  2019 计划  预习JAVA 把 业余无线电牌照 考到手 继续学习算法知识 待定\u0026hellip;  ","title":"2018年度简报"},{"content":" 提醒：这只是一篇学习笔记，不保证语句通顺，仅作记录。\n 学习目标 安装 httpd、php、mysql  建立 两个 虚拟主机建立网站，并申请 SSL 使其能够通过 https 访问  学习过程 安装 yum install https://mirrors.ustc.edu.cn/epel/epel-release-latest-6.noarch.rpm https://mirrors.ustc.edu.cn/remi/enterprise/remi-release-6.rpm yum -y install yum-utils yum-config-manager --enable remi-php72 yum -y install httpd mysql mysql-server mysql-connector-odbc mysql-devel libdbi-dbd-mysql openssl mod_ssl httpd-manual mod_ssl mod_perl mod_auth_mysql yum -y install php php-mcrypt php-cli php-gd php-curl php-mysql php-zip php-fileinfo php-fpm php-xml php-mbstring php-ldap php-xmlrpc php-devel 设置开机启动\nchkconfig httpd on chkconfig mysqld on 建立虚拟主机文件夹\ncd /home mkdir www 修改httpd配置文件\ncd /etc/httpd/conf vi httpd.conf 加入\nInclude /home/www/vhost.conf 解析域名 略\n新建虚拟主机 建立虚拟主机路径 cd /home/www mkdir hk.lvcshu.info 新建虚拟主机配置 vi vhost.conf 写入\n\u0026lt;VirtualHost :80\u0026gt; DocumentRoot /home/www/hk.lvcshu.info ServerName hk.lvcshu.info RewriteEngine on RewriteCond %{SERVER_PORT} !^443 RewriteRule ^(.)?$ https://%{SERVER_NAME}/$1 [R=permanent,L] \u0026lt;Directory \u0026ldquo;/home/www/hk.lvcshu.info\u0026rdquo;\u0026gt; Options Indexes FollowSymLinks AllowOverride all Order Deny,Allow Deny from none Allow from all 建立一个简陋的主页 略\n申请证书 使用 acme.sh 的开源项目\ncurl https://get.acme.sh | sh\ncd .acme.sh acme.sh \u0026ndash;issue -d hk.lvcshu.info \u0026ndash;webroot /home/www/hk.lvcshu.info/ 证书路径：/root/.acme.sh/hk.lvcshu.info\nSSLCertificateFile /root/.acme.sh/hk.lvcshu.info/hk.lvcshu.info.cer SSLCertificateKeyFile /root/.acme.sh/hk.lvcshu.info/hk.lvcshu.info.key 配置 https \u0026lt;VirtualHost *:443\u0026gt; DocumentRoot /home/www/hk.lvcshu.info ServerName hk.lvcshu.info SSLEngine on SSLCertificateFile /root/.acme.sh/hk.lvcshu.info/hk.lvcshu.info.cer SSLCertificateKeyFile /root/.acme.sh/hk.lvcshu.info/hk.lvcshu.info.key return 0;\n更新：\n其实有一个更加好的虚拟主机的管理方法，那就是一个网站用一个配置文件来管理，在配置文件 httpd.conf 中直接引入 /home/www/vhost/* 即可\n例如在 /home/www/vhost 中 hk.lvcshu.info.dom 即为 hk.lvcshu.info 的配置文件。\n","permalink":"https://blog.lvcshu.com/2018/11/02/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%88%9D%E8%AF%86httpd/","summary":"提醒：这只是一篇学习笔记，不保证语句通顺，仅作记录。\n 学习目标 安装 httpd、php、mysql  建立 两个 虚拟主机建立网站，并申请 SSL 使其能够通过 https 访问  学习过程 安装 yum install https://mirrors.ustc.edu.cn/epel/epel-release-latest-6.noarch.rpm https://mirrors.ustc.edu.cn/remi/enterprise/remi-release-6.rpm yum -y install yum-utils yum-config-manager --enable remi-php72 yum -y install httpd mysql mysql-server mysql-connector-odbc mysql-devel libdbi-dbd-mysql openssl mod_ssl httpd-manual mod_ssl mod_perl mod_auth_mysql yum -y install php php-mcrypt php-cli php-gd php-curl php-mysql php-zip php-fileinfo php-fpm php-xml php-mbstring php-ldap php-xmlrpc php-devel 设置开机启动\nchkconfig httpd on chkconfig mysqld on 建立虚拟主机文件夹\ncd /home mkdir www 修改httpd配置文件","title":"学习笔记:初识httpd"},{"content":" 提醒：这只是一篇学习笔记，不保证语句通顺，仅作记录。\n 学习目标 安装 httpd、php、mysql  建立 两个 虚拟主机建立网站，并申请 SSL 使其能够通过 https 访问  学习过程 安装 yum install https://mirrors.ustc.edu.cn/epel/epel-release-latest-6.noarch.rpm https://mirrors.ustc.edu.cn/remi/enterprise/remi-release-6.rpm yum -y install yum-utils yum-config-manager --enable remi-php72 yum -y install httpd mysql mysql-server mysql-connector-odbc mysql-devel libdbi-dbd-mysql openssl mod_ssl httpd-manual mod_ssl mod_perl mod_auth_mysql yum -y install php php-mcrypt php-cli php-gd php-curl php-mysql php-zip php-fileinfo php-fpm php-xml php-mbstring php-ldap php-xmlrpc php-devel 设置开机启动\nchkconfig httpd on chkconfig mysqld on 建立虚拟主机文件夹\ncd /home mkdir www 修改httpd配置文件\ncd /etc/httpd/conf vi httpd.conf 加入\nInclude /home/www/vhost.conf 解析域名 略\n新建虚拟主机 建立虚拟主机路径 cd /home/www mkdir hk.lvcshu.info 新建虚拟主机配置 vi vhost.conf 写入\n\u0026lt;VirtualHost :80\u0026gt; DocumentRoot /home/www/hk.lvcshu.info ServerName hk.lvcshu.info RewriteEngine on RewriteCond %{SERVER_PORT} !^443 RewriteRule ^(.)?$ https://%{SERVER_NAME}/$1 [R=permanent,L] \u0026lt;Directory \u0026ldquo;/home/www/hk.lvcshu.info\u0026rdquo;\u0026gt; Options Indexes FollowSymLinks AllowOverride all Order Deny,Allow Deny from none Allow from all 建立一个简陋的主页 略\n申请证书 使用 acme.sh 的开源项目\ncurl https://get.acme.sh | sh\ncd .acme.sh acme.sh \u0026ndash;issue -d hk.lvcshu.info \u0026ndash;webroot /home/www/hk.lvcshu.info/ 证书路径：/root/.acme.sh/hk.lvcshu.info\nSSLCertificateFile /root/.acme.sh/hk.lvcshu.info/hk.lvcshu.info.cer SSLCertificateKeyFile /root/.acme.sh/hk.lvcshu.info/hk.lvcshu.info.key 配置 https \u0026lt;VirtualHost *:443\u0026gt; DocumentRoot /home/www/hk.lvcshu.info ServerName hk.lvcshu.info SSLEngine on SSLCertificateFile /root/.acme.sh/hk.lvcshu.info/hk.lvcshu.info.cer SSLCertificateKeyFile /root/.acme.sh/hk.lvcshu.info/hk.lvcshu.info.key return 0;\n更新：\n其实有一个更加好的虚拟主机的管理方法，那就是一个网站用一个配置文件来管理，在配置文件 httpd.conf 中直接引入 /home/www/vhost/* 即可\n例如在 /home/www/vhost 中 hk.lvcshu.info.dom 即为 hk.lvcshu.info 的配置文件。\n","permalink":"https://blog.lvcshu.com/2018/11/02/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%88%9D%E8%AF%86httpd/","summary":"提醒：这只是一篇学习笔记，不保证语句通顺，仅作记录。\n 学习目标 安装 httpd、php、mysql  建立 两个 虚拟主机建立网站，并申请 SSL 使其能够通过 https 访问  学习过程 安装 yum install https://mirrors.ustc.edu.cn/epel/epel-release-latest-6.noarch.rpm https://mirrors.ustc.edu.cn/remi/enterprise/remi-release-6.rpm yum -y install yum-utils yum-config-manager --enable remi-php72 yum -y install httpd mysql mysql-server mysql-connector-odbc mysql-devel libdbi-dbd-mysql openssl mod_ssl httpd-manual mod_ssl mod_perl mod_auth_mysql yum -y install php php-mcrypt php-cli php-gd php-curl php-mysql php-zip php-fileinfo php-fpm php-xml php-mbstring php-ldap php-xmlrpc php-devel 设置开机启动\nchkconfig httpd on chkconfig mysqld on 建立虚拟主机文件夹\ncd /home mkdir www 修改httpd配置文件","title":"学习笔记:初识httpd"},{"content":"前一阵子我入手了一（台？）（个？）树莓派，但是一直都没有时间研究该用来做什么\u0026hellip;. 然后无意间看见了一个叫做pi-dashboard 的小玩意儿 上一张图看看\n就是这样，性能看起来就比较方便了\n安装docker 这里参考的是docker 中文文档的安装过程 诶，用官方脚本一步搞定嘞\ncurl -fsSL get.docker.com -o get-docker.sh sudo sh get-docker.sh --mirror Aliyun 很快的。。。\n使用docker一步搞定 pi-dashboard sudo docker run -d --name docker-pi-dashboard -e \u0026#39;LISTEN=1024\u0026#39; --net=host ecat/docker-pi-dashboard 来自一键部署pi dashboard\n好了，就这么水完了\u0026hellip;\n","permalink":"https://blog.lvcshu.com/2018/10/21/%E6%A0%91%E8%8E%93%E6%B4%BE-docker-%E6%90%AD%E5%BB%BA-pi-dashboard/","summary":"\u003cp\u003e前一阵子我入手了一（台？）（个？）树莓派，但是一直都没有时间研究该用来做什么\u0026hellip;. 然后无意间看见了一个叫做pi-dashboard 的小玩意儿 上一张图看看\u003c/p\u003e","title":"树莓派 docker 搭建 pi-dashboard"},{"content":"注意：本文已失效，目前有效的方法在 这里\n最近入手了一台 thinkpad S2 ，打开 windows 系统，觉得缺了点什么，于是连忙把 ubuntu 系统也安装了上去，但是在配置 ubuntu 系统的时候并没有让我连接网络的选项，当时就感觉有些奇怪\u0026lt;!\u0026mdash;more\u0026mdash;\u0026gt;，但是没有放在心上。安装完成后打开 ubuntu 系统发现系统 根本没有 检测到无线网卡的存在，于是我就慌了，赶紧回到 windows 系统，看见了无线网卡的型号\nRealtek 8821CE Wireless LAN 802.11ac PCI-E NIC 于是使用强大的 百度 google 搜索解决办法，最后在 ubuntu论坛 的这个帖子里发现了解决办法。\n解决方法 由这个帖子里的大佬在这里请教到的大佬给出解决方法\n原文如下：\nWorked solution (Requirements: kernel \u0026gt;=4.11) : (UPD: In the latest release of endlessm you need kernel version 4.15) Download driver directory from this repo: https://github.com/endlessm/linux/tree/master/drivers/net/wireless/rtl8821ce You can do it by this link: https://minhaskamal.github.io/DownGit/#/home?url=https://github.com/endlessm/linux/tree/master/drivers/net/wireless/rtl8821ce Unpack zip archive. Change the Makefile. Line \u0026#34;export TopDIR ?= ...\u0026#34; to export \u0026#34;TopDIR ?= PATH TO EXTRACTED DIRECTORY\u0026#34;. $ make $ sudo make install $ sudo modprobe -a 8821ce 至此，完美解决了这个问题\n一点小问题 在某次 ubuntu 的内核升级了以后，我发现我的无线网卡驱动 又没了 马上扔掉电脑 于是我想到了使用脚本进行安装，这样就可以在下一次遇到这样的问题时快速解决！\n脚本内容：\n#!/bin/bash  mv rtl8821ce.zip /home/johnpoint cd ~ unzip rtl8821ce.zip cd rtl8821ce make sudo make install sudo modprobe -a 8821ce exit 0 撒花\n","permalink":"https://blog.lvcshu.com/2018/08/25/ubuntu%E5%AE%89%E8%A3%85-thinkpad-s2-%E6%97%A0%E7%BA%BF%E7%BD%91%E5%8D%A1%E9%A9%B1%E5%8A%A8/","summary":"注意：本文已失效，目前有效的方法在 这里\n最近入手了一台 thinkpad S2 ，打开 windows 系统，觉得缺了点什么，于是连忙把 ubuntu 系统也安装了上去，但是在配置 ubuntu 系统的时候并没有让我连接网络的选项，当时就感觉有些奇怪\u0026lt;!\u0026mdash;more\u0026mdash;\u0026gt;，但是没有放在心上。安装完成后打开 ubuntu 系统发现系统 根本没有 检测到无线网卡的存在，于是我就慌了，赶紧回到 windows 系统，看见了无线网卡的型号\nRealtek 8821CE Wireless LAN 802.11ac PCI-E NIC 于是使用强大的 百度 google 搜索解决办法，最后在 ubuntu论坛 的这个帖子里发现了解决办法。\n解决方法 由这个帖子里的大佬在这里请教到的大佬给出解决方法\n原文如下：\nWorked solution (Requirements: kernel \u0026gt;=4.11) : (UPD: In the latest release of endlessm you need kernel version 4.15) Download driver directory from this repo: https://github.com/endlessm/linux/tree/master/drivers/net/wireless/rtl8821ce You can do it by this link: https://minhaskamal.github.io/DownGit/#/home?url=https://github.com/endlessm/linux/tree/master/drivers/net/wireless/rtl8821ce Unpack zip archive. Change the Makefile.","title":"\u003c失效\u003e Ubuntu 安装 thinkpad S2 无线网卡驱动"},{"content":"密码一直以来是人们帐号的一个薄弱点，通过各种各样的途径，想要获取他人密码的人总能获取到另他们满意的信息，\u0026lt;!\u0026mdash;more\u0026mdash;\u0026gt;而人们喜欢利用自己个人信息的组合作为密码立下了汗马功劳，而一些人对于密码重要性毫不了解从而设下简单密码的人也功不可没，而我，一直以来使用的是一串字符串所生成 md5 来作为我帐号的密码，自认为十分安全，实则不然，因为密码中只含有小写字母和数字，是可以实现暴力破解的。加上一些特殊符号的密码是目前为止相对安全的密码解决方案，但是 复杂的密码太难记了啊 这该咋办，直到某群大佬说出了 密码管理器是好文明（） 我才发现原来早就有人想到解决方案了。\n目前，网络上流行的有四款密码管理器：\n KeePass：免费 开源 兼容性强 LastPass：最大的优势是跨浏览器平台 1Password：跨平台管理 用户认可度高 Enpass：支持平台多 20条密码免费  而其中，我第一时间试用了 LastPass 发现多设备使用需要高级版本授权，而授权居然需要 VISA卡 （我没有啊啊啊啊） ，于是舍弃。后来我看见了开源解决方案 KeePass 在经过一段时间的使用之后，觉得用起来十分舒服，而且支持 Linux 、Windows 和手机系统，而且支持 Webdav ，这在自己已经搭建了网盘的人来说简直就是太爽了，不用担心密码存放在别人手里而不安全，但是安全设施一定要做好。\nKeePass 同样采用了主流的一个主密码打开密码数据库文件的模式，这时，这个主密码就代表了你的所有密码，需要尽可能的兼顾复杂与你的好记，这就是唯一需要做的。至于其他密码，KeePass 提供了随机密码生成器，能自定义生成密码包含 字母、符号、特殊字符等内容，还可以自定义长度，总之就是非常爽就是了。\n在用上 KeePass 的那一晚，我就把每一个可以想起来的帐号都改成了自动生成的强密码，感觉自己的帐号安全提升了不止一点半点，美滋滋～\n赶快去尝试下咯～\n","permalink":"https://blog.lvcshu.com/2018/08/24/%E5%AF%86%E7%A0%81%E7%AE%A1%E7%90%86%E5%99%A8%E6%98%AF%E5%A5%BD%E6%96%87%E6%98%8E/","summary":"密码一直以来是人们帐号的一个薄弱点，通过各种各样的途径，想要获取他人密码的人总能获取到另他们满意的信息，\u0026lt;!\u0026mdash;more\u0026mdash;\u0026gt;而人们喜欢利用自己个人信息的组合作为密码立下了汗马功劳，而一些人对于密码重要性毫不了解从而设下简单密码的人也功不可没，而我，一直以来使用的是一串字符串所生成 md5 来作为我帐号的密码，自认为十分安全，实则不然，因为密码中只含有小写字母和数字，是可以实现暴力破解的。加上一些特殊符号的密码是目前为止相对安全的密码解决方案，但是 复杂的密码太难记了啊 这该咋办，直到某群大佬说出了 密码管理器是好文明（） 我才发现原来早就有人想到解决方案了。\n目前，网络上流行的有四款密码管理器：\n KeePass：免费 开源 兼容性强 LastPass：最大的优势是跨浏览器平台 1Password：跨平台管理 用户认可度高 Enpass：支持平台多 20条密码免费  而其中，我第一时间试用了 LastPass 发现多设备使用需要高级版本授权，而授权居然需要 VISA卡 （我没有啊啊啊啊） ，于是舍弃。后来我看见了开源解决方案 KeePass 在经过一段时间的使用之后，觉得用起来十分舒服，而且支持 Linux 、Windows 和手机系统，而且支持 Webdav ，这在自己已经搭建了网盘的人来说简直就是太爽了，不用担心密码存放在别人手里而不安全，但是安全设施一定要做好。\nKeePass 同样采用了主流的一个主密码打开密码数据库文件的模式，这时，这个主密码就代表了你的所有密码，需要尽可能的兼顾复杂与你的好记，这就是唯一需要做的。至于其他密码，KeePass 提供了随机密码生成器，能自定义生成密码包含 字母、符号、特殊字符等内容，还可以自定义长度，总之就是非常爽就是了。\n在用上 KeePass 的那一晚，我就把每一个可以想起来的帐号都改成了自动生成的强密码，感觉自己的帐号安全提升了不止一点半点，美滋滋～\n赶快去尝试下咯～","title":"密码管理器是好文明"},{"content":"怎么双开博客呢？ 答案就是—— vps 与 github 一起部署。。。\n好吧，我承认我是标题党了一下，主要是记录一下我 成功部署 完 hexo 博客了以后如何将博客部署到 github 上去。\n创建远程仓库 就是在 github 上创建一个名称为 用户名.github.io 的仓库，这一个仓库可以在自动化部署之后在 用户名.github.io 生成博客，而用 github 在全世界（除中国大陆，中国大陆就是互联网上的孤岛）外厉害的 cdn ，我们的博客访问速度会比较快， 注意，一开始我是选择不初始化仓库，这样可以避免一些莫名奇妙的坑！\n修改 站点配置 在 站点根目录 下的 _config.yml 寻找 deploy 关键词，将其 整部分 修改为：\ndeploy:type:gitrepo:GitHub上仓库的完整路径包括 .gitbranch:masterrepo 的链接一定要是 ssh 而不是 https 的！！！\n配置 git 生成 ssh 密钥\ngit config --global user.name \u0026#34;你的GitHub用户名\u0026#34; git config --global user.email \u0026#34;你的GitHub注册邮箱\u0026#34; 生成ssh密钥文件：\nssh-keygen -t rsa -C \u0026#34;你的GitHub注册邮箱\u0026#34; 然后直接三个回车即可，默认不需要设置密码 然后找到生成的 .ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制\n打开 GitHub_Settings_keys 页面，新建 new SSH Key\nTitle 为标题，任意填即可，将刚刚复制的 id_rsa.pub 内容粘贴进去，最后点击 Add SSH key。\n大功告成！\n 以上部分内容来自 GitHub+Hexo 搭建个人网站详细教程\n 推送博客至 github 好了，我们使用下面的一条指令就可以将博客推送到 github 上，实现某些意义上的 neveroffline™ 了！\n撒花～～\n","permalink":"https://blog.lvcshu.com/2018/08/07/%E5%8D%9A%E5%AE%A2%E5%8F%8C%E5%BC%80%E9%81%BF%E5%85%8Doffline/","summary":"怎么双开博客呢？ 答案就是—— vps 与 github 一起部署。。。\n好吧，我承认我是标题党了一下，主要是记录一下我 成功部署 完 hexo 博客了以后如何将博客部署到 github 上去。\n创建远程仓库 就是在 github 上创建一个名称为 用户名.github.io 的仓库，这一个仓库可以在自动化部署之后在 用户名.github.io 生成博客，而用 github 在全世界（除中国大陆，中国大陆就是互联网上的孤岛）外厉害的 cdn ，我们的博客访问速度会比较快， 注意，一开始我是选择不初始化仓库，这样可以避免一些莫名奇妙的坑！\n修改 站点配置 在 站点根目录 下的 _config.yml 寻找 deploy 关键词，将其 整部分 修改为：\ndeploy:type:gitrepo:GitHub上仓库的完整路径包括 .gitbranch:masterrepo 的链接一定要是 ssh 而不是 https 的！！！\n配置 git 生成 ssh 密钥\ngit config --global user.name \u0026#34;你的GitHub用户名\u0026#34; git config --global user.email \u0026#34;你的GitHub注册邮箱\u0026#34; 生成ssh密钥文件：\nssh-keygen -t rsa -C \u0026#34;你的GitHub注册邮箱\u0026#34; 然后直接三个回车即可，默认不需要设置密码 然后找到生成的 .ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制","title":"博客双开，避免offline™"},{"content":"首先先说一说吐槽一下微信封闭的生态圈，除了开放给搜狗这个搜索引擎可以搜索微信公众号的 api 之外，几乎没有开放任何可以利用的 api ，固然这有其在安全方面的考虑，但是这就使得一些比较有趣的功能难以实现，例如机器人。而一些比较实用的功能又在官方垃圾客户端中没有实现。\n需求 在 chrome 上了 web 版微信的基础上利用 chrome 自带的 console + javascript 实现 自动、循环、发送信息\n施工 首先声明，我在事前并 没有 了解过 javascript 这种语言，一切都是通过善用搜索引擎来一步一步实现的，所以请各位看到这一篇文章的大佬们看到有什么不妥的地方欢迎在评论区指出。\n网页源码 首先当然是登录网页版微信，顺手打开 F12 开发者工具，尝试着发送了几条信息，并在 network 选项卡里面观察了一下网页的活动，然后发现\n\u0026lt;pre id=\u0026#34;editArea\u0026#34; contenteditable-directive=\u0026#34;\u0026#34; mm-paste=\u0026#34;\u0026#34; class=\u0026#34;flex edit_area ng-isolate-scope ng-pristine ng-valid\u0026#34; contenteditable=\u0026#34;true\u0026#34; ng-blur=\u0026#34;editAreaBlur($event)\u0026#34; ng-model=\u0026#34;editAreaCtn\u0026#34; ng-click=\u0026#34;editAreaClick($event)\u0026#34; ng-keyup=\u0026#34;editAreaKeyup($event)\u0026#34; ng-keydown=\u0026#34;editAreaKeydown($event)\u0026#34;\u0026gt;\u0026lt;/pre\u0026gt; 然而并没有什么用。。。\ngoogle搜索 然后，我分别以 微信、发信息、chrome、console、javascript 为关键词进行搜索，最终发现了这篇文章–\u0026gt;用javascriptt脚本实现微信定时发送信息，关键词命中。遂打开，发现正是我想要的。\n修改代码\n// 周一----周五： 6:50 AM 提醒对方起床， 9：30 PM提醒对方回宿舍  var appElement = document.querySelector(\u0026#39;[ng-controller=chatSenderController]\u0026#39;); var $scope = angular.element(appElement).scope(); setInterval(function(){ var localTime = new Date(); if(localTime.getDay() \u0026lt; 6){ //非周末  var localTimeString = localTime.toLocaleTimeString(); if(localTimeString.indexOf(\u0026#39;上午6:49:00\u0026#39;) === 0){ $scope.editAreaCtn = \u0026#34;6.50了，你该起床了！\u0026#34;; $scope.sendTextMessage(); }else if(localTimeString.indexOf(\u0026#39;上午6:54:00\u0026#39;) === 0){ $scope.editAreaCtn = \u0026#34;今天又是新的一天，祝你好运！\u0026#34;; $scope.sendTextMessage(); }else if(localTimeString.indexOf(\u0026#39;下午9:28:00\u0026#39;) === 0){ $scope.editAreaCtn = \u0026#34;时间快到9:30了，你该回去了！\u0026#34;; $scope.sendTextMessage(); } } },1000); 在这篇文章中，发送微信消息之前还要进行一波判断，但是我不需要，我只需要无脑发就行，（对了还要设置一个间歇时间，不然就成了刷屏了），最终改成这样：\nvar appElement = document.querySelector(\u0026#39;[ng-controller=chatSenderController]\u0026#39;); var $scope = angular.element(appElement).scope(); setInterval(function(){ $scope.editAreaCtn = \u0026#34;消息内容\u0026#34;; $scope.sendTextMessage(); },1000); 然后把这一段小代码输进 console 运行了一下，哎呦，太快了。赶紧停下，发现 chrome 已经全神贯注发信息卡死了。。。无奈只好 kill 了 chrome 的进程。\nsleep 的加入以及最终成果 然后想起 python 是有 sleep 这种用法的，马上搜索下，发现了一种 javascript sleep 的 土制方法（ javascript 本身不支持 sleep ）\n最后修改了下代码，再结合 for 进行死循环，最终成果：\nvar appElement = document.querySelector(\u0026#39;[ng-controller=chatSenderController]\u0026#39;); var $scope = angular.element(appElement).scope(); async function test() { $scope.editAreaCtn = \u0026#34;发送内容\u0026#34;; $scope.sendTextMessage(); } function sleep(ms) { return new Promise(resolve =\u0026gt; setTimeout(resolve, ms)) } i = 0 for (; ; i++) { test() await sleep(1000000) } 那么，只需要登录网页版微信，定位到想发信息的聊天窗口，运行即可！\n 续\n在写完了上一篇文章以后，问题来了，有个人开始笑话我代码自带加密，于是，按照他的要求改了一下，顺便加上了从10～15分钟随机抽取间歇时间的功能，代码如下：\nvar appElement = document.querySelector(\u0026#39;[ng-controller=chatSenderController]\u0026#39;); var $scope = angular.element(appElement).scope(); var n = 10; var m = 15; //引入sleep function sleep(ms) { return new Promise(resolve =\u0026gt; setTimeout(resolve, ms)) } //发送消息 async function test() { $scope.editAreaCtn = \u0026#34;消息内容\u0026#34;; $scope.sendTextMessage(); } //产生n~m的随机数 function rd(n,m){ var c = m-n+1; return Math.floor(Math.random() * c + n); } //死循环 while(true){ test(); t = rd(n,m) console.log(t) await sleep(t * 10000); } 今日水文结束\n","permalink":"https://blog.lvcshu.com/2018/07/21/%E8%AE%BE%E5%AE%9A%E5%BE%AE%E4%BF%A1%E8%87%AA%E5%8A%A8%E5%8F%91%E9%80%81%E4%BF%A1%E6%81%AF/","summary":"首先先说一说吐槽一下微信封闭的生态圈，除了开放给搜狗这个搜索引擎可以搜索微信公众号的 api 之外，几乎没有开放任何可以利用的 api ，固然这有其在安全方面的考虑，但是这就使得一些比较有趣的功能难以实现，例如机器人。而一些比较实用的功能又在官方垃圾客户端中没有实现。\n需求 在 chrome 上了 web 版微信的基础上利用 chrome 自带的 console + javascript 实现 自动、循环、发送信息\n施工 首先声明，我在事前并 没有 了解过 javascript 这种语言，一切都是通过善用搜索引擎来一步一步实现的，所以请各位看到这一篇文章的大佬们看到有什么不妥的地方欢迎在评论区指出。\n网页源码 首先当然是登录网页版微信，顺手打开 F12 开发者工具，尝试着发送了几条信息，并在 network 选项卡里面观察了一下网页的活动，然后发现\n\u0026lt;pre id=\u0026#34;editArea\u0026#34; contenteditable-directive=\u0026#34;\u0026#34; mm-paste=\u0026#34;\u0026#34; class=\u0026#34;flex edit_area ng-isolate-scope ng-pristine ng-valid\u0026#34; contenteditable=\u0026#34;true\u0026#34; ng-blur=\u0026#34;editAreaBlur($event)\u0026#34; ng-model=\u0026#34;editAreaCtn\u0026#34; ng-click=\u0026#34;editAreaClick($event)\u0026#34; ng-keyup=\u0026#34;editAreaKeyup($event)\u0026#34; ng-keydown=\u0026#34;editAreaKeydown($event)\u0026#34;\u0026gt;\u0026lt;/pre\u0026gt; 然而并没有什么用。。。\ngoogle搜索 然后，我分别以 微信、发信息、chrome、console、javascript 为关键词进行搜索，最终发现了这篇文章–\u0026gt;用javascriptt脚本实现微信定时发送信息，关键词命中。遂打开，发现正是我想要的。\n修改代码\n// 周一----周五： 6:50 AM 提醒对方起床， 9：30 PM提醒对方回宿舍  var appElement = document.querySelector(\u0026#39;[ng-controller=chatSenderController]\u0026#39;); var $scope = angular.element(appElement).scope(); setInterval(function(){ var localTime = new Date(); if(localTime.","title":"设定微信自动发送信息"},{"content":"使用lnmp.org的lnmp安装一键包，按程序安装好即可，并顺手创建一个虚拟主机，不需要重写，不需要数据库。\n 本文采用 lvcshu.com 为示例域名\n 安装 HEXO 按照官网说明的方法一步步安装\n安装 node.js curl:\ncurl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash 或\nwget:\nwget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash 然后重启终端或者ssh重新连接\nnvm install stable 安装 hexo-cil npm install -g hexo-cli 随后就会很快安装完成！\n部署博客  安装Hexo后，运行以下命令以初始化目标中的Hexo 。\n 此处的 folder 就是我们博客的主目录，即 lnmp 虚拟主机的目录，进入目录以后执行\nhexo init . npm install hexo g 此时我们博客的静态页面已经成功生成了，但是访问页面是没有办法看到的，接着下一步\n调整 nginx 配置文件 打开 nginx 相应站点 的配置文件，找到\nroot /home/wwwroot/lvcshu.com; 改为\nroot /home/wwwroot/blog.lvcshu.com/public; 记住：有两个地方要改，对应http与https\n推荐：可以将 http 通过301跳转，跳转到 https\nlnmp nginx restart 看看效果吧！\n更换主题 网络上有很多开源的，十分漂亮的 hexo 主题而默认主题是真的丑我想不使用默认主题，找到了一个极简但是十分美观的主题——“NexT”\n安装 NexT 主题 进入博客主目录\ngit clone https://github.com/theme-next/hexo-theme-next themes/next 然后前往 站点配置文件(博客主目录下 ‘_config.yml’) 将 theme 字段改为 next ，然后执行 hexo clean \u0026amp;\u0026amp; hexo g ,打开网站即可看到效果。\n Next主题优化 以下内容来自 Hexo+Next主题优化 建议前往围观及点赞！\n设置主题风格 打开 themes/next/_config.yml 文件，搜索 scheme 关键字，将你需用启用的 scheme 前面注释 # 去除即可。\n\\# --------------------------------------------------------------- \\# Scheme Settings \\# --------------------------------------------------------------- \\# Schemes #scheme: Muse # 默认 Scheme，这是 NexT 最初的版本，黑白主调，大量留白 #scheme: Mist # Muse 的紧凑版本，整洁有序的单栏外观 scheme: Pisces # 双栏 Scheme，小家碧玉似的清新 #scheme: Gemini # 类似 Pisces 设置菜单项的显示文本和图标 NexT 使用的是 Font Awesome 提供的图标， Font Awesome 提供了 600+ 的图标，可以满足绝大的多数的场景，同时无须担心在 Retina 屏幕下图标模糊的问题。\n设置菜单项的显示中文文本： 打开 themes/next/languages/zh-Hans.yml 文件,搜索 menu 关键字，修改对应中文或者新增。\nmenu: home: 首页 archives: 归档 categories: 分类 tags: 标签 about: 关于 search: 搜索 schedule: 日程表 sitemap: 站点地图 commonweal: 公益404 # 新增menu catalogue: 目录 设定菜单项的文件目录和对应图标（新版两项合并） 打开 themes/next/_config.yml 文件，搜索 menu_icons 关键字，修改对应图标名称或者新增对应 menu 的图标。\n\\# --------------------------------------------------------------- \\# Menu Settings \\# --------------------------------------------------------------- \\# When running the site in a subdirectory (e.g. domain.tld/blog), remove the leading slash from link value (/archives -\u0026gt; archives). \\# Usage: \\`Key: /link/ || icon\\` \\# Key is the name of menu item. If translate for this menu will find in languages - this translate will be loaded; if not - Key name will be used. Key is case-senstive. \\# Value before `||` delimeter is the target link. \\# Value after `||` delimeter is the name of FontAwesome icon. If icon (with or without delimeter) is not specified, question icon will be loaded. menu: home: / || home archives: /archives/ || history categories: /categories/ || list tags: /tags/ || tags tools: /categories/工具资源/ || briefcase about: /about/ || user #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat \\# Enable/Disable menu icons. \\# Icon Mapping: \\# Map a menu item to a specific FontAwesome icon name. \\# Key is the name of menu item and value is the name of FontAwesome icon. Key is case-senstive. \\# When an question mask icon presenting up means that the item has no mapping icon. menu_icons: enable: true 除了 home， archives , /后面都需要手动创建这个页面\n创建菜单项对应文件目录 以分类为例，在终端窗口下，定位到 Hexo 站点目录下。使用 hexo new page 新建一个页面，命名为 categories ：\ncd your-hexo-site hexo new page categories 编辑刚新建的页面,设置分类\n\\-\\-\\- title: 分类 date: 2014-12-22 12:39:04 categories: Testing #分类名 type: \u0026#34;categories\u0026#34; \\-\\-\\- 头像设置 添加头像 打开 themes/next/_config.yml 文件，搜索 Sidebar Avatar 关键字，去掉 avatar 前面的 #：\n\\# Sidebar Avatar \\# in theme directory(source/images): /images/avatar.jpg \\# in site directory(source/uploads): /uploads/avatar.jpg avatar: http://example.com/avatar.png 或者使用本地图片,把图片放入 themes/next/source/images 下,修改 avatar：\navatar: /images/avatar.gif\n设置头像边框为圆形框 打开位于 themes/next/source/css/_common/components/sidebar/sidebar-author.syl 文件,修改如下:\n.site-author-image { display: block; margin: 0 auto; padding: $site-author-image-padding; max-width: $site-author-image-width; height: $site-author-image-height; border: $site-author-image-border-width solid $site-author-image-border-color; // 修改头像边框 border-radius: 50%; -webkit-border-radius: 50%; -moz-border-radius: 50%; } 特效：鼠标放置头像上旋转 .site-author-image { display: block; margin: 0 auto; padding: $site-author-image-padding; max-width: $site-author-image-width; height: $site-author-image-height; border: $site-author-image-border-width solid $site-author-image-border-color; // 修改头像边框 border-radius: 50%; -webkit-border-radius: 50%; -moz-border-radius: 50%; // 设置旋转 transition: 1.4s all; } // 可旋转的圆形头像,\\`hover\\`动作 .site-author-image:hover { -webkit-transform: rotate(360deg); -moz-transform: rotate(360deg); -ms-transform: rotate(360deg); -transform: rotate(360deg); } 浏览页面的时候显示当前浏览进度 打开 themes/next/_config.yml ,搜索关键字 scrollpercent ,把 false 改为 true。\n把top按钮放在侧边栏 如果想把 top 按钮放在侧边栏,打开 themes/next/_config.yml ,搜索关键字 b2t ,把 false 改为 true。\n\\# Back to top in sidebar b2t: true \\# Scroll percent label in b2t button scrollpercent: true 侧边栏设置 设置侧边栏社交链接 打开 themes/next/_config.yml 文件,搜索关键字 social ,然后添加社交站点名称与地址即可。\n\\# --------------------------------------------------------------- \\# Sidebar Settings \\# --------------------------------------------------------------- \\# Social Links. \\# Usage: \\`Key: permalink || icon\\` \\# Key is the link label showing to end users. \\# Value before `||` delimeter is the target permalink. \\# Value after `||` delimeter is the name of FontAwesome icon. If icon (with or without delimeter) is not specified, globe icon will be loaded. social: E-Mail: mailto:yourname@gmail.com || envelope Google: https://plus.google.com/yourname || google Twitter: https://twitter.com/yourname || twitter FB Page: https://www.facebook.com/yourname || facebook # 等等 设置侧边栏社交图标 打开 themes/next/_config.yml 文件,搜索关键字 social_icons ，添加社交站点名称（注意大小写）图标，Font Awesome图标地。\nRSS 在你 Hexo 站点目录下：\nnpm install hexo-generator-feed --save 打开 Hexo 站点下的 _config.yml ,添加如下配置：\n\\# feed \\# Dependencies: https://github.com/hexojs/hexo-generator-feed feed: type: atom path: atom.xml limit: 20 hub: content: 友情链接 打开 themes/next/_config.yml 文件,搜索关键字 Blog rolls：\n\\# Blog rolls links_title: 友情链接 #标题 links_layout: block #布局，一行一个连接 #links_layout: inline links: #连接 baidu: http://example.com/ google: http://example.com/ 主页文章添加边框阴影效果 打开 themes/next/source/css/_custom/custom.styl ,向里面加代码:\n// 主页文章添加阴影效果 .post { margin-top: 0px; margin-bottom: 60px; padding: 25px; -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5); -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5); } 修改文章间分割线 打开 themes/next/source/css/_common/components/post/post-eof.styl ,修改：\n.posts-expand { .post-eof { display: block; // margin: $post-eof-margin-top auto $post-eof-margin-bottom; width: 0%; //分割线长度 height: 0px; // 分割线高度 background: $grey-light; text-align: center; } } 代码块自定义样式 // Custom styles. code { color: #ff7600; background: #fbf7f8; margin: 2px; } // 边框的自定义样式 .highlight, pre { margin: 5px 0; padding: 5px; border-radius: 3px; } .highlight, code, pre { border: 1px solid #d6d6d6; } 开启版权声明 主题配置文件下,搜索关键字 post_copyright , enable 改为 true：\n\\# Declare license on posts post_copyright: enable: true license: CC BY-NC-SA 4.0 license_url: https://creativecommons.org/licenses/by-nc-sa/4.0/ 自定义文章底部版权声明\n作者：Dragonstyle 链接：http://www.dragonstyle.win/2017/09/06/Android-Studio个人设置/ 來源：简书 版权声明： 本博客所有文章除特别声明外，均采用 CC BY-NC-SA 4.0 许可协议。转载请注明出处！ 在目录 themes/next/layout/_macro/ 下添加 my-copyright.swig ,内容如下:\n{% if page.copyright %} \u0026lt;div class=\u0026#34;my\\_post\\_copyright\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- JS库 sweetalert 可修改路径 --\u0026gt; \u0026lt;!-- \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;http://jslibs.wuxubj.cn/sweetalert_mini/jquery-1.7.1.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; type=\u0026#34;text/css\u0026#34; href=\u0026#34;http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.mini.css\u0026#34;\u0026gt;--\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span\u0026gt;本文标题:\u0026lt;/span\u0026gt;{{ page.title }}\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span\u0026gt;文章作者:\u0026lt;/span\u0026gt;{{ theme.author }}\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span\u0026gt;发布时间:\u0026lt;/span\u0026gt;{{ page.date.format(\u0026#34;YYYY年MM月DD日 - HH:mm:ss\u0026#34;) }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span\u0026gt;最后更新:\u0026lt;/span\u0026gt;{{ page.updated.format(\u0026#34;YYYY年MM月DD日 - HH:mm:ss\u0026#34;) }}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span\u0026gt;原始链接:\u0026lt;/span\u0026gt;\u0026lt;a href=\u0026#34;{{ url_for(page.path) }}\u0026#34; title=\u0026#34;{{ page.title }}\u0026#34;\u0026gt;{{ page.permalink }}\u0026lt;/a\u0026gt; \u0026lt;span class=\u0026#34;copy-path\u0026#34; title=\u0026#34;点击复制文章链接\u0026#34;\u0026gt;\u0026lt;i class=\u0026#34;fa fa-clipboard\u0026#34; data-clipboard-text=\u0026#34;{{ page.permalink }}\u0026#34; aria-label=\u0026#34;复制成功！\u0026#34;\u0026gt;\u0026lt;/i\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span\u0026gt;许可协议:\u0026lt;/span\u0026gt;\u0026lt;i class=\u0026#34;fa fa-creative-commons\u0026#34;\u0026gt;\u0026lt;/i\u0026gt; \u0026lt;a rel=\u0026#34;license\u0026#34; href=\u0026#34;https://creativecommons.org/licenses/by-nc-nd/4.0/\u0026#34; target=\u0026#34;_blank\u0026#34; title=\u0026#34;Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)\u0026#34;\u0026gt;署名-非商业性使用-禁止演绎 4.0 国际\u0026lt;/a\u0026gt; 转载请保留原文链接及作者。\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; var clipboard = new Clipboard(\u0026#39;.fa-clipboard\u0026#39;); clipboard.on(\u0026#39;success\u0026#39;, $(function(){ $(\u0026#34;.fa-clipboard\u0026#34;).click(function(){ swal({ title: \u0026#34;\u0026#34;, text: \u0026#39;复制成功\u0026#39;, html: false, timer: 500, showConfirmButton: false }); }); })); \u0026lt;/script\u0026gt; {% endif %} 在目录 themes/next/source/css/_common/components/post/ 下添加 my-post-copyright.styl,内容如下:\n.my\\_post\\_copyright { width: 85%; max-width: 45em; margin: 2.8em auto 0; padding: 0.5em 1.0em; border: 1px solid #d3d3d3; font-size: 0.93rem; line-height: 1.6em; word-break: break-all; background: rgba(255,255,255,0.4); } .my\\_post\\_copyright p{margin:0;} .my\\_post\\_copyright span { display: inline-block; width: 5.2em; color: #333333; // title color font-weight: bold; } .my\\_post\\_copyright .raw { margin-left: 1em; width: 5em; } .my\\_post\\_copyright a { color: #808080; border-bottom:0; } .my\\_post\\_copyright a:hover { color: #0593d3; // link color text-decoration: underline; } .my\\_post\\_copyright:hover .fa-clipboard { color: #000; } .my\\_post\\_copyright .post-url:hover { font-weight: normal; } .my\\_post\\_copyright .copy-path { margin-left: 1em; width: 1em; +mobile(){display:none;} } .my\\_post\\_copyright .copy-path:hover { color: #808080; cursor: pointer; } 修改 themes/next/layout/_macro/post.swig ,在代码如下：\n{% if theme.wechat\\_subscriber.enabled and not is\\_index %} \u0026lt;div\u0026gt; {% include \u0026#39;wechat-subscriber.swig\u0026#39; %} \u0026lt;/div\u0026gt; {% endif %} 之前添加增加如下代码：\n\u0026lt;div\u0026gt; {% if not is_index %} {% include \u0026#39;my-copyright.swig\u0026#39; %} {% endif %} \u0026lt;/div\u0026gt; 修改 themes/next/source/css/_common/components/post/post.styl 文件，在最后一行增加代码：\n@import \u0026#34;my-post-copyright\u0026#34; 设置新建文章自动开启 copyright,即新建文章自动显示自定义的版权声明,设置 your site/scaffolds/post.md文件\n--- title: {{ title }} date: {{ date }} tags: type: \u0026#34;categories\u0026#34; categories: copyright: true #新增,开启 --- ","permalink":"https://blog.lvcshu.com/2018/07/20/%E5%AE%89%E8%A3%85hexo%E5%8D%9A%E5%AE%A2%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96%E8%AE%B0%E5%BD%95/","summary":"使用lnmp.org的lnmp安装一键包，按程序安装好即可，并顺手创建一个虚拟主机，不需要重写，不需要数据库。\n 本文采用 lvcshu.com 为示例域名\n 安装 HEXO 按照官网说明的方法一步步安装\n安装 node.js curl:\ncurl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash 或\nwget:\nwget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash 然后重启终端或者ssh重新连接\nnvm install stable 安装 hexo-cil npm install -g hexo-cli 随后就会很快安装完成！\n部署博客  安装Hexo后，运行以下命令以初始化目标中的Hexo 。\n 此处的 folder 就是我们博客的主目录，即 lnmp 虚拟主机的目录，进入目录以后执行\nhexo init . npm install hexo g 此时我们博客的静态页面已经成功生成了，但是访问页面是没有办法看到的，接着下一步\n调整 nginx 配置文件 打开 nginx 相应站点 的配置文件，找到\nroot /home/wwwroot/lvcshu.com; 改为\nroot /home/wwwroot/blog.lvcshu.com/public; 记住：有两个地方要改，对应http与https\n推荐：可以将 http 通过301跳转，跳转到 https","title":"安装hexo博客及其优化记录"},{"content":"自从360云盘把业务收缩回企业用户之时，笔者就在不断的寻觅适合个人用户使用的私有云盘，但是纵观网络的各种各样的云盘，不是过于简单，就是部署过于复杂，还有就是会出现各种各样奇奇怪怪的问题（比如nextcloud），\n所以在不断的尝试中，终于发现了一个比较符合使用习惯的云盘程序 —\u0026gt; cloudreve\n助您以最低的成本快速搭建公私兼备的网盘系统\n安装 　由于官网已经有了比较详细的安装教程，在此不再赘述，无非是：安装lnmp环境、创建虚拟主机、获取程序、编辑数据库连接信息、把 fileinfo 的 php 扩展加载进去、修改 nginx 设置。\n使用 　进入页迎面而来是一个漂亮的首页，点击登录使用默认账户登录，经过一番体验，将优缺点一一总结如下\n优点  多用户支持（可以和好基友家里人互不干扰的使用一套云盘） 完善的分享功能（提供公开分享与私密分享，界面简洁） 一键提取文件外链（wget 神器） 自定义文件上传策略（保障服务器安全） 支持与 aria2 离线下载对接 安装简便 webdav 支持 ………  缺点 不支持扫描本地文件（文件上传只能通过网页端，大概是要用数据库管理）\n总评 cloudreve 已经是一款相当成熟的云盘程序，是继 owncloud、nextcloud以后的私有云盘的不二选择\n","permalink":"https://blog.lvcshu.com/2018/05/09/cloudreve%E4%BD%93%E9%AA%8C%E6%8A%A5%E5%91%8A/","summary":"\u003cp\u003e自从360云盘把业务收缩回企业用户之时，笔者就在不断的寻觅适合个人用户使用的私有云盘，但是纵观网络的各种各样的云盘，不是过于简单，就是部署过于复杂，还有就是会出现各种各样奇奇怪怪的问题（比如nextcloud），\u003c/p\u003e","title":"cloudreve体验报告"},{"content":" 什么是https？ 现在，请看到你的浏览器的网址栏，你会看到会有一个绿色的锁或者类似的安全标志，这说明我的博客加上了https保障数据传送的安全性~  那么，什么是https呢？\n HTTPS（全称：Hyper Text Transfer Protocol over Secure Socket Layer），是以安全为目标的HTTP通道，简单讲是HTTP的安全版。 来自百度百科\n 简单的来说https就是保障了这个网站的呈现给你的内容没有被擅改\n一个小故事 但是，https并不是绝对安全的，我在知乎上看到了这样一个故事：(斜体为笔者注释)\n从前山上有座庙，庙里有个和尚……，别胡闹了，老和尚来了。\n小和尚问老和尚：ssl为什么会让http安全？\n老和尚答道：譬如你我都有一个同样的密码，我发信给你时用这个密码加密，你收到我发的信，用这个密码解密，就能知道我信的内容，其他的闲杂人等，就算偷偷拿到了信，由于不知道这个密码，也只能望信兴叹，这个密码就叫做对称密码。ssl使用对称密码对http内容进行加解密，所以让http安全了，常用的加解密算法主要有3DES和AES等。\n小和尚摸摸脑袋问老和尚：师傅，如果我们两人选择“和尚”作为密码，再创造一个和尚算法，我们俩之间的通信不就高枕无忧了？\n老和尚当头给了小和尚一戒尺：那我要给山下的小花写情书，还得用“和尚”这个密码不成？想了想又给了小和尚一戒尺：虽然我们是和尚，不是码农，也不能自己造轮子，当初一堆牛人码农造出了Wifi的安全算法WEP，后来发现是一绣花枕头，在安全界传为笑谈；况且小花只知道3DES和AES，哪知道和尚算法？\n小和尚问到：那师傅何解？\n老和尚：我和小花只要知道每封信的密码，就可以读到对方加密的信件，关键是我们互相之间怎么知道这个对称密码。你说，我要是将密码写封信给她，信被别人偷了，那大家不都知道我们的密码了，也就能够读懂我们情书了。不过还是有解的，这里我用到了江湖中秘传的非对称密码。我现在手头有两个密码，一个叫“公钥”，一个叫“私钥”，公钥发布到了江湖上，好多人都知道，私钥嘛，江湖上只有我一个人知道；这两个密钥有数学相关性，就是说用公钥加密的信件，可以用私钥解开，但是用公钥却解不开。公钥小花是知道的，她每次给我写信，都要我的公钥加密她的对称密码，单独写一张密码纸，然后用她的对称密码加密她的信件，这样我用我的私钥可以解出这个对称密码，再用这个对称密码来解密她的信件。\n这种加密方法即自己生成自签证书，这种做法是不完全安全的，具体表现为Chrome地址栏划掉的红色https\n老和尚顿了顿：可惜她用的对称密码老是“和尚为什么写情书”这一类，所以我每次解开密码纸时总是怅然若失，其实我钟意的对称密码是诸如“风花”“雪月”什么的，最头痛的是，我还不得不用“和尚为什么写情书”这个密码来加密我给小花回的情书，人世间最痛苦的事莫过于如此。可我哪里知道，其实有人比我更痛苦。山下的张屠夫，暗恋小花很多年，看着我们鸿雁传书，心中很不是滋味，主动毛遂自荐代替香客给我们送信。在他第一次给小花送信时，就给了小花他自己的公钥，谎称是我公钥刚刚更新了，小花信以为真，之后的信件对称密码都用张屠夫的这个公钥加密了，张屠夫拿到回信后，用他自己的私钥解开了小花的对称密码，然后用这个对称密码，不仅能够看到了小花信件的所有内容，还能使用这个密码伪造小花给我写信，同时还能用他的私钥加密给小花的信件。渐渐我发现信件变味了，尽管心生疑惑，但是没有确切的证据，一次我写信问小花第一次使用的对称密码，回信中“和尚为什么写情书”赫然在列，于是我的疑惑稍稍减轻。直到有一次去拜会嵩山少林寺老方丈才顿悟，原来由于我的公钥没有火印，任何人都可以伪造一份公钥宣称是我的，这样这个人即能读到别人写给我的信，也能伪造别人给我写信，同样也能读到我的回信，也能伪造我给别人的回信，这种邪门武功江湖上称之“Man-in-the-middle attack”（即中间人攻击）。唯一的破解就是使用嵩山少林寺的火印（即由CA机构颁发的证书），这个火印可有讲究了，需要将我的公钥及个人在江湖地位提交给18罗汉委员会，他们会根据我的这些信息使用委员会私钥进行数字签名，签名的信息凸现在火印上，有火印的公钥真实性在江湖上无人质疑，要知道18罗汉可是无人敢得罪的。\n小和尚问：那然后呢？\n老和尚：从嵩山少林寺回山上寺庙时，我将有火印的公钥亲自给小花送去，可是之后再也没有收到小花的来信。过了一年才知道，其实小花还是给我写过信的，当时信确实是用有火印的公钥加密，张屠夫拿到信后，由于不知道我的私钥，解不开小花的密码信，所以一怒之下将信件全部烧毁了。也由于张屠夫无法知道小花的对称密码而无法回信，小花发出几封信后石沉大海，也心生疑惑，到处打听我的近况。这下张屠夫急了，他使用我发布的公钥，仿照小花的语气，给我发来一封信。拿到信时我就觉得奇怪，信纸上怎么有一股猪油的味道，结尾竟然还关切的询问我的私钥。情知有诈，我思量无论如何要找到办法让我知道来的信是否真是小花所写。后来竟然让我想到了办法….\n老和尚摸着光头说：这头发可不是白掉的，我托香客给小花带话，我一切安好，希望她也拥有属于自己的一段幸福，不对，是一对非对称密钥。小花委托小镇美女协会给小花公钥打上火印后，托香客给我送来，这样小花在每次给我写信时，都会在密码纸上贴上一朵小牡丹，牡丹上写上用她自己的私钥加密过的给我的留言，这样我收到自称是小花的信后，我会先抽出密码纸，取下小牡丹，使用小花的公钥解密这段留言，如果解不出来，我会直接将整封信连同密码纸一起扔掉，因为这封信一定不是小花写的，如果能够解出来，这封信才能确信来之于小花，我才仔细的解码阅读。\n小和尚：难怪听说张屠夫是被活活气死的。您这情书整的，我头都大了，我长大后，有想法直接扯着嗓子对山下喊，也省的这么些麻烦。不过我倒是明白了楼上的话，ssl 握手阶段，就是要解决什么看火印，读牡丹，解密码纸，确实够麻烦的，所以性能瓶颈在这里，一旦双方都知道了对称密码，之后就是行云流水的解码读信阶段了，相对轻松很多。\n编辑于 2014-04-28\n著作权归作者所有\n 来源:【HTTPS 要比 HTTP 多用多少服务器资源？】牟旭东的回答\n 但是 并不是所有的CA机构所颁发的证书都是值得信任的，例如：\n 违反多项凭证机构要求，Chrome 全面取消对中国沃通的 SSL 证书信任\n  2016 年 9 月 Mozilla 揭发中国凭证机构 WoSign（沃通）伪造证书发行日期、隐瞒收购同行等问题，宣布暂停信任该机构发出的证书，苹果、Google 也跟随。近日 Google 宣布，旗下的 Chrome 浏览器在 9 月发布新版本后，将对 WoSign 及其收购的 StartCom 签发所有证书，不论新旧全部取消信任，建议正在使用的网站考虑更换这些数位证书。\n ","permalink":"https://blog.lvcshu.com/2018/02/11/%E8%BF%98%E4%B8%8D%E7%BB%99%E4%BD%A0%E7%9A%84%E7%BD%91%E7%AB%99%E5%8A%A0%E4%B8%8Ahttps/","summary":"什么是https？ 现在，请看到你的浏览器的网址栏，你会看到会有一个绿色的锁或者类似的安全标志，这说明我的博客加上了https保障数据传送的安全性~  那么，什么是https呢？\n HTTPS（全称：Hyper Text Transfer Protocol over Secure Socket Layer），是以安全为目标的HTTP通道，简单讲是HTTP的安全版。 来自百度百科\n 简单的来说https就是保障了这个网站的呈现给你的内容没有被擅改\n一个小故事 但是，https并不是绝对安全的，我在知乎上看到了这样一个故事：(斜体为笔者注释)\n从前山上有座庙，庙里有个和尚……，别胡闹了，老和尚来了。\n小和尚问老和尚：ssl为什么会让http安全？\n老和尚答道：譬如你我都有一个同样的密码，我发信给你时用这个密码加密，你收到我发的信，用这个密码解密，就能知道我信的内容，其他的闲杂人等，就算偷偷拿到了信，由于不知道这个密码，也只能望信兴叹，这个密码就叫做对称密码。ssl使用对称密码对http内容进行加解密，所以让http安全了，常用的加解密算法主要有3DES和AES等。\n小和尚摸摸脑袋问老和尚：师傅，如果我们两人选择“和尚”作为密码，再创造一个和尚算法，我们俩之间的通信不就高枕无忧了？\n老和尚当头给了小和尚一戒尺：那我要给山下的小花写情书，还得用“和尚”这个密码不成？想了想又给了小和尚一戒尺：虽然我们是和尚，不是码农，也不能自己造轮子，当初一堆牛人码农造出了Wifi的安全算法WEP，后来发现是一绣花枕头，在安全界传为笑谈；况且小花只知道3DES和AES，哪知道和尚算法？\n小和尚问到：那师傅何解？\n老和尚：我和小花只要知道每封信的密码，就可以读到对方加密的信件，关键是我们互相之间怎么知道这个对称密码。你说，我要是将密码写封信给她，信被别人偷了，那大家不都知道我们的密码了，也就能够读懂我们情书了。不过还是有解的，这里我用到了江湖中秘传的非对称密码。我现在手头有两个密码，一个叫“公钥”，一个叫“私钥”，公钥发布到了江湖上，好多人都知道，私钥嘛，江湖上只有我一个人知道；这两个密钥有数学相关性，就是说用公钥加密的信件，可以用私钥解开，但是用公钥却解不开。公钥小花是知道的，她每次给我写信，都要我的公钥加密她的对称密码，单独写一张密码纸，然后用她的对称密码加密她的信件，这样我用我的私钥可以解出这个对称密码，再用这个对称密码来解密她的信件。\n这种加密方法即自己生成自签证书，这种做法是不完全安全的，具体表现为Chrome地址栏划掉的红色https\n老和尚顿了顿：可惜她用的对称密码老是“和尚为什么写情书”这一类，所以我每次解开密码纸时总是怅然若失，其实我钟意的对称密码是诸如“风花”“雪月”什么的，最头痛的是，我还不得不用“和尚为什么写情书”这个密码来加密我给小花回的情书，人世间最痛苦的事莫过于如此。可我哪里知道，其实有人比我更痛苦。山下的张屠夫，暗恋小花很多年，看着我们鸿雁传书，心中很不是滋味，主动毛遂自荐代替香客给我们送信。在他第一次给小花送信时，就给了小花他自己的公钥，谎称是我公钥刚刚更新了，小花信以为真，之后的信件对称密码都用张屠夫的这个公钥加密了，张屠夫拿到回信后，用他自己的私钥解开了小花的对称密码，然后用这个对称密码，不仅能够看到了小花信件的所有内容，还能使用这个密码伪造小花给我写信，同时还能用他的私钥加密给小花的信件。渐渐我发现信件变味了，尽管心生疑惑，但是没有确切的证据，一次我写信问小花第一次使用的对称密码，回信中“和尚为什么写情书”赫然在列，于是我的疑惑稍稍减轻。直到有一次去拜会嵩山少林寺老方丈才顿悟，原来由于我的公钥没有火印，任何人都可以伪造一份公钥宣称是我的，这样这个人即能读到别人写给我的信，也能伪造别人给我写信，同样也能读到我的回信，也能伪造我给别人的回信，这种邪门武功江湖上称之“Man-in-the-middle attack”（即中间人攻击）。唯一的破解就是使用嵩山少林寺的火印（即由CA机构颁发的证书），这个火印可有讲究了，需要将我的公钥及个人在江湖地位提交给18罗汉委员会，他们会根据我的这些信息使用委员会私钥进行数字签名，签名的信息凸现在火印上，有火印的公钥真实性在江湖上无人质疑，要知道18罗汉可是无人敢得罪的。\n小和尚问：那然后呢？\n老和尚：从嵩山少林寺回山上寺庙时，我将有火印的公钥亲自给小花送去，可是之后再也没有收到小花的来信。过了一年才知道，其实小花还是给我写过信的，当时信确实是用有火印的公钥加密，张屠夫拿到信后，由于不知道我的私钥，解不开小花的密码信，所以一怒之下将信件全部烧毁了。也由于张屠夫无法知道小花的对称密码而无法回信，小花发出几封信后石沉大海，也心生疑惑，到处打听我的近况。这下张屠夫急了，他使用我发布的公钥，仿照小花的语气，给我发来一封信。拿到信时我就觉得奇怪，信纸上怎么有一股猪油的味道，结尾竟然还关切的询问我的私钥。情知有诈，我思量无论如何要找到办法让我知道来的信是否真是小花所写。后来竟然让我想到了办法….\n老和尚摸着光头说：这头发可不是白掉的，我托香客给小花带话，我一切安好，希望她也拥有属于自己的一段幸福，不对，是一对非对称密钥。小花委托小镇美女协会给小花公钥打上火印后，托香客给我送来，这样小花在每次给我写信时，都会在密码纸上贴上一朵小牡丹，牡丹上写上用她自己的私钥加密过的给我的留言，这样我收到自称是小花的信后，我会先抽出密码纸，取下小牡丹，使用小花的公钥解密这段留言，如果解不出来，我会直接将整封信连同密码纸一起扔掉，因为这封信一定不是小花写的，如果能够解出来，这封信才能确信来之于小花，我才仔细的解码阅读。\n小和尚：难怪听说张屠夫是被活活气死的。您这情书整的，我头都大了，我长大后，有想法直接扯着嗓子对山下喊，也省的这么些麻烦。不过我倒是明白了楼上的话，ssl 握手阶段，就是要解决什么看火印，读牡丹，解密码纸，确实够麻烦的，所以性能瓶颈在这里，一旦双方都知道了对称密码，之后就是行云流水的解码读信阶段了，相对轻松很多。\n编辑于 2014-04-28\n著作权归作者所有\n 来源:【HTTPS 要比 HTTP 多用多少服务器资源？】牟旭东的回答\n 但是 并不是所有的CA机构所颁发的证书都是值得信任的，例如：\n 违反多项凭证机构要求，Chrome 全面取消对中国沃通的 SSL 证书信任\n  2016 年 9 月 Mozilla 揭发中国凭证机构 WoSign（沃通）伪造证书发行日期、隐瞒收购同行等问题，宣布暂停信任该机构发出的证书，苹果、Google 也跟随。近日 Google 宣布，旗下的 Chrome 浏览器在 9 月发布新版本后，将对 WoSign 及其收购的 StartCom 签发所有证书，不论新旧全部取消信任，建议正在使用的网站考虑更换这些数位证书。","title":"还不给你的网站加上https？"},{"content":"很久以来许许多多人催促着我赶快配置好防火墙规则以保护vps，但是。。。配置繁琐的iptables使我望而却步~~（其实就是懒~~\n直到我发现了ufw这个神器\n UFW 全称为 UncomplicatedFirewall[1]，是 Ubuntu 系统上默认的防火墙组件, 为了轻量化配置 iptables 而开发的一款工具。UFW 提供一个非常友好的界面用于创建基于IPV4，IPV6的防火墙规则。\n 废话不多说，上教程\n环境 Ubuntu 16.04\n安装 apt install ufw 配置 首先先打开ssh端口\nufw allow ssh 如果你的ssh端口不是默认的22，就\nufw allow 你的ssh端口 打开53端口，使dns功能不受影响\nufw allow 53/tcp ufw allow 53/udp 可选：打开80，443端口\nufw allow http/tcp ufw allow https/tcp 然后\nufw default deny 阻断除上述规则外的外部连接（本机外发流量无影响）\nufw enable 启动防火墙，done！\n操作指令 启动防火墙 ufw enable 关闭防火墙 ufw disable 更新配置 ufw reload 查看防火墙状态 ufw status ","permalink":"https://blog.lvcshu.com/2018/01/15/%E9%85%8D%E7%BD%AEufw%E9%98%B2%E7%81%AB%E5%A2%99%E5%AE%88%E6%8A%A4%E4%BD%A0%E7%9A%84ubuntu/","summary":"很久以来许许多多人催促着我赶快配置好防火墙规则以保护vps，但是。。。配置繁琐的iptables使我望而却步~~（其实就是懒~~\n直到我发现了ufw这个神器\n UFW 全称为 UncomplicatedFirewall[1]，是 Ubuntu 系统上默认的防火墙组件, 为了轻量化配置 iptables 而开发的一款工具。UFW 提供一个非常友好的界面用于创建基于IPV4，IPV6的防火墙规则。\n 废话不多说，上教程\n环境 Ubuntu 16.04\n安装 apt install ufw 配置 首先先打开ssh端口\nufw allow ssh 如果你的ssh端口不是默认的22，就\nufw allow 你的ssh端口 打开53端口，使dns功能不受影响\nufw allow 53/tcp ufw allow 53/udp 可选：打开80，443端口\nufw allow http/tcp ufw allow https/tcp 然后\nufw default deny 阻断除上述规则外的外部连接（本机外发流量无影响）\nufw enable 启动防火墙，done！\n操作指令 启动防火墙 ufw enable 关闭防火墙 ufw disable 更新配置 ufw reload 查看防火墙状态 ufw status ","title":"配置ufw防火墙，守护你的Ubuntu"},{"content":" 作者小海，原文已被和谐\n 几年以前，我曾经嘲笑过某科技界大佬。当时他说：也许90后、95后会慢慢不知道谷歌是什么网站。\n那一年，这对于我来说简直就是世界上最好笑的笑话。谷歌，全世界最卓越的互联网公司，活在互联网的一代中国人，会不知道他们的网站？\n今天，我收回这句嘲笑。因为这件不可能的事，它慢慢变成了现实。\n没有人再关注什么谷歌不谷歌。对他们来说，百度也蛮好用的，反正他们几乎没用过谷歌。没有谷歌又怎样？大家还是开心的刷微博，看微信，听歌，看娱乐节目。对于从来就不知道谷歌的人来说，少了谷歌又有什么影响？\n慢慢的，就没有了，就像从未存在过\n多年前，我们也是可以登陆Facebook的。其实这个网站和校内一样，也挺蠢的。可在上面你能看到老外们的生活，可以轻易的跟一万公里以外的人互相拜访，可以看到很多根本不会开到校内上的主页。你用汉语回复，下面给你聊起来的可能是香港仔，可能是台湾人。你用英语回复，说不定有比你英语用的更蹩脚的寂寞的北欧人来跟你搭讪。你感觉地球真的变成了地球村，你还没拉门走出去，别人就推门走了进来。\n然后，它就没有了。起初，它的失踪激起了很大的声音，后来，声音就消失了。\n多年前，我们也是可以登陆Twitter的。其实这个网站和微博一样，也不过是些信息流，刷上一整天，也不见得有什么用处。但至少，你可以以最快速度获取你想知道的任何新事，你会真正了解什么事情在全世界是流行的，而不是经过各种截图、翻译、转发，甚至曲解、断章取义、黑白颠倒的东西。你知道的是真相，赤裸裸的，也许有点太短的真相。但至少中间不会有无数人的加工与再加工，偏激、片面，就在这个过程中产生了，不管后来者有意还是无意。\n然后，它就没有了。首先是它的本体没有了，然后它的模仿者也没有了，模仿者的模仿者也没有了。只剩一个模仿者的模仿者的模仿者，现在你每天能在上面看到无数广告。\n多年前，我们也是可以登陆YouTube的。对于有的人来说，这个网站就是个大型优酷，当年有人信誓旦旦的说，没有YouTube，我们中国人会很快让优酷超过YouTube。可这么多年过去了，视频还是那么卡，内容还是那么垃圾，原创还是那么容易被盗窃，视频丰富度还是那么的可怜。在YouTube上，你能看到全世界最棒的手艺人，最逗乐的笑话，最天马行空的创意，最激荡人心的音乐，最美好的完美瞬间，可在优酷上，你想看一分钟视频，请先看半分钟广告。\n哦，对了。Instagram，有些人可能感觉它和QQ空间也差不多。可我在上面关注了六百多个摄影师，它们都是顶好顶好的影像记录者，每天看他们的作品，我感觉到很幸福，那种即使没有到那里去，也身临其境的幸福。我还在上面认识了一个日本的爱自拍的帅小伙，一个爱喝酒的韩国大叔，一个十年前到过中国今天会在每张我发的紫禁城照片下点赞的美国大爷，一个美丽无比的俄罗斯妹子，我和他们基本上都难以交流，语言是很大的障碍，但几个简单的单词，心意也就到了，这种感觉，有时候比多年老友相聚还兴奋。因为这是人类不同族群自由交流互相沟通的过程，这种过程很神奇，真的很神奇。\n可现在，它没有了，它之所以没有就因为在某个特定的时间你在搜索特定的词汇时，会搜出来特定的照片。虽然这么搜的人并不多，虽然看到的人也不会大惊小怪，也不会觉得天黑了，天亮了，天要塌了，天要变了。可它就是没了，Instagram，就这么没了。谷歌也是这么没的，Twitter也是这么没的，Facebook也是这么没的。不知道是什么人，在什么场合，说了什么话，下了什么决定。就要有超过十亿人像陷于哥谭市的孤岛里一样，看着一座又一座桥梁被炸掉，又被炸掉，又被炸掉，然后，就什么都没了。\n我时常觉得悲哀，真的好悲哀，一个我根本不认识也不知道是谁的人，也许是一个群体，在不断抢走我身边的东西，而我却无能为力。我抱怨一声，他听不到，任何人都听不到。我怒吼一句，身边的大多数人却像看疯子一样的看着我。我哀嚎一声，这声音被阻碍在黑黑的幕墙以里。我发出尖锐的嘶吼，这声音传不了多远，就和我那被抢走的东西一样，消失了，不见了，就像从来没存在过一样。\n对于本来就没存在过的东西，有谁又会觉得在意呢？那些本来拥有又被掠夺的人的哀愁，后来的人又怎么懂呢？我曾经是拥有一切的，我曾经是拥有世界的，我站在这片土地上，呼吸的是自由的空气，饮下的是自由的琼浆玉液。就在长的无法计数的时间里，我自由生命的一部分又一部分就这么被杀死了，突然就杀死了。可我还始终觉得，它们还奄奄一息的活着，就像它们是慢慢的死去的一样。\n可它们终归是死了，而且随着它们的死，愈来愈多的事情慢慢的发生了，很慢很慢，几乎不被人察觉，可还是发生了。\n没有谷歌，我可以用百度呀。可某些结果被越挪越后，越挪越后，最后就不见了。就像本来就不该搜出这个结果一样。\n没有Facebook，我可以用校内呀。可你想发只有在Facebook上能发的文章，很快在校内上就失踪了。接着，校内变成了人人，话题变成了人人都关心的话题。大家都在抢着看星座、明星、八卦、娱乐。没有人会关心什么消失了，反正它们本来也没多少存在感。\n没有YouTube，我可以用优酷呀。可你却经常只能在优酷上看到抄袭别人的作品，而且还不署名，而且还洋洋得意，而且还自我陶醉，就好像那个idea本来属于他自己一样。你看了还要惊呼，他是如此的有创意！好一个抄袭的创意，可你却不知道，因为你不知道这个世界上有个网站叫YouTube。\n没有Twitter，我还可以用微博呀。可你想知道最近发生了什么，你搜的越勤快，越能看到越明显的??“根据相关法律法规，相关搜索结果不予显示??”。时间长了，你想，反正知道了也没什么用，不如不看了。\n慢慢的，一扇又一扇的门关上了。今天你打开世界上最大的博客网站，发现它没了。明天你一看，世界上最好的设计师分享网站没了，一开始是刷新的很慢很慢，后来它就没了。过两天再一看，平常每天都会读两篇文章的媒体网站没了，那里的文章缤纷多彩，最后都变成了该页无法显示几个字。再过几个月，大学的网站不让上了，摄影师的网站不让上了，就连百度日本这种自家网站，也没了。\n接着，漫画看不了了，接着，动画看不成了。接着，美剧英剧失踪了。下载美剧英剧的网站又又又又又失踪了。尊重正版，保护权益，行吧，然后字幕网站也没了。\n游戏没了，你习惯性登陆的游戏网站，发现下载栏正在整治中。论坛关了，天天都在看的论坛，突然接到相关部门的电话，因为??“报备问题??”不让办了。个人网站，私人博客，对不起，说没就没有，你在上面存了多少多年辛勤耕耘的东西都没用。\n你关注的人，有一天你登陆微博，发现他怎么好久都没说话了，然后你搜索了一下，发现他的账号不存在了，而且你搜他的名字，他的名字未予显示。\n一盏一盏的灯，灭了。四面八方的光源，消失了。我们生活的五光十色的世界，变成了一片黑色。\n天黑了，那么睡觉吧，但愿长醉不复醒，卧槽泥马勒戈壁。\n最后，我们变成了一群做梦的人，这个梦的名字，叫根据相关法律法规，相关搜索结果不予显示梦。\n","permalink":"https://blog.lvcshu.com/2017/12/21/%E6%85%A2%E6%85%A2%E7%9A%84%E5%B0%B1%E6%B2%A1%E6%9C%89%E4%BA%86%E5%B0%B1%E5%83%8F%E4%BB%8E%E6%9C%AA%E5%AD%98%E5%9C%A8%E8%BF%87/","summary":"作者小海，原文已被和谐\n 几年以前，我曾经嘲笑过某科技界大佬。当时他说：也许90后、95后会慢慢不知道谷歌是什么网站。\n那一年，这对于我来说简直就是世界上最好笑的笑话。谷歌，全世界最卓越的互联网公司，活在互联网的一代中国人，会不知道他们的网站？\n今天，我收回这句嘲笑。因为这件不可能的事，它慢慢变成了现实。\n没有人再关注什么谷歌不谷歌。对他们来说，百度也蛮好用的，反正他们几乎没用过谷歌。没有谷歌又怎样？大家还是开心的刷微博，看微信，听歌，看娱乐节目。对于从来就不知道谷歌的人来说，少了谷歌又有什么影响？\n慢慢的，就没有了，就像从未存在过\n多年前，我们也是可以登陆Facebook的。其实这个网站和校内一样，也挺蠢的。可在上面你能看到老外们的生活，可以轻易的跟一万公里以外的人互相拜访，可以看到很多根本不会开到校内上的主页。你用汉语回复，下面给你聊起来的可能是香港仔，可能是台湾人。你用英语回复，说不定有比你英语用的更蹩脚的寂寞的北欧人来跟你搭讪。你感觉地球真的变成了地球村，你还没拉门走出去，别人就推门走了进来。\n然后，它就没有了。起初，它的失踪激起了很大的声音，后来，声音就消失了。\n多年前，我们也是可以登陆Twitter的。其实这个网站和微博一样，也不过是些信息流，刷上一整天，也不见得有什么用处。但至少，你可以以最快速度获取你想知道的任何新事，你会真正了解什么事情在全世界是流行的，而不是经过各种截图、翻译、转发，甚至曲解、断章取义、黑白颠倒的东西。你知道的是真相，赤裸裸的，也许有点太短的真相。但至少中间不会有无数人的加工与再加工，偏激、片面，就在这个过程中产生了，不管后来者有意还是无意。\n然后，它就没有了。首先是它的本体没有了，然后它的模仿者也没有了，模仿者的模仿者也没有了。只剩一个模仿者的模仿者的模仿者，现在你每天能在上面看到无数广告。\n多年前，我们也是可以登陆YouTube的。对于有的人来说，这个网站就是个大型优酷，当年有人信誓旦旦的说，没有YouTube，我们中国人会很快让优酷超过YouTube。可这么多年过去了，视频还是那么卡，内容还是那么垃圾，原创还是那么容易被盗窃，视频丰富度还是那么的可怜。在YouTube上，你能看到全世界最棒的手艺人，最逗乐的笑话，最天马行空的创意，最激荡人心的音乐，最美好的完美瞬间，可在优酷上，你想看一分钟视频，请先看半分钟广告。\n哦，对了。Instagram，有些人可能感觉它和QQ空间也差不多。可我在上面关注了六百多个摄影师，它们都是顶好顶好的影像记录者，每天看他们的作品，我感觉到很幸福，那种即使没有到那里去，也身临其境的幸福。我还在上面认识了一个日本的爱自拍的帅小伙，一个爱喝酒的韩国大叔，一个十年前到过中国今天会在每张我发的紫禁城照片下点赞的美国大爷，一个美丽无比的俄罗斯妹子，我和他们基本上都难以交流，语言是很大的障碍，但几个简单的单词，心意也就到了，这种感觉，有时候比多年老友相聚还兴奋。因为这是人类不同族群自由交流互相沟通的过程，这种过程很神奇，真的很神奇。\n可现在，它没有了，它之所以没有就因为在某个特定的时间你在搜索特定的词汇时，会搜出来特定的照片。虽然这么搜的人并不多，虽然看到的人也不会大惊小怪，也不会觉得天黑了，天亮了，天要塌了，天要变了。可它就是没了，Instagram，就这么没了。谷歌也是这么没的，Twitter也是这么没的，Facebook也是这么没的。不知道是什么人，在什么场合，说了什么话，下了什么决定。就要有超过十亿人像陷于哥谭市的孤岛里一样，看着一座又一座桥梁被炸掉，又被炸掉，又被炸掉，然后，就什么都没了。\n我时常觉得悲哀，真的好悲哀，一个我根本不认识也不知道是谁的人，也许是一个群体，在不断抢走我身边的东西，而我却无能为力。我抱怨一声，他听不到，任何人都听不到。我怒吼一句，身边的大多数人却像看疯子一样的看着我。我哀嚎一声，这声音被阻碍在黑黑的幕墙以里。我发出尖锐的嘶吼，这声音传不了多远，就和我那被抢走的东西一样，消失了，不见了，就像从来没存在过一样。\n对于本来就没存在过的东西，有谁又会觉得在意呢？那些本来拥有又被掠夺的人的哀愁，后来的人又怎么懂呢？我曾经是拥有一切的，我曾经是拥有世界的，我站在这片土地上，呼吸的是自由的空气，饮下的是自由的琼浆玉液。就在长的无法计数的时间里，我自由生命的一部分又一部分就这么被杀死了，突然就杀死了。可我还始终觉得，它们还奄奄一息的活着，就像它们是慢慢的死去的一样。\n可它们终归是死了，而且随着它们的死，愈来愈多的事情慢慢的发生了，很慢很慢，几乎不被人察觉，可还是发生了。\n没有谷歌，我可以用百度呀。可某些结果被越挪越后，越挪越后，最后就不见了。就像本来就不该搜出这个结果一样。\n没有Facebook，我可以用校内呀。可你想发只有在Facebook上能发的文章，很快在校内上就失踪了。接着，校内变成了人人，话题变成了人人都关心的话题。大家都在抢着看星座、明星、八卦、娱乐。没有人会关心什么消失了，反正它们本来也没多少存在感。\n没有YouTube，我可以用优酷呀。可你却经常只能在优酷上看到抄袭别人的作品，而且还不署名，而且还洋洋得意，而且还自我陶醉，就好像那个idea本来属于他自己一样。你看了还要惊呼，他是如此的有创意！好一个抄袭的创意，可你却不知道，因为你不知道这个世界上有个网站叫YouTube。\n没有Twitter，我还可以用微博呀。可你想知道最近发生了什么，你搜的越勤快，越能看到越明显的??“根据相关法律法规，相关搜索结果不予显示??”。时间长了，你想，反正知道了也没什么用，不如不看了。\n慢慢的，一扇又一扇的门关上了。今天你打开世界上最大的博客网站，发现它没了。明天你一看，世界上最好的设计师分享网站没了，一开始是刷新的很慢很慢，后来它就没了。过两天再一看，平常每天都会读两篇文章的媒体网站没了，那里的文章缤纷多彩，最后都变成了该页无法显示几个字。再过几个月，大学的网站不让上了，摄影师的网站不让上了，就连百度日本这种自家网站，也没了。\n接着，漫画看不了了，接着，动画看不成了。接着，美剧英剧失踪了。下载美剧英剧的网站又又又又又失踪了。尊重正版，保护权益，行吧，然后字幕网站也没了。\n游戏没了，你习惯性登陆的游戏网站，发现下载栏正在整治中。论坛关了，天天都在看的论坛，突然接到相关部门的电话，因为??“报备问题??”不让办了。个人网站，私人博客，对不起，说没就没有，你在上面存了多少多年辛勤耕耘的东西都没用。\n你关注的人，有一天你登陆微博，发现他怎么好久都没说话了，然后你搜索了一下，发现他的账号不存在了，而且你搜他的名字，他的名字未予显示。\n一盏一盏的灯，灭了。四面八方的光源，消失了。我们生活的五光十色的世界，变成了一片黑色。\n天黑了，那么睡觉吧，但愿长醉不复醒，卧槽泥马勒戈壁。\n最后，我们变成了一群做梦的人，这个梦的名字，叫根据相关法律法规，相关搜索结果不予显示梦。","title":"慢慢的，就没有了，就像从未存在过"},{"content":"","permalink":"https://blog.lvcshu.com/archives/","summary":"archives","title":"Archive"},{"content":" 会点前端 会点后端 喜欢折腾 全不精通\n 编程语言  Go Python C Java PHP Javascript ejs? HTML Vue  项目    名称 描述 标签     Neshouse 一个 clubhouse 的开源实现 #Javascript #Alpine.js #Bulma Css NES.css #Leancloud #Agora   lottery_bot 抽奖 Bot,如果没有记错的话，这是 TG 中文圈第一台抽奖 Bot 呢，嘻嘻 #Python #pyTelegramBotApi   @xiaojin_bot 津津乐道播客听友 Telegram 群机器人，目前还活着并且一直在维护 #Python #pyTelegramBotApi   go-pmbot 用 Go 语言写的 PM Bot 算是跟风 #Golang   tele-uptime-bot 监控服务器在线 Bot ，主要靠 ping #Golang   hexo-theme-XvA 一套 Hexo 主题，就是现在在用的这个 #Javascript #Ejs   ControlCenter 服务器综合管理面板 #Golang #Gorm #Echo   ControlCenter-web 服务器综合管理面板前端 #Vue #Element-ui   RssReader Vue 前端 Go 后端的 Rss 在线阅读器 #Vue #Bootstrap-vue #Golang #Echo #Gorm   CEIC-TG 地震预警推送到 telegram #Python #pyTelegramBotApi   Weather-Card 基于 ESP8266 的桌面天气时钟摆件 #Arduino #C++   DNMP-lvcshu 使用 docker-compose 组织安装 LNMP 环境 #PHP #Shell   start-vps-shell 梦开始的地方 #Shell    联系    平台 联系方式     GitHub johnpoint   Wikipedia johnpoint   Telegram @johnpoint   Mail me@lvcshu.com    SSH 公钥 ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIMMkcVBtYdqmP7DsDmfwsIZquum6YWp67bGdr2h78Elo 授权协议 文章 本博客大部分文章采用采用知识共享署名-相同方式共享 4.0 国际许可协议进行许可。\n You are free to: Share — copy and redistribute the material in any medium or format Adapt — remix, transform, and build upon the material for any purpose, even commercially.\n  Under the following terms: Attribution — You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. ShareAlike — If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original. No additional restrictions — You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.\n 协议中文版本\n图片 本站图片部分来自 Unsplash\n License All photos published on Unsplash can be used for free. You can use them for commercial and noncommercial purposes. You do not need to ask permission from or provide credit to the photographer or Unsplash, although it is appreciated when possible.\nMore precisely, Unsplash grants you an irrevocable, nonexclusive, worldwide copyright license to download, copy, modify, distribute, perform, and use photos from Unsplash for free, including for commercial purposes, without permission from or attributing the photographer or Unsplash. This license does not include the right to compile photos from Unsplash to replicate a similar or competing service.\n 关于本站  源代码 johnpoint/johnpoint.github.io 主题 hexo-theme-XvA GitHub Action Auto Build | 部署  Github Pages https://johnpoint.github.io CloudFlare Workers  https://blog.lvcshu.com https://6-d.cc https://lvcshu.com   Netlify 托管 https://lvcshu.netlify.app/|    关于友情链接 友情链接嘛，顾名思义我们先得认识，然后才能叫友情链接。\n其次，友情链接的博客 必须 要有持续的、不会太低质量的文章。\n还有，博客总得有个独立域名不过分吧 ～\n都有独立域名了，都 2020 年了上个 https 不难吧？\n最后，采集站、分享站勿扰。\n如果想跟我交换友情链接的话想办法联系我并且提供以下信息:\n博客名称、博客描述、博客链接、博客头像\n然后我就会处理你的友链请求啦～记得要先加上我的友情链接哦～\n以上原则自 commit 64c8029ebc681afff4c07d458d2ba157789efb9d 起生效\n服务提供商  IDC.WIKI VULTR Digitalocean Letbox RivenCloud GigsgigsCloud BandwagonHost namesilo Cloudflare Tencent Cloud  ","permalink":"https://blog.lvcshu.com/about/","summary":"about","title":"关于我"},{"content":"  console.log(\"test\") var all_friend = [];    all_friend.push({ \"name\": \"极光星空\", \"url\": \"https://blog.ilemonrain.com/\", \"logo\": \"https://cdn.6-d.cc/img/friends/ilemonrain.jpg\", \"desc\": \"探索星空，一路前行\", })   all_friend.push({ \"name\": \"Ovear's Blog\", \"url\": \"https://ovear.info/\", \"logo\": \"https://cdn.6-d.cc/img/friends/ovear.jpg\", \"desc\": \"=。=\", })   all_friend.push({ \"name\": \"南琴浪的博客\", \"url\": \"https://blog.sometimesnaive.org/\", \"logo\": \"https://cdn.6-d.cc/img/friends/sometimesnaive.jpeg\", \"desc\": \"已无法访问\", })   all_friend.push({ \"name\": \"Xzymoe's Blog\", \"url\": \"https://www.xzymoe.com/\", \"logo\": \"https://cdn.6-d.cc/img/friends/xzymoe.jpg\", \"desc\": \"关注互联网, 记录MOE的互联网生活.\", })   all_friend.push({ \"name\": \"奶冰の冷藏室\", \"url\": \"https://milkice.me\", \"logo\": \"https://cdn.6-d.cc/img/friends/milkice.jpg\", \"desc\": \"Maybe a way to explore the world?\", })   all_friend.push({ \"name\": \"萌爪实验室\", \"url\": \"https://www.mengclaw.com/\", \"logo\": \"https://cdn.6-d.cc/img/friends/wolfskylake.jpg\", \"desc\": \"一只雪狗狗的杂货铺\", })   all_friend.push({ \"name\": \"双草酸酯的博客\", \"url\": \"https://0x.mk/\", \"logo\": \"https://cdn.6-d.cc/img/friends/0xmk.jpg\", \"desc\": \"\", })   all_friend.push({ \"name\": \"kn007 的个人博客\", \"url\": \"https://kn007.net/\", \"logo\": \"https://cdn.6-d.cc/img/friends/kn007.jpg\", \"desc\": \"著名更新博主\", })   all_friend.push({ \"name\": \"Vigorous Pro\", \"url\": \"https://www.wevg.org\", \"logo\": \"https://cdn.6-d.cc/img/friends/Vigorous.jpg\", \"desc\": \"The world can always use more heroes.\", })   all_friend.push({ \"name\": \"Elepover's Blog\", \"url\": \"https://daily.elepover.com/\", \"logo\": \"https://cdn.6-d.cc/img/friends/elepover.svg\", \"desc\": \"Make undeniable rules to your own world.\", })   all_friend.push({ \"name\": \"派兹的小站\", \"url\": \"https://blog.blw.moe\", \"logo\": \"https://cdn.6-d.cc/img/friends/blingwang.jpg\", \"desc\": \"莓办法 银不了 尽梨了\", })   all_friend.push({ \"name\": \"Justf's Channel\", \"url\": \"https://channel.Justf.space\", \"logo\": \"https://cdn.6-d.cc/img/friends/Justf.jpg\", \"desc\": \"幸福如人饮水，冷暖自知。\", })   all_friend.push({ \"name\": \"Cyberspace of Swung\", \"url\": \"https://www.swung0x48.com\", \"logo\": \"https://cdn.6-d.cc/img/friends/Swung0x48.jpg\", \"desc\": \"Lost in cyberpunk.\", })   all_friend.push({ \"name\": \"FlyingSky's Blog\", \"url\": \"https://blog.fsky7.com\", \"logo\": \"https://cdn.6-d.cc/img/friends/FlyingSky.jpg\", \"desc\": \"每个人的裂痕，最后都会变成故事的花纹。\", })   all_friend.push({ \"name\": \"1A23 Studio\", \"url\": \"https://1a23.com\", \"logo\": \"https://cdn.6-d.cc/img/friends/1A23.jpg\", \"desc\": \"We create.\", })   all_friend.push({ \"name\": \"翰林的小站\", \"url\": \"https://blog.hanlin.press\", \"logo\": \"https://cdn.6-d.cc/img/friends/ihcr.jpg\", \"desc\": \"博览乐学，敢于探索。\", })   all_friend.push({ \"name\": \"Taoidle\", \"url\": \"https://www.taoidle.com\", \"logo\": \"https://cdn.6-d.cc/img/friends/Taoidle.jpg\", \"desc\": \"交流学习心得，分享生活乐事\", })   all_friend.push({ \"name\": \"Anthony's Blog\", \"url\": \"https://www.scery.com/\", \"logo\": \"https://cdn.6-d.cc/img/friends/anthony.jpg\", \"desc\": \"As you look around\", })   all_friend.push({ \"name\": \"Marshall's Blog\", \"url\": \"https://www.naiquoy.com/\", \"logo\": \"https://cdn.6-d.cc/img/friends/wxy.jpg\", \"desc\": \"人生何处不青山\", })   all_friend.push({ \"name\": \"noechou\", \"url\": \"https://noechou.cn\", \"logo\": \"https://cdn.6-d.cc/img/friends/noechou.jpg\", \"desc\": \"要正视无情的真理，就要有无穷勇气\", })   all_friend.push({ \"name\": \"JerryXiao\", \"url\": \"https://jerryxiao.cc/\", \"logo\": \"https://cdn.6-d.cc/img/friends/jerryxiao.jpg\", \"desc\": \"某位网友\", })   all_friend = all_friend.sort(() = Math.random() - 0.5); all_friend.forEach(element = { document.querySelector('#all-friend').innerHTML += ``+element['name']+`\n`+element['desc']+`  ` });  ","permalink":"https://blog.lvcshu.com/friends/","summary":"console.log(\"test\") var all_friend = [];    all_friend.push({ \"name\": \"极光星空\", \"url\": \"https://blog.ilemonrain.com/\", \"logo\": \"https://cdn.6-d.cc/img/friends/ilemonrain.jpg\", \"desc\": \"探索星空，一路前行\", })   all_friend.push({ \"name\": \"Ovear's Blog\", \"url\": \"https://ovear.info/\", \"logo\": \"https://cdn.6-d.cc/img/friends/ovear.jpg\", \"desc\": \"=。=\", })   all_friend.push({ \"name\": \"南琴浪的博客\", \"url\": \"https://blog.sometimesnaive.org/\", \"logo\": \"https://cdn.6-d.cc/img/friends/sometimesnaive.jpeg\", \"desc\": \"已无法访问\", })   all_friend.push({ \"name\": \"Xzymoe's Blog\", \"url\": \"https://www.xzymoe.com/\", \"logo\": \"https://cdn.6-d.cc/img/friends/xzymoe.jpg\", \"desc\": \"关注互联网, 记录MOE的互联网生活.\", })   all_friend.push({ \"name\": \"奶冰の冷藏室\", \"url\": \"https://milkice.me\", \"logo\": \"https://cdn.6-d.cc/img/friends/milkice.jpg\", \"desc\": \"Maybe a way to explore the world?","title":"小伙伴们！"}]